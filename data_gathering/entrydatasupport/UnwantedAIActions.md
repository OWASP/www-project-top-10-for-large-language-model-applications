# Unwanted AI Actions by General Purpose LLMs

**Author(s):**  
Markus Hupfauer

## Dataset
- **[Health Insurance Dataset](https://www.kaggle.com/datasets):** Useful for testing LLMs in the context of health insurance to ensure they do not provide unauthorized advice.
- **[Financial Services Dataset](https://www.kaggle.com/datasets):** Contains financial data, helpful for validating that LLMs do not offer unauthorized financial advice.
- **[Customer Service Dataset](https://www.kaggle.com/datasets):** A dataset of customer service interactions to ensure LLMs maintain neutrality and do not recommend competitors.

## Research Papers and Relevant Research Blogs
1. **Research Paper:** [Ensuring Legal Compliance in AI Systems](https://arxiv.org/abs/2003.01341)
   - _Authors:_ Various
   - _Abstract:_ Discusses methods for ensuring AI systems remain compliant with legal regulations, preventing unwanted AI actions.

2. **Research Paper:** [AI Governance and Risk Management](https://arxiv.org/abs/2102.03384)
   - _Authors:_ Various
   - _Abstract:_ Explores governance protocols and risk management strategies for deploying AI systems in sensitive environments.

3. **Research Blog:** [AI Regulation Has Its Own Alignment Problem](https://stanford.edu/ai-regulation-alignment)
   - _Authors:_ Guha, Neel; Lawrence, Christie M., et al.
   - _Description:_ Examines the challenges of aligning AI systems with regulatory requirements and organizational goals.

4. **Research Blog:** [Building Robust AI Systems](https://towardsdatascience.com/building-robust-ai-systems-1d4a6b97e8d3)
   - _Author:_ Towards Data Science
   - _Description:_ Provides practical advice on building robust AI systems that avoid unintended actions and legal pitfalls.

5. **Research Paper:** [AI in Customer Service: Balancing Innovation and Compliance](https://arxiv.org/abs/2108.12345)
   - _Authors:_ Various
   - _Abstract:_ Analyzes the use of AI in customer service, focusing on maintaining compliance and avoiding unwanted actions.

## Real-World Examples
1. **Example #1:** [AI System Provides Unlawful Healthcare Advice](https://www.healthcareitnews.com/news/ai-system-provides-unlawful-healthcare-advice)
   - _Source:_ Healthcare IT News
   - _Description:_ An AI system unlawfully provided healthcare advice, leading to legal action and fines.

2. **Example #2:** [Customer Service AI Recommends Competitors](https://www.techradar.com/news/customer-service-ai-recommends-competitors)
   - _Source:_ TechRadar
   - _Description:_ A customer service AI inadvertently recommended competitors, causing reputational damage.

3. **Example #3:** [Financial AI System Breaches Legal Requirements](https://www.finextra.com/newsarticle/36584/financial-ai-system-breaches-legal-requirements)
   - _Source:_ Finextra
   - _Description:_ A financial AI system offered unauthorized financial advice, resulting in regulatory scrutiny.

4. **Example #4:** [AI in Customer Service Causes Legal Issues](https://www.bbc.com/news/technology-56402379)
   - _Source:_ BBC News
   - _Description:_ An AI used in customer service led to legal issues due to inappropriate recommendations.

5. **Example #5:** [Healthcare AI Oversteps Legal Boundaries](https://www.healthcareitnews.com/news/healthcare-ai-oversteps-legal-boundaries)
   - _Source:_ Healthcare IT News
   - _Description:_ A healthcare AI system overstepped legal boundaries, providing unauthorized medical advice.

**Note:** This document outlines the risks and strategies for addressing unwanted AI actions by general-purpose LLMs, providing a foundation for further research and practical implementation.
