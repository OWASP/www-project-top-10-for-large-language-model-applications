## LLM06:2025 الإفراط في الاستقلالية

### الوصف 

عادةً ما يتم منح نظام قائم على نموذج لغة كبير قدرًا من الاستقلالية من قِبل مطوّره — أي القدرة على استدعاء وظائف أو التفاعل مع أنظمة أخرى عبر الإضافات (Extensions)، والتي يُشار إليها أحيانًا باسم الأدوات (Tools) أو المهارات (Skills) أو المكونات الإضافية (Plugins) حسب المورد. قد يتم أيضًا تفويض القرار بشأن أي إضافة يتم استدعاؤها إلى "وكيل" (LLM Agent) لتحديدها ديناميكيًا بناءً على مدخلات التعليمات أو مخرجات النموذج. غالبًا ما تقوم الأنظمة المعتمدة على الوكلاء بإجراء استدعاءات متكررة للنموذج باستخدام مخرجات الاستدعاءات السابقة كأساس لتوجيه الاستدعاءات اللاحقة.

الإفراط في الاستقلالية (Excessive Agency) هو ثغرة تمكّن من تنفيذ إجراءات ضارة استجابةً لمخرجات غير متوقعة أو غامضة أو متلاعب بها من نموذج اللغة الكبير، بغض النظر عن السبب الذي أدى إلى خلل في أداء النموذج. تشمل المحفزات الشائعة ما يلي:
* الهلاوس/الاختلاقات الناتجة عن تعليمات سليمة ولكن مصممة بشكل سيئ، أو ببساطة عن أداء ضعيف للنموذج؛
* حقن التعليمات المباشر أو غير المباشر من قِبل المهاجم، أو من خلال استدعاء سابق لإضافة خبيثة أو مخترقة، أو (في الأنظمة متعددة الوكلاء/التعاونية) من وكيل نظير خبيث أو مخترق.

السبب الجذري للإفراط في الاستقلالية يعود عادةً إلى واحد أو أكثر من العوامل التالية:
* الإفراط في الوظائف (Excessive Functionality)؛
* الإفراط في الصلاحيات (Excessive Permissions)؛
* الإفراط في الاستقلالية (Excessive Autonomy).

يمكن أن يؤدي الإفراط في الاستقلالية إلى مجموعة واسعة من الآثار التي تطال جوانب السرية والنزاهة والتوافر، وذلك اعتمادًا على الأنظمة التي يتمكن تطبيق قائم على نموذج لغة كبير من التفاعل معها.

ملاحظة: يختلف الإفراط في الاستقلالية عن التعامل غير السليم مع المخرجات، حيث أن الأخير يتعلق بعدم التدقيق الكافي في مخرجات نموذج اللغة الكبير.

### أمثلة شائعة على المخاطر

#### 1. الإفراط في الوظائف
  يمتلك وكيل نموذج اللغة الكبير حق الوصول إلى إضافات تتضمن وظائف لا تُعد ضرورية للتشغيل المقصود للنظام. على سبيل المثال، يحتاج مطور إلى منح وكيل نموذج اللغة الكبير القدرة على قراءة مستندات من مستودع، لكن الإضافة الخارجية التي اختار استخدامها تتضمن أيضًا إمكانية تعديل وحذف المستندات.
#### 2. الإفراط في الوظائف
  قد تتم تجربة إضافة خلال مرحلة التطوير ويتم التخلي عنها لاحقًا لصالح بديل أفضل، إلا أن الإضافة الأصلية تظل متاحة لوكيل نموذج اللغة الكبير.
#### 3. الإفراط في الوظائف
  تفشل إضافة نموذج اللغة الكبير ذات الوظائف المفتوحة في تصفية تعليمات الإدخال بشكل صحيح لمنع تنفيذ أوامر تتجاوز ما هو مطلوب للتشغيل المقصود للتطبيق. على سبيل المثال، إضافة مخصصة لتنفيذ أمر واحد في موجه الأوامر (Shell) تفشل في منع تنفيذ أوامر أخرى.
#### 4. الإفراط في الصلاحيات
  تمتلك إضافة نموذج اللغة الكبير صلاحيات على الأنظمة الفرعية تتجاوز ما هو ضروري للتشغيل المقصود للتطبيق. على سبيل المثال، إضافة مخصصة لقراءة البيانات تتصل بخادم قاعدة بيانات باستخدام هوية تملك ليس فقط صلاحيات SELECT بل أيضًا صلاحيات UPDATE وINSERT وDELETE.
#### 5. الإفراط في الصلاحيات
  إضافة نموذج اللغة الكبير مصممة لتنفيذ عمليات في سياق مستخدم فردي، تصل إلى الأنظمة الفرعية باستخدام هوية عامة ذات امتيازات عالية. على سبيل المثال، إضافة مصممة لقراءة مستودع مستندات المستخدم الحالي تتصل بمستودع المستندات عبر حساب ذي امتيازات يتيح الوصول إلى ملفات جميع المستخدمين.
#### 6. الإفراط في الاستقلالية
  فشل تطبيق أو إضافة قائمة على نموذج اللغة الكبير (LLM) في التحقق والموافقة بشكل مستقل على العمليات ذات التأثير الكبير. على سبيل المثال، إضافة تتيح حذف مستندات المستخدم تقوم بعمليات الحذف دون أي تأكيد من المستخدم.

### استراتيجيات الوقاية والتخفيف

تساعد الإجراءات التالية في منع الإفراط في الاستقلالية:

#### 1. تقليل الإضافات
  قلل الإضافات التي يُسمح لوكلاء نموذج اللغة الكبير باستدعائها إلى الحد الأدنى اللازم فقط. على سبيل المثال، إذا لم يكن نظام قائم على نموذج اللغة الكبير يحتاج إلى القدرة على جلب محتويات عنوان URL، فلا ينبغي تقديم مثل هذه الإضافة إلى الوكيل.
#### 2. تقليل وظائف الإضافات
  حدّد الوظائف المنفذة ضمن إضافات نموذج اللغة الكبير إلى الحد الأدنى الضروري فقط. على سبيل المثال، قد تتطلب إضافة للوصول إلى صندوق بريد المستخدم بغرض تلخيص الرسائل فقط القدرة على قراءة الرسائل، ولا ينبغي أن تحتوي على وظائف إضافية مثل حذف الرسائل أو إرسالها.
#### 3. تجنب الإضافات المفتوحة
  تجنب استخدام الإضافات ذات النطاق المفتوح قدر الإمكان (مثل تنفيذ أوامر Shell أو جلب عنوان URL) واستخدم إضافات ذات وظائف أكثر دقة. على سبيل المثال، قد يحتاج تطبيق قائم على نموذج اللغة الكبير إلى كتابة مخرجات إلى ملف. إذا تم تنفيذ ذلك عبر إضافة لتنفيذ أمر في موجه أوامر النظام (Shell)، فإن مجال تنفيذ أوامر غير مرغوبة يصبح واسعًا جدًا (أي أمر Shell آخر قد يتم تنفيذه). البديل الأكثر أمانًا هو بناء إضافة مخصصة لكتابة الملفات لا تنفذ سوى هذه الوظيفة المحددة.
#### 4. تقليل صلاحيات الإضافات
  حد من الصلاحيات التي تُمنح لإضافات نموذج اللغة الكبير على الأنظمة الأخرى إلى الحد الأدنى اللازم لتقليل مجال الأفعال غير المرغوبة. على سبيل المثال، قد يحتاج وكيل نموذج اللغة الكبير يستخدم قاعدة بيانات منتجات لإعطاء توصيات شراء إلى حق الوصول للقراءة فقط إلى جدول "المنتجات"، ويجب ألا يكون لديه حق الوصول إلى جداول أخرى أو القدرة على إدخال أو تعديل أو حذف السجلات. ينبغي فرض ذلك من خلال تطبيق صلاحيات قاعدة بيانات مناسبة على الهوية التي تستخدمها الإضافة للاتصال بقاعدة البيانات.
#### 5. تنفيذ الإضافات في سياق المستخدم
  تتبع تفويض المستخدم ونطاق الأمان لضمان أن جميع العمليات التي تتم بالنيابة عن المستخدم تُنفذ في الأنظمة الفرعية ضمن سياق هذا المستخدم المحدد ومع أقل امتيازات ممكنة. على سبيل المثال، يجب أن تتطلب إضافة نموذج اللغة الكبير التي تقرأ مستودع كود المستخدم أن يصادق المستخدم عبر OAuth مع أقل نطاق صلاحيات مطلوب.
#### 6. اشتراط موافقة المستخدم
  استخدم آلية "الإنسان في الحلقة" (Human-in-the-Loop) لطلب موافقة بشرية على العمليات ذات التأثير الكبير قبل تنفيذها. قد يتم تنفيذ هذه الآلية في نظام فرعي (خارج نطاق تطبيق نموذج اللغة الكبير) أو داخل الإضافة نفسها. على سبيل المثال، يجب أن يتضمن تطبيق قائم على نموذج اللغة الكبير ينشئ منشورات على وسائل التواصل الاجتماعي نيابة عن المستخدم، روتينًا لموافقة المستخدم داخل الإضافة التي تنفذ عملية النشر.
#### 7. تطبيق الوساطة الكاملة
  نفّذ آليات التحقق من الصلاحيات داخل الأنظمة الفرعية بدلاً من الاعتماد على نموذج اللغة الكبير في تحديد ما إذا كان الإجراء مسموحًا أم لا. طبّق مبدأ الوساطة الكاملة لضمان التحقق من جميع الطلبات المرسلة إلى الأنظمة الفرعية عبر الإضافات ضد السياسات الأمنية.
#### 8. تنقية مدخلات ومخرجات نموذج اللغة الكبير
  اتبع أفضل ممارسات البرمجة الآمنة، مثل تطبيق توصيات أواسب (OWASP) ضمن معيار التحقق من أمان التطبيقات (ASVS)، مع التركيز بشكل خاص على تنقية المدخلات. استخدم اختبار أمان البرمجيات الثابت (SAST) واختبار البرمجيات الديناميكي والتفاعلي (DAST وIAST) ضمن خطوط تطوير البرمجيات.

الخيارات التالية لن تمنع الإفراط في الاستقلالية، ولكن يمكنها الحد من مستوى الضرر الناتج:

- سجل وراقب نشاط إضافات نموذج اللغة الكبير والأنظمة الفرعية المرتبطة بها لتحديد أماكن حدوث الأفعال غير المرغوبة، والاستجابة لها بشكل مناسب.
- نفّذ قيودًا على معدل الطلبات (Rate-Limiting) لتقليل عدد الأفعال غير المرغوبة التي يمكن أن تحدث خلال فترة زمنية معينة، مما يزيد من فرصة اكتشاف الأفعال غير المرغوبة عبر المراقبة قبل حدوث ضرر كبير.

### أمثلة على سيناريوهات الهجوم

يُمنح تطبيق مساعد شخصي قائم على نموذج اللغة الكبير حق الوصول إلى صندوق بريد فردي عبر إضافة بغرض تلخيص محتوى الرسائل الواردة. لتنفيذ هذه الوظيفة، تتطلب الإضافة القدرة على قراءة الرسائل، ومع ذلك فإن المكون الإضافي الذي اختاره مطور النظام يحتوي أيضًا على وظائف لإرسال الرسائل. بالإضافة إلى ذلك، يكون التطبيق عرضة لهجوم حقن تعليمات غير مباشر، حيث تقوم رسالة بريد إلكتروني خبيثة مصممة خصيصًا بخداع النموذج وإصدار أمر للوكيل بفحص صندوق بريد المستخدم بحثًا عن معلومات حساسة وإرسالها إلى عنوان البريد الإلكتروني الخاص بالمهاجم. يمكن تجنب ذلك عبر:
* التخلص من الإفراط في الوظائف عبر استخدام إضافة تنفذ فقط إمكانيات قراءة البريد؛
* التخلص من الإفراط في الصلاحيات عبر المصادقة على خدمة بريد المستخدم باستخدام جلسة OAuth بنطاق قراءة فقط؛
* أو التخلص من الإفراط في الاستقلالية) عبر اشتراط مراجعة المستخدم يدويًا والنقر على "إرسال" لكل رسالة يتم إعدادها بواسطة إضافة نموذج اللغة الكبير.

بديلًا عن ذلك، يمكن تقليل الضرر الناتج عبر تطبيق قيود على معدل إرسال الرسائل عبر واجهة إرسال البريد الإلكتروني نفسها.

### روابط مرجعية

1. [Slack AI data exfil from private channels](https://promptarmor.substack.com/p/slack-ai-data-exfiltration-from-private): **PromptArmor**
2. [Rogue Agents: Stop AI From Misusing Your APIs](https://www.twilio.com/en-us/blog/rogue-ai-agents-secure-your-apis): **Twilio**
3. [Embrace the Red: Confused Deputy Problem](https://embracethered.com/blog/posts/2023/chatgpt-cross-plugin-request-forgery-and-prompt-injection./): **Embrace The Red**
4. [NeMo-Guardrails: Interface guidelines](https://github.com/NVIDIA/NeMo-Guardrails/blob/main/docs/security/guidelines.md): **NVIDIA Github**
6. [Simon Willison: Dual LLM Pattern](https://simonwillison.net/2023/Apr/25/dual-llm-pattern/): **Simon Willison**
7. [Sandboxing Agentic AI Workflows with WebAssembly](https://developer.nvidia.com/blog/sandboxing-agentic-ai-workflows-with-webassembly/) **NVIDIA, Joe Lucas**
