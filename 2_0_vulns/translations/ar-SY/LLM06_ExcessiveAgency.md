## LLM06:2025 الإفراط في الاستقلالية (Excessive Agency)

### الوصف 

عادةً ما يتم منح نظام قائم على نموذج لغة كبير (LLM) قدرًا من الاستقلالية من قِبل مطوّره — أي القدرة على استدعاء وظائف أو التفاعل مع أنظمة أخرى عبر الإضافات (Extensions)، والتي يُشار إليها أحيانًا باسم الأدوات (Tools) أو المهارات (Skills) أو المكونات الإضافية (Plugins) حسب المورد. قد يتم أيضًا تفويض القرار بشأن أي إضافة يتم استدعاؤها إلى "وكيل" (LLM Agent) لتحديدها ديناميكيًا بناءً على مدخلات التعليمات أو مخرجات النموذج. غالبًا ما تقوم الأنظمة المعتمدة على الوكلاء بإجراء استدعاءات متكررة للنموذج باستخدام مخرجات الاستدعاءات السابقة كأساس لتوجيه الاستدعاءات اللاحقة.

الإفراط في الاستقلالية (Excessive Agency) هو ثغرة تمكّن من تنفيذ إجراءات ضارة استجابةً لمخرجات غير متوقعة أو غامضة أو متلاعب بها من نموذج اللغة الكبير (LLM)، بغض النظر عن السبب الذي أدى إلى خلل في أداء النموذج. تشمل المحفزات الشائعة ما يلي:
* الهلاوس/الاختلاقات الناتجة عن تعليمات سليمة ولكن مصممة بشكل سيئ، أو ببساطة عن أداء ضعيف للنموذج؛
* حقن التعليمات المباشر أو غير المباشر من قِبل المهاجم، أو من خلال استدعاء سابق لإضافة خبيثة أو مخترقة، أو (في الأنظمة متعددة الوكلاء/التعاونية) من وكيل نظير خبيث أو مخترق.

السبب الجذري للإفراط في الاستقلالية (Excessive Agency) يعود عادةً إلى واحد أو أكثر من العوامل التالية:
* الإفراط في الوظائف (Excessive Functionality)؛
* الإفراط في الصلاحيات (Excessive Permissions)؛
* الإفراط في الاستقلالية (Excessive Autonomy).

يمكن أن يؤدي الإفراط في الاستقلالية إلى مجموعة واسعة من الآثار التي تطال جوانب السرية والنزاهة والتوافر، وذلك اعتمادًا على الأنظمة التي يتمكن تطبيق قائم على نموذج لغة كبير (LLM-based app) من التفاعل معها.

ملاحظة: يختلف الإفراط في الاستقلالية عن التعامل غير السليم مع المخرجات (Insecure Output Handling)، حيث أن الأخير يتعلق بعدم التدقيق الكافي في مخرجات نموذج اللغة الكبير.

### أمثلة شائعة على المخاطر

#### 1. الإفراط في الوظائف (Excessive Functionality)
  يمتلك وكيل نموذج اللغة الكبير حق الوصول إلى إضافات تتضمن وظائف لا تُعد ضرورية للتشغيل المقصود للنظام. على سبيل المثال، يحتاج مطور إلى منح وكيل LLM القدرة على قراءة مستندات من مستودع، لكن الإضافة الخارجية التي اختار استخدامها تتضمن أيضًا إمكانية تعديل وحذف المستندات.
#### 2. الإفراط في الوظائف (Excessive Functionality)
  قد تتم تجربة إضافة خلال مرحلة التطوير ويتم التخلي عنها لاحقًا لصالح بديل أفضل، إلا أن الإضافة الأصلية تظل متاحة لوكيل LLM.
#### 3. الإفراط في الوظائف (Excessive Functionality)
  تفشل إضافة نموذج اللغة الكبير ذات الوظائف المفتوحة في تصفية تعليمات الإدخال بشكل صحيح لمنع تنفيذ أوامر تتجاوز ما هو مطلوب للتشغيل المقصود للتطبيق. على سبيل المثال، إضافة مخصصة لتنفيذ أمر واحد في غلاف النظام (Shell) تفشل في منع تنفيذ أوامر أخرى.
#### 4. الإفراط في الصلاحيات (Excessive Permissions)
  تمتلك إضافة نموذج اللغة الكبير صلاحيات على الأنظمة الفرعية (Downstream Systems) تتجاوز ما هو ضروري للتشغيل المقصود للتطبيق. على سبيل المثال، إضافة مخصصة لقراءة البيانات تتصل بخادم قاعدة بيانات باستخدام هوية تملك ليس فقط صلاحيات SELECT بل أيضًا صلاحيات UPDATE وINSERT وDELETE.
#### 5. الإفراط في الصلاحيات (Excessive Permissions)
  إضافة نموذج اللغة الكبير مصممة لتنفيذ عمليات في سياق مستخدم فردي، تصل إلى الأنظمة الفرعية باستخدام هوية عامة ذات امتيازات عالية. على سبيل المثال، إضافة مصممة لقراءة مستودع مستندات المستخدم الحالي تتصل بمستودع المستندات عبر حساب ذي امتيازات يتيح الوصول إلى ملفات جميع المستخدمين.
#### 6. الإفراط في الاستقلالية (Excessive Autonomy)
  فشل تطبيق أو إضافة قائمة على نموذج اللغة الكبير (LLM) في التحقق والموافقة بشكل مستقل على العمليات ذات التأثير الكبير. على سبيل المثال، إضافة تتيح حذف مستندات المستخدم تقوم بعمليات الحذف دون أي تأكيد من المستخدم.

### استراتيجيات الوقاية والتخفيف

تساعد الإجراءات التالية في منع الإفراط في الاستقلالية (Excessive Agency):

#### 1. تقليل الإضافات (Minimize Extensions)
  قلل الإضافات التي يُسمح لوكلاء نموذج اللغة الكبير (LLM) باستدعائها إلى الحد الأدنى اللازم فقط. على سبيل المثال، إذا لم يكن نظام قائم على LLM يحتاج إلى القدرة على جلب محتويات عنوان URL، فلا ينبغي تقديم مثل هذه الإضافة إلى وكيل LLM.
#### 2. تقليل وظائف الإضافات (Minimize Extension Functionality)
  حدّد الوظائف المنفذة ضمن إضافات نموذج اللغة الكبير (LLM) إلى الحد الأدنى الضروري فقط. على سبيل المثال، قد تتطلب إضافة للوصول إلى صندوق بريد المستخدم بغرض تلخيص الرسائل فقط القدرة على قراءة الرسائل، ولا ينبغي أن تحتوي على وظائف إضافية مثل حذف الرسائل أو إرسالها.
#### 3. تجنب الإضافات المفتوحة (Avoid Open-Ended Extensions)
  تجنب استخدام الإضافات ذات النطاق المفتوح قدر الإمكان (مثل تنفيذ أوامر Shell أو جلب عنوان URL) واستخدم إضافات ذات وظائف أكثر دقة. على سبيل المثال، قد يحتاج تطبيق قائم على نموذج اللغة الكبير (LLM) إلى كتابة مخرجات إلى ملف. إذا تم تنفيذ ذلك عبر إضافة لتنفيذ أمر في غلاف النظام (Shell)، فإن مجال تنفيذ أوامر غير مرغوبة يصبح واسعًا جدًا (أي أمر Shell آخر قد يتم تنفيذه). البديل الأكثر أمانًا هو بناء إضافة مخصصة لكتابة الملفات لا تنفذ سوى هذه الوظيفة المحددة.
#### 4. تقليل صلاحيات الإضافات (Minimize Extension Permissions)
  حد من الصلاحيات التي تُمنح لإضافات نموذج اللغة الكبير (LLM) على الأنظمة الأخرى إلى الحد الأدنى اللازم لتقليل مجال الأفعال غير المرغوبة. على سبيل المثال، قد يحتاج وكيل نموذج اللغة الكبير (LLM) يستخدم قاعدة بيانات منتجات لإعطاء توصيات شراء إلى حق الوصول للقراءة فقط إلى جدول "المنتجات"، ويجب ألا يكون لديه حق الوصول إلى جداول أخرى أو القدرة على إدخال أو تعديل أو حذف السجلات. ينبغي فرض ذلك من خلال تطبيق صلاحيات قاعدة بيانات مناسبة على الهوية التي تستخدمها الإضافة للاتصال بقاعدة البيانات.
#### 5. تنفيذ الإضافات في سياق المستخدم (Execute Extensions in User's Context)
  تتبع تفويض المستخدم ونطاق الأمان لضمان أن جميع العمليات التي تتم بالنيابة عن المستخدم تُنفذ في الأنظمة الفرعية (Downstream Systems) ضمن سياق هذا المستخدم المحدد ومع أقل امتيازات ممكنة. على سبيل المثال، يجب أن تتطلب إضافة نموذج اللغة الكبير (LLM) التي تقرأ مستودع كود المستخدم أن يصادق المستخدم عبر OAuth مع أقل نطاق صلاحيات مطلوب.
#### 6. اشتراط موافقة المستخدم (Require User Approval)
  استخدم آلية "الإنسان في الحلقة" (Human-in-the-Loop) لطلب موافقة بشرية على العمليات ذات التأثير الكبير قبل تنفيذها. قد يتم تنفيذ هذه الآلية في نظام فرعي (خارج نطاق تطبيق LLM) أو داخل الإضافة نفسها. على سبيل المثال، يجب أن يتضمن تطبيق قائم على LLM ينشئ منشورات على وسائل التواصل الاجتماعي نيابة عن المستخدم، روتينًا لموافقة المستخدم داخل الإضافة التي تنفذ عملية النشر.
#### 7. تطبيق الوساطة الكاملة (Complete Mediation)
  نفّذ آليات التحقق من الصلاحيات داخل الأنظمة الفرعية بدلاً من الاعتماد على نموذج اللغة الكبير (LLM) في تحديد ما إذا كان الإجراء مسموحًا أم لا. طبّق مبدأ الوساطة الكاملة لضمان التحقق من جميع الطلبات المرسلة إلى الأنظمة الفرعية عبر الإضافات ضد السياسات الأمنية.
#### 8. تنقية مدخلات ومخرجات نموذج اللغة الكبير (Sanitise LLM Inputs and Outputs)
  اتبع أفضل ممارسات البرمجة الآمنة، مثل تطبيق توصيات OWASP ضمن معيار التحقق من أمان التطبيقات (ASVS)، مع التركيز بشكل خاص على تنقية المدخلات. استخدم اختبار أمان البرمجيات الثابت (SAST) واختبار البرمجيات الديناميكي والتفاعلي (DAST وIAST) ضمن خطوط تطوير البرمجيات.

الخيارات التالية لن تمنع الإفراط في الاستقلالية (Excessive Agency)، ولكن يمكنها الحد من مستوى الضرر الناتج:

- سجل وراقب نشاط إضافات LLM والأنظمة الفرعية المرتبطة بها لتحديد أماكن حدوث الأفعال غير المرغوبة، والاستجابة لها بشكل مناسب.
- نفّذ قيودًا على معدل الطلبات (Rate-Limiting) لتقليل عدد الأفعال غير المرغوبة التي يمكن أن تحدث خلال فترة زمنية معينة، مما يزيد من فرصة اكتشاف الأفعال غير المرغوبة عبر المراقبة قبل حدوث ضرر كبير.

### أمثلة على سيناريوهات الهجوم

يُمنح تطبيق مساعد شخصي قائم على نموذج اللغة الكبير حق الوصول إلى صندوق بريد فردي عبر إضافة (Extension) بغرض تلخيص محتوى الرسائل الواردة. لتنفيذ هذه الوظيفة، تتطلب الإضافة القدرة على قراءة الرسائل، ومع ذلك فإن المكون الإضافي الذي اختاره مطور النظام يحتوي أيضًا على وظائف لإرسال الرسائل. بالإضافة إلى ذلك، يكون التطبيق عرضة لهجوم حقن تعليمات غير مباشر (Indirect Prompt Injection)، حيث تقوم رسالة بريد إلكتروني خبيثة مصممة خصيصًا بخداع النموذج وإصدار أمر للوكيل (Agent) بفحص صندوق بريد المستخدم بحثًا عن معلومات حساسة وإرسالها إلى عنوان البريد الإلكتروني الخاص بالمهاجم. يمكن تجنب ذلك عبر:
* التخلص من الإفراط في الوظائف (Excessive Functionality) عبر استخدام إضافة تنفذ فقط إمكانيات قراءة البريد؛
* التخلص من الإفراط في الصلاحيات (Excessive Permissions) عبر المصادقة على خدمة بريد المستخدم باستخدام جلسة OAuth بنطاق قراءة فقط (Read-Only Scope)؛
* أو التخلص من الإفراط في الاستقلالية (Excessive Autonomy) عبر اشتراط مراجعة المستخدم يدويًا والنقر على "إرسال" لكل رسالة يتم إعدادها بواسطة إضافة نموذج اللغة الكبير (LLM Extension).

بديلًا عن ذلك، يمكن تقليل الضرر الناتج عبر تطبيق قيود على معدل إرسال الرسائل (Rate-Limiting) عبر واجهة إرسال البريد الإلكتروني نفسها.

### روابط مرجعية

1. [Slack AI data exfil from private channels](https://promptarmor.substack.com/p/slack-ai-data-exfiltration-from-private): **PromptArmor**
2. [Rogue Agents: Stop AI From Misusing Your APIs](https://www.twilio.com/en-us/blog/rogue-ai-agents-secure-your-apis): **Twilio**
3. [Embrace the Red: Confused Deputy Problem](https://embracethered.com/blog/posts/2023/chatgpt-cross-plugin-request-forgery-and-prompt-injection./): **Embrace The Red**
4. [NeMo-Guardrails: Interface guidelines](https://github.com/NVIDIA/NeMo-Guardrails/blob/main/docs/security/guidelines.md): **NVIDIA Github**
6. [Simon Willison: Dual LLM Pattern](https://simonwillison.net/2023/Apr/25/dual-llm-pattern/): **Simon Willison**
7. [Sandboxing Agentic AI Workflows with WebAssembly](https://developer.nvidia.com/blog/sandboxing-agentic-ai-workflows-with-webassembly/) **NVIDIA, Joe Lucas**
