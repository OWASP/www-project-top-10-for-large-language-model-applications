## LLM10:2025 الاستهلاك غير المحدود

### الوصف 

يشير مصطلح الاستهلاك غير المحدود (Unbounded Consumption) إلى العملية التي يقوم فيها نموذج اللغة الكبير بتوليد مخرجات استنادًا إلى استعلامات أو مطالبات الإدخال. تُعد عملية الاستدلال (Inference) وظيفة أساسية لنماذج اللغة الكبيرة، حيث تتضمن تطبيق الأنماط والمعرفة المكتسبة لإنتاج استجابات أو تنبؤات ذات صلة.

تعتمد الهجمات المصممة لتعطيل الخدمة، أو استنزاف الموارد المالية للهدف، أو حتى سرقة الملكية الفكرية عن طريق استنساخ سلوك النموذج، على نوع شائع من الثغرات الأمنية لتحقيق النجاح. يحدث الاستهلاك غير المحدود عندما يسمح تطبيق يعتمد على نموذج لغة كبير  للمستخدمين بإجراء استدلالات مفرطة وغير مضبوطة، مما يؤدي إلى مخاطر مثل حجب الخدمة (DoS)، والخسائر الاقتصادية، وسرقة النموذج، وتدهور الخدمة. تجعل المتطلبات الحسابية العالية للنماذج، خاصة في البيئات السحابية، هذه النماذج عرضة لاستغلال الموارد والاستخدام غير المصرح به.

### أمثلة شائعة على الثغرات

#### 1. إغراق الإدخال بطول متغير
  يمكن للمهاجمين تحميل نموذج اللغة الكبير بعدد كبير من المدخلات ذات الأطوال المختلفة، مستغلين أوجه القصور في المعالجة. يمكن أن يؤدي ذلك إلى استنزاف الموارد وقد يتسبب في جعل النظام غير مستجيب، مما يؤثر بشكل كبير على توفر الخدمة.
#### 2. استنزاف المحفظة
  من خلال إطلاق حجم كبير من العمليات، يستغل المهاجمون نموذج التكلفة حسب الاستخدام لخدمات الذكاء الاصطناعي السحابية، مما يؤدي إلى أعباء مالية غير مستدامة على المزود ويهدد بإحداث خسائر مالية جسيمة.
#### 3. تدفق الإدخال المستمر
  إرسال مدخلات بشكل مستمر تتجاوز نافذة السياق للنموذج يمكن أن يؤدي إلى استخدام مفرط للموارد الحاسوبية، مما يتسبب في تدهور الخدمة واضطرابات تشغيلية.
#### 4. استعلامات كثيفة الموارد
  تقديم استعلامات تتطلب موارد عالية بشكل غير عادي تتضمن تسلسلات معقدة أو أنماط لغوية دقيقة يمكن أن يستهلك موارد النظام بشكل مفرط، مما يؤدي إلى أوقات معالجة طويلة واحتمال حدوث أعطال في النظام.
#### 5. استخراج النموذج عبر واجهة برمجية
  قد يقوم المهاجمون باستدعاء واجهة برمجة API التطبيقات للنموذج باستخدام مدخلات مصممة بعناية وتقنيات حقن التعليمات لجمع مخرجات كافية تتيح لهم استنساخ نموذج جزئي أو إنشاء نموذج ظل. يمثل ذلك خطرًا على الملكية الفكرية ويقوض سلامة النموذج الأصلي.
#### 6. استنساخ النموذج الوظيفي
  باستخدام النموذج المستهدف لتوليد بيانات تدريب اصطناعية، يمكن للمهاجمين ضبط نموذج أساسي آخر وإنشاء نموذج مكافئ وظيفيًا. يتيح هذا النهج تجاوز طرق الاستخراج التقليدية المعتمدة على الاستعلامات، مما يشكل تهديدًا كبيرًا للنماذج والتقنيات المملوكة.
#### 7. هجمات القنوات الجانبية
  قد يستغل المهاجمون الخبيثون تقنيات تصفية المدخلات الخاصة بنموذج اللغة الكبير لتنفيذ هجمات القنوات الجانبية، لجمع أوزان النموذج ومعلومات حول هيكليته. يمكن أن يؤدي ذلك إلى تعريض أمن النموذج للخطر وفتح المجال لمزيد من الاستغلال.

### استراتيجيات الوقاية والتخفيف

#### 1. التحقق من المدخلات
  نفّذ عمليات تحقق صارمة من المدخلات لضمان عدم تجاوز المدخلات للحدود الحجمية المعقولة.
#### 2. تقييد إظهار Logits و Logprobs
  قيّد أو قم بإخفاء كشف معلومات `logit_bias` و`logprobs` في ردود واجهة برمجة التطبيقات (APIs). قدّم فقط المعلومات الضرورية دون الكشف عن الاحتمالات التفصيلية.
#### 3. تحديد المعدل
  طبّق تحديد المعدل (Rate Limiting) وحصص المستخدمين لتقييد عدد الطلبات التي يمكن لكيان واحد إرسالها خلال فترة زمنية محددة.
#### 4. إدارة تخصيص الموارد
  راقب وادرس تخصيص الموارد بشكل ديناميكي لمنع أي مستخدم أو طلب واحد من استهلاك موارد مفرطة.
#### 5. تحديد المهلة وتقليل سرعة المعالجة
  قم بتعيين مهلات (Timeouts) وقلل سرعة المعالجة (Throttling) للعمليات التي تستهلك موارد بكثافة لمنع الاستهلاك المطوّل للموارد.
#### 6.تقنيات العزل
  قيّد وصول نموذج اللغة الكبير إلى الموارد الشبكية، والخدمات الداخلية، وواجهات برمجة التطبيقات.
  - يُعد ذلك بالغ الأهمية في جميع السيناريوهات الشائعة لأنه يشمل مخاطر وتهديدات من الداخل. علاوة على ذلك، فإنه يتحكم في مدى وصول تطبيق نموذج اللغة الكبير إلى البيانات والموارد، ما يجعله آلية تحكم حاسمة للتخفيف من هجمات القنوات الجانبية أو منعها.
#### 7. التسجيل الشامل والمراقبة والكشف عن الشذوذ
  قم بمراقبة استخدام الموارد باستمرار وتنفيذ تسجيلات لاكتشاف أنماط استهلاك غير معتادة والاستجابة لها.
#### 8. وضع العلامات المائية
  قم بتنفيذ أطر عمل لوضع العلامات المائية (Watermarking) لاكتشاف الاستخدام غير المصرح به لمخرجات نموذج اللغة الكبير.
#### 9. التدهور التدريجي
  صمّم النظام بحيث يتدهور تدريجيًا عند التحميل الزائد، مع الحفاظ على بعض الوظائف بدلاً من الانهيار الكامل.
#### 10. تقييد الإجراءات المنتظرة والتوسع الديناميكي
  طبّق قيودًا على عدد الإجراءات المنتظرة والإجراءات الإجمالية، مع دمج التوسع الديناميكي (Dynamic Scaling) وموازنة الأحمال (Load Balancing) للتعامل مع الطلبات المتغيرة وضمان أداء النظام باستمرار.
#### 11. تدريب على مقاومة الهجمات التلاعبية
  درّب النماذج لاكتشاف الاستعلامات الهجومية ومحاولات الاستخراج والتخفيف من آثارها.
#### 12. تصفية الرموز المعطوبة
  أنشئ قوائم بالرموز المعطوبة المعروفة وقم بفحص المخرجات قبل إضافتها إلى نافذة السياق للنموذج.
#### 13. ضوابط الوصول
  قم بتنفيذ ضوابط وصول قوية، بما في ذلك التحكم بالوصول المعتمد على الأدوار (RBAC) ومبدأ أقل امتياز (Least Privilege) للحد من الوصول غير المصرح به إلى مستودعات النماذج وبيئات التدريب.
#### 14. مستودع مركزي لنماذج التعلّم الآلي
  استخدم سجل مركزي أو مستودع نماذج (Model Registry) للنماذج المستخدمة في بيئة الإنتاج لضمان الحوكمة المناسبة والتحكم في الوصول.
#### 15. النشر الآلي لعمليات إدارة نماذج التعلم الآلي
  قم بتنفيذ نشر آلي لعمليات MLOps يتضمن الحوكمة، والتتبع، وتدفقات الموافقة (Approval Workflows) لتعزيز ضوابط الوصول والنشر داخل البنية التحتية.

### أمثلة على سيناريوهات الهجوم

#### السيناريو  #1: حجم إدخال غير منضبط
  يقوم مهاجم بإرسال إدخال كبير بشكل غير معتاد إلى تطبيق نموذج اللغة الكبير يعالج بيانات نصية، مما يؤدي إلى استخدام مفرط للذاكرة وحمل زائد على وحدة المعالجة المركزية (CPU)، وقد يتسبب ذلك في تعطل النظام أو إبطاء الخدمة بشكل كبير.
#### السيناريو  #2: الطلبات المتكررة
  يرسل المهاجم حجمًا كبيرًا من الطلبات إلى واجهة API الخاصة بنموذج اللغة الكبير، مما يؤدي إلى استهلاك مفرط للموارد الحاسوبية ويجعل الخدمة غير متاحة للمستخدمين الشرعيين.
#### السيناريو  #3: استعلامات كثيفة الموارد
  يصمم المهاجم مدخلات محددة مصممة لتفعيل أكثر العمليات استهلاكًا للموارد في نموذج اللغة الكبير، مما يؤدي إلى استخدام مطوّل لوحدة المعالجة المركزية واحتمال تعطل النظام.
#### السيناريو  #4: استنزاف المحفظة
  يقوم المهاجم بإنشاء عمليات مفرطة لاستغلال نموذج الدفع مقابل الاستخدام لخدمات الذكاء الاصطناعي السحابية، مما يتسبب في تكاليف غير مستدامة لمزود الخدمة.
#### السيناريو  #5: استنساخ النموذج الوظيفي
  يستخدم المهاجم واجهة API الخاصة بنموذج اللغة الكبير لتوليد بيانات تدريب اصطناعية ويقوم بضبط نموذج آخر، مما يؤدي إلى إنشاء نموذج مكافئ وظيفيًا ويتجاوز القيود التقليدية لاستخراج النماذج.
#### السيناريو  #6: تجاوز تصفية مدخلات النظام
  يقوم مهاجم خبيث بتجاوز تقنيات تصفية المدخلات ومقدمات النموذج (Preambles) لتنفيذ هجوم القنوات الجانبية واسترجاع معلومات النموذج إلى مورد يتم التحكم به عن بُعد.

### روابط مرجعية

1. [Proof Pudding (CVE-2019-20634)](https://avidml.org/database/avid-2023-v009/) **AVID** (`moohax` & `monoxgas`)
2. [arXiv:2403.06634 Stealing Part of a Production Language Model](https://arxiv.org/abs/2403.06634) **arXiv**
3. [Runaway LLaMA | How Meta's LLaMA NLP model leaked](https://www.deeplearning.ai/the-batch/how-metas-llama-nlp-model-leaked/): **Deep Learning Blog**
4. [You wouldn't download an AI, Extracting AI models from mobile apps](https://altayakkus.substack.com/p/you-wouldnt-download-an-ai): **Substack blog**
5. [A Comprehensive Defense Framework Against Model Extraction Attacks](https://ieeexplore.ieee.org/document/10080996): **IEEE**
6. [Alpaca: A Strong, Replicable Instruction-Following Model](https://crfm.stanford.edu/2023/03/13/alpaca.html): **Stanford Center on Research for Foundation Models (CRFM)**
7. [How Watermarking Can Help Mitigate The Potential Risks Of LLMs?](https://www.kdnuggets.com/2023/03/watermarking-help-mitigate-potential-risks-llms.html): **KD Nuggets**
8. [Securing AI Model Weights Preventing Theft and Misuse of Frontier Models](https://www.rand.org/content/dam/rand/pubs/research_reports/RRA2800/RRA2849-1/RAND_RRA2849-1.pdf)
9. [Sponge Examples: Energy-Latency Attacks on Neural Networks: Arxiv White Paper](https://arxiv.org/abs/2006.03463) **arXiv**
10. [Sourcegraph Security Incident on API Limits Manipulation and DoS Attack](https://about.sourcegraph.com/blog/security-update-august-2023) **Sourcegraph**

### الأطر والتصنيفات ذات الصلة 

راجع هذا القسم للحصول على معلومات شاملة، واستراتيجيات السيناريوهات المتعلقة بنشر البنية التحتية، وضوابط البيئة التطبيقية، وأفضل الممارسات الأخرى.

- [MITRE CWE-400: Uncontrolled Resource Consumption](https://cwe.mitre.org/data/definitions/400.html) **MITRE Common Weakness Enumeration**
- [AML.TA0000 ML Model Access: Mitre ATLAS](https://atlas.mitre.org/tactics/AML.TA0000) & [AML.T0024 Exfiltration via ML Inference API](https://atlas.mitre.org/techniques/AML.T0024) **MITRE ATLAS**
- [AML.T0029 - Denial of ML Service](https://atlas.mitre.org/techniques/AML.T0029) **MITRE ATLAS**
- [AML.T0034 - Cost Harvesting](https://atlas.mitre.org/techniques/AML.T0034) **MITRE ATLAS**
- [AML.T0025 - Exfiltration via Cyber Means](https://atlas.mitre.org/techniques/AML.T0025) **MITRE ATLAS**
- [OWASP Machine Learning Security Top Ten - ML05:2023 Model Theft](https://owasp.org/www-project-machine-learning-security-top-10/docs/ML05_2023-Model_Theft.html) **OWASP ML Top 10**
- [API4:2023 - Unrestricted Resource Consumption](https://owasp.org/API-Security/editions/2023/en/0xa4-unrestricted-resource-consumption/) **OWASP Web Application Top 10**
- [OWASP Resource Management](https://owasp.org/www-project-secure-coding-practices-quick-reference-guide/) **OWASP Secure Coding Practices**
