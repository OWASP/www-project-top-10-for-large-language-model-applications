## رسالة من قادة المشروع

بدأ مشروع أواسب لأهم 10 مخاطر في تطبيقات النماذج اللغوية الكبيرة في عام 2023 كمبادرة يقودها المجتمع لتسليط الضوء على مشكلات الأمان الخاصة بتطبيقات الذكاء الاصطناعي ومعالجتها. ومنذ ذلك الحين، استمرت هذه التقنية في الانتشار عبر مختلف الصناعات والتطبيقات، وكذلك ازدادت المخاطر المرتبطة بها. ومع تكامل النماذج اللغوية الكبيرة بشكل أعمق في كل شيء، من تفاعلات العملاء إلى العمليات الداخلية، بدأ المطورون ومتخصصو الأمن في اكتشاف ثغرات جديدة وطرق لمعالجتها.

كانت قائمة عام 2023 ناجحة في رفع مستوى الوعي وبناء أساس لاستخدام آمن للنماذج اللغوية الكبيرة، لكننا تعلمنا المزيد منذ ذلك الحين. في إصدار 2025 الجديد هذا، عملنا مع مجموعة أكبر وأكثر تنوعًا من المساهمين من جميع أنحاء العالم، ساهموا جميعًا في تشكيل هذه القائمة. شمل هذا العمل جلسات عصف ذهني، وتصويتات، وتعليقات من الواقع العملي قدمها متخصصون في أمن تطبيقات النماذج اللغوية، سواء من خلال المساهمة أو تحسين الإدخالات استنادًا إلى الملاحظات. كانت كل مساهمة ضرورية لجعل هذا الإصدار الجديد شاملًا وعمليًا قدر الإمكان.

### ما الجديد في قائمة 2025 لأهم 10 مخاطر

تعكس قائمة 2025 فهمًا أعمق للمخاطر الحالية وتقدم تحديثات مهمة حول كيفية استخدام النماذج اللغوية الكبيرة في التطبيقات الواقعية اليوم. على سبيل المثال، توسعت فئة **الاستهلاك غير المحدود** عما كان يُعرف سابقًا بـ "نفي الخدمة" لتشمل المخاطر المتعلقة بإدارة الموارد والتكاليف غير المتوقعة، وهي مسألة ملحّة في عمليات النشر الواسعة للنماذج اللغوية.

جاء إدخال **المتجهات والتضمين** استجابةً لطلب المجتمع تقديم إرشادات حول تأمين أساليب "التوليد المعزز بالاسترجاع (RAG)" وطرق التضمين الأخرى، والتي أصبحت ممارسات أساسية لتأصيل مخرجات النماذج.

أضفنا أيضًا فئة **تسريب التعليمات النظامية** لمعالجة منطقة ظهرت فيها استغلالات واقعية، وكانت من أكثر المواضيع طلبًا من قبل المجتمع. افترضت العديد من التطبيقات أن التعليمات محفوظة بشكل آمن، لكن الحوادث الأخيرة أظهرت أن المطورين لا يمكنهم الاعتماد على بقاء هذه المعلومات سرية.

تم توسيع فئة **الاستقلالية المفرطة** نظرًا للاستخدام المتزايد للهياكل التي تمنح النموذج مزيدًا من الاستقلالية. ومع تصرف النماذج اللغوية كعوامل أو ضمن بيئات إضافية (Plug-ins)، يمكن أن تؤدي الأذونات غير المضبوطة إلى سلوكيات غير مقصودة أو محفوفة بالمخاطر، مما يجعل هذه الفئة أكثر أهمية من أي وقت مضى.

### المضي قدمًا

مثلها مثل التكنولوجيا نفسها، هذه القائمة هي نتاج رؤى وخبرات مجتمع المصادر المفتوحة. تم تشكيلها من خلال مساهمات من مطورين، وعلماء بيانات، وخبراء أمن من مختلف القطاعات، جميعهم ملتزمون ببناء تطبيقات ذكاء اصطناعي أكثر أمانًا. نحن فخورون بمشاركة إصدار 2025 هذا معكم، ونأمل أن يزودكم بالأدوات والمعرفة اللازمة لتأمين استخدام النماذج اللغوية الكبيرة بفعالية.

شكرًا لكل من ساهم في إنجاز هذا العمل، ولكل من يواصل استخدامه وتحسينه. نحن ممتنون لكوننا جزءًا من هذا الجهد معكم.

#### ستيف ويلسون  
قائد المشروع  
أواسب لأهم 10 مخاطر في تطبيقات النماذج اللغوية الكبيرة  
لينكدإن: https://www.linkedin.com/in/wilsonsd

#### آدز دوسون  
القائد التقني وقائد إدخالات الثغرات  
أواسب لأهم 10 مخاطر في تطبيقات النماذج اللغوية الكبيرة  
لينكدإن: https://www.linkedin.com/in/adamdawson0

### فريق الترجمة العربية  
#### ليث رستناوي
لينكدإن: https://www.linkedin.com/in/laith-rastanawi

#### عمر العقاد
لينكدإن: https://www.linkedin.com/in/omar-a-994238200


### حول هذه الترجمة  
نظرًا للطبيعة التقنية والحساسة لقائمة أواسب لأهم 10 مخاطر في تطبيقات النماذج اللغوية الكبيرة، فقد اخترنا عمدًا الاعتماد على مترجمين بشريين فقط في إعداد هذه الترجمة. يتمتع المترجمون المدرجون أعلاه بمعرفة تقنية عميقة بالمحتوى الأصلي، إلى جانب الطلاقة اللغوية اللازمة لإنجاح هذه الترجمة.

#### تالِش سيبارسان  
قائد الترجمة
أواسب لأهم 10 مخاطر في تطبيقات النماذج اللغوية الكبيرة
لينكدإن: https://www.linkedin.com/in/talesh
