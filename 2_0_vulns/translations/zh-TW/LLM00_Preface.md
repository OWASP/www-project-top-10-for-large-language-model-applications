## 專案負責團隊的信

「OWASP 大型語言模型應用 Top 10」自 2023 年起，即以社群驅動的方式著手突顯並解決 AI 應用中特有的安全議題。隨著這項技術不斷拓展至各行各業與各種應用中，其伴隨的風險也同步增加。如今，大型語言模型 (LLM) 已從顧客互動到內部營運的各方面都已有深度的應用，開發者與資安專家也不斷發現新的弱點及相對應的防範策略。

2023 年的名單在提升安全意識並奠定安全使用 LLM 的基礎方面取得了不小的成就，但自那之後，我們又學到了更多。在全新的 2025 年版本中，我們與更多元且更廣泛的全球貢獻者合作，透過腦力激盪、投票，以及吸收來自實務環境中專業人士的回饋和意見，進行了項目的更新與修正。在這之中，每位貢獻者的聲音都相當重要，也使本次更新更為完整、實用。

### 2025 年新版的焦點

2025 年的名單更清晰地呈現了對現有風險更加深層的理解，同時也針對 LLM 在真實世界中在應用層面所面臨的最新挑戰進行關鍵更新。舉例來說，**無上限消耗 (Unbounded Consumption)** 一條在前版本原屬於「阻斷服務 (Denial of Service)」的議題上，現已擴大範疇並將資源管理及意外成本風險納入，對於大規模佈署 LLM 的環境尤其迫切。

**向量與嵌入 (Vector and Embeddings)** 項目則回應社群對於強化檢索增強式生成 (RAG) 及其他嵌入技術上安全性建議的呼聲，因為這些方法如今已成為確保模型輸出更為實務化的核心技術。

我們也新增了**系統提示洩漏 (System Prompt Leakage)** 項目，以反應社群在真實世界中看到高度重複發生的實際案例。許多應用原以為系統提示 (Prompt) 內容能安全隔離，但近期事件顯示，開發者不應輕易假設提示中的資訊能夠被完整的保護。

**過度授權 (Excessive Agency)** 亦已擴充，呼應現在愈發普及的代理人 (Agentic) 架構在 LLM 應用中的使用。當 LLM 作為代理或透過外掛進行作業時，若未妥善限制和確認其授權，便可能帶來意料之外或高風險的行為，因此此項目比以往更為重要。

**展望未來**

如同技術本身的進化，這份名單的產出依舊仰賴開源社群的見解與實務經驗，來自各行各業的開發者、資料科學家與資安專家的貢獻，皆以共同建立更安全的 AI 應用為目標。我們很榮幸能在此與您分享 2025 年版的名單，並期望這份資料能為您提供更有效保障 LLM 安全的工具與知識。

感謝所有為此專案付出心力的人，以及所有持續使用並改進這份名單的成員。我們深感榮幸能與您一起推進這個專案。


###@ Steve Wilson
專案負責人
OWASP 大型語言模型應用 Top 10
LinkedIn: https://www.linkedin.com/in/wilsonsd/

###@ Ads Dawson
技術負責人與弱點項目負責人
OWASP 大型語言模型應用 Top 10

=======

### 繁體中文翻譯團隊
###@ Henry Hu 
Tranditional Chinese Translation Group / Group Leader
LinkedIn: https://www.linkedin.com/in/ninedter/

###@ Will Huang 
Tranditional Chinese Translation Group / Reviewer
LinkedIn: https://www.linkedin.com/in/will-huang-tw/

###@ Yingzi Jin
Tranditional Chinese Translation Group / Reviewer
LinkedIn: https://www.linkedin.com/in/yingzi-j-77606122a/

### 關於本次翻譯

有鑑於大型語言模型應用程式 (LLM Applications) 前十大風險的高度技術性與關鍵性，我們特別選擇完全由人工翻譯進行此版本的製作。上述列出的翻譯人員不僅對原始內容擁有深厚的技術理解，更具備相應的語言流暢度，以確保本次翻譯的品質與成功。

###@ Talesh Seeparsan
Translation Lead, OWASP Top 10 for AI Applications LLM
LinkedIn: https://www.linkedin.com/in/talesh/
>>>>>>> 9b608f2680bc3c4dae194787bda2ffec45c729f5
