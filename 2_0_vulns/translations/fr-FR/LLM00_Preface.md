## Letter from the Project Leads

Le OWASP Top 10 for Large Language Model Application (LLM) a vu le jour en 2023 dans le cadre d’un effort communautaire visant à mettre en évidence et traiter les problèmes de sécurité spécifiques aux dispositifs de l’IA. Depuis, la technologie a continué à proliférer dans divers secteurs et applications, tout comme les risques qui y sont associés. Au fur et à mesure de l’intégration de LLM de plus en plus avancé dans tous les domaines — des interactions avec la clientèle aux processus internes — les équipes de développement et les spécialistes en sécurité découvrent de nouvelles vulnérabilités et les moyens d’en contrer l’exploitation.

La liste de 2023 a été un réel succès, favorisant la sensibilisation et établissant une base solide pour un usage sécurisé des LLM. Mais nous en approfondissons encore plus notre compréhension depuis. Dans cette nouvelle version de 2025, nous avons travaillé avec un groupe élargi, avec des contributions plus diversifiées, à travers le monde, qui ont grandement aidé à la façonner. Le processus a impliqué des séances de réflexions, des votes et des retours d’expériences professionnelles concrètes, de personnes directement impliquées dans la sécurisation des applications LLM, que ce soit en contribuant ou en affinant les entrées par leurs commentaires. Chaque voix a été essentielle pour rendre cette nouvelle édition aussi exhaustive et pratique que possible.


### Quoi de neuf dans le Top 10 2025 ?

La liste de 2025 reflète une meilleure compréhension des risques existants et intègre des mises à jour critiques quant à l'usage effectif des modèles de langage (LLM) dans les applications d'aujourd'hui. Par exemple, **Consommation Illimitée** élargit ce qui était auparavant Déni de Service afin de prendre en compte les risques liés à la gestion des ressources et aux coûts imprévus: un enjeu majeur dans les déploiements à grande échelle de LLM.

L’entrée **vecteurs et représentations vectorielles** répond aux demandes de la communauté pour des directives relatives à la sécurisation des processus de Génération augmentée par récupération (RAG), et autres méthodes basées sur les intégrations, qui sont désormais des pratiques courantes afin d’assurer un ancrage contextuel des sorties de modèles.

Nous avons également ajouté **Fuite de requête système** pour traiter ce sujet de vulnérabilités avérées, largement sollicité par la communauté. De nombreuses applications présument les invites de requêtes protégées par un isolement sécurisé mais des incidents récents ont montré que les développeurs ne peuvent pas tenir pour acquis que les informations transmises dans ces requêtes restent secrètes.

**Agentivité excessive** a été élargie en raison de l'utilisation croissante d'architectures agentiques qui peuvent donner plus d'autonomie au LLM. Lorsqu'ils agissent à titre d'agents ou configurateur de paramètres de plugiciels, les permissions non contrôlées peuvent entraîner des actions involontaires ou exposées à des risques, rendant cette entrée plus critique que jamais.
 
### Surmonter les obstacles

Like the technology itself, this list is a product of the open-source community’s insights and experiences. It has been shaped by contributions from developers, data scientists, and security experts across sectors, all committed to building safer AI applications. We’re proud to share this 2025 version with you, and we hope it provides you with the tools and knowledge to secure LLMs effectively.

Thank you to everyone who helped bring this together and those who continue to use and improve it. We’re grateful to be part of this work with you.


#### Steve Wilson
Project Lead
OWASP Top 10 for Large Language Model Applications
LinkedIn: https://www.linkedin.com/in/wilsonsd/

#### Ads Dawson
Technical Lead & Vulnerability Entries Lead
OWASP Top 10 for Large Language Model Applications
LinkedIn: https://www.linkedin.com/in/adamdawson0/
