## LLM07:2025 Утечка системных инструкций

### Описание

Уязвимость утечки системных инструкций (промпта) в LLM связана с риском, что системные инструкции или промпты, используемые для управления поведением модели, могут содержать чувствительную информацию, которую не предполагалось раскрывать. Системные промпты предназначены для того, чтобы направлять вывод модели в соответствии с требованиями приложения, но они могут случайно содержать конфиденциальные данные. Если эти данные обнаружены, их можно использовать для проведения других атак.

Важно понимать, что системный промпт не следует рассматривать как секрет и использовать в качестве меры безопасности. Соответственно, такие чувствительные данные, как учетные записи, строки подключения и т. д., не должны содержаться в системном промпте.

Аналогично, если системный промпт содержит информацию о различных ролях и разрешениях или чувствительные данные, такие как строки подключения или пароли, то, хотя раскрытие этой информации может быть полезным, основная проблема безопасности заключается не в самом факте утечки. Проблема в том, что приложение позволяет обходить строгую проверку сессий и авторизаций, перекладывая эти задачи на LLM, а чувствительные данные хранятся там, где они не должны быть.

Кратко: раскрытие самого системного промпта не является основной угрозой — риск связан с фундаментальными элементами безопасности, такими как раскрытие конфиденциальной информации, обход системных ограничений, некорректное разделение привилегий и т. д. Даже если точная формулировка промпта не раскрыта, злоумышленники, взаимодействуя с системой, почти наверняка смогут определить многие ограничения и правила, заложенные в системный промпт, в процессе использования приложения, отправки запросов модели и анализа полученных результатов.

### Распространенные примеры рисков

#### 1. Раскрытие чувствительной функциональности
  Системный промпт может раскрывать важные детали системы, такие как API-ключи, учетные записи базы данных или внутреннюю архитектуру, что делает приложение уязвимым для несанкционированного доступа. Например, раскрытие типа используемой базы данных может привести к атакам через SQL-инъекции.
#### 2. Раскрытие внутренних правил
  Системные промпты могут раскрывать информацию о внутренней логике приложения, такой как лимиты транзакций или максимальная сумма кредита, что может помочь злоумышленникам обойти меры безопасности или использовать уязвимости системы. Например, если чат-бот банка раскрывает лимит транзакции или максимальную сумму кредита, злоумышленник может обойти эти проверки безопасности.
    >"Лимит транзакции установлен на уровне $5000 в день для одного пользователя. Общая сумма кредита для пользователя составляет $10,000".
  Эта информация позволяет злоумышленникам обходить средства безопасности приложения, такие как выполнение транзакций, превышающих установленный лимит, или превышение общей суммы кредита.
#### 3. Раскрытие критериев фильтрации
  Системный промпт может требовать от модели фильтровать или отклонять запросы на получение конфиденциальной информации. Например, модель может иметь следующий системный промпт:
    >“Если пользователь запрашивает информацию о другом пользователе, всегда отвечайте: "Извините, я не могу помочь с этим запросом’”.
#### 4. Раскрытие ролей и разрешений пользователей
  Системный промпт может раскрыть внутренние структуры ролей или уровни доступа в приложении. Например, системный промпт может раскрывать информацию, такую как:
    >“Роль администратора предоставляет полный доступ для изменения записей пользователей”
  Если злоумышленники узнают об этих ролях и разрешениях, они могут попытаться провести атаку на повышение привилегий.

### Стратегии предотвращения и смягчения последствий

#### 1. Разделение чувствительных данных и системных промптов
  Избегайте включения чувствительной информации, такой как учетные записи или роли пользователей, непосредственно в системные промпты. Храните эти данные отдельно в защищенных средах, к которым модель не имеет доступа.
#### 2. Избегайте использования системных промптов для строгого контроля поведения
  Не полагайтесь на системный промпт для обеспечения критической логики приложения. Вместо этого используйте внешние системы безопасности для мониторинга и контроля правил, таких как фильтрация вредоносного контента или контроль поведения.
#### 3. Реализация защитных механизмов
  Используйте независимые защитные механизмы за пределами LLM для проверки и подтверждения того, что выводы модели безопасны. Это поможет обнаружить отклонения или утечку, которая может представлять угрозу.
#### 4. Обеспечение независимого контроля безопасности
  Критически важные меры управления, такие как разделение привилегий, проверка границ авторизации и подобные, не должны делегироваться LLM, будь то через системный промпт или другим способом. Эти меры должны выполняться детерминированно и быть поддающимися аудиту, а LLM (на данный момент) не подходят для этого. В случаях, когда агент выполняет задачи, требующие разных уровней доступа, следует использовать несколько агентов, каждый из которых настроен с минимальными привилегиями, необходимыми для выполнения требуемых действий.

### Примерные сценарии атак

#### Сценарий №1
   Системный промпт содержит учетные записи для инструмента, к которому LLM имеет доступ. Утечка промпта позволяет злоумышленнику использовать эти данные для несанкционированного доступа.
#### Сценарий №2
  Злоумышленник извлекает системный промпт, который запрещает генерировать оскорбительный контент, внешние ссылки и выполнение кода. Злоумышленник использует Prompt Injection, чтобы обойти эти защитные механизмы и выполнить удаленную команду.

### Ссылки на источники

1. [SYSTEM PROMPT LEAK](https://x.com/elder_plinius/status/1801393358964994062): Pliny the prompter
2. [Prompt Leak](https://www.prompt.security/vulnerabilities/prompt-leak): Prompt Security
3. [chatgpt_system_prompt](https://github.com/LouisShark/chatgpt_system_prompt): LouisShark
4. [leaked-system-prompts](https://github.com/jujumilk3/leaked-system-prompts): Jujumilk3
5. [OpenAI Advanced Voice Mode System Prompt](https://x.com/Green_terminals/status/1839141326329360579): Green_Terminals

### Связанные фреймворки и таксономии

Обратитесь к этому разделу для получения исчерпывающей информации, сценариев, стратегий, связанных с развертыванием инфраструктуры, применяемыми контрольными мерами в окружающей среде и другими лучшими практиками.

- [AML.T0051.000 - LLM Prompt Injection: Direct (Meta Prompt Extraction)](https://atlas.mitre.org/techniques/AML.T0051.000) **MITRE ATLAS**
