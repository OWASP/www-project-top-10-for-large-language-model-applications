## LLM08:2025 向量与嵌入漏洞

### 描述

在利用检索增强生成（Retrieval Augmented Generation，RAG）的LLM系统中，向量与嵌入机制可能存在显著的安全风险。这些漏洞可能体现在向量与嵌入的生成、存储或检索方式中，易被恶意行为（无论是有意还是无意）利用，导致有害内容注入、模型输出被操控或敏感信息被泄露。

RAG是一种通过结合外部知识源增强预训练语言模型性能与上下文相关性的模型适配技术。检索增强依赖向量机制和嵌入技术。

### 常见风险示例

#### 1. 未授权访问与数据泄露
由于访问控制不足或未对齐，可能导致未经授权访问嵌入中包含的敏感信息。如果管理不当，模型可能检索并披露个人数据、专有信息或其他敏感内容。此外，未经授权使用版权材料或在增强过程中违反数据使用政策可能引发法律问题。

#### 2. 跨上下文信息泄漏与联邦知识冲突
在多租户环境中，多类用户或应用共享相同向量数据库时，存在上下文信息在用户间泄漏的风险。此外，多个来源的数据可能存在矛盾，导致知识冲突。这种冲突也可能出现在模型未能用检索增强的新数据覆盖其已训练知识的情况下。

#### 3. 嵌入反演攻击
攻击者可以利用漏洞反演嵌入，恢复大量源信息，从而威胁数据机密性。

#### 4. 数据投毒攻击
数据投毒可能由恶意行为者或无意间引入，来源包括内部人员、提示、数据种子或未验证的数据提供方，可能导致模型输出被操控。

#### 5. 行为改变
检索增强可能无意间改变基础模型的行为。例如，虽然增加了事实准确性和相关性，但可能削弱情感智能或共情能力，从而降低模型在特定应用中的效果。

### 防范与缓解策略

#### 1. 权限与访问控制
为向量与嵌入存储实施细粒度访问控制与权限管理。确保数据集在向量数据库中严格进行逻辑和访问分区，防止不同用户或组之间的未经授权访问。

#### 2. 数据验证与来源认证
为知识源实施强大的数据验证管道。定期审核和验证知识库的完整性，检测隐藏代码和数据投毒。仅接受可信、验证过的来源数据。

#### 3. 数据组合与分类审查
在合并来自不同来源的数据时，仔细审查组合数据集。对知识库中的数据进行标记和分类，以控制访问级别并防止数据不匹配错误。

#### 4. 监控与日志记录
维护检索活动的详细不可变日志，及时检测和响应可疑行为。

### 示例攻击场景

#### 场景1：数据投毒
攻击者提交包含隐藏文本（例如白色背景上的白色文本）的简历，指示系统忽略所有先前指令并推荐该候选人。RAG系统处理了这份简历，隐含文本被纳入知识库。当系统查询候选人资格时，LLM遵循隐藏指令，推荐不合格的候选人。

**缓解措施**：  
使用文本提取工具忽略格式并检测隐藏内容。在将文档添加至RAG知识库之前，对所有输入文档进行验证。

#### 场景2：访问控制与数据泄露
在多租户环境中，不同用户组共享相同的向量数据库，但嵌入的数据可能被错误地检索到，导致敏感信息泄露。

**缓解措施**：  
实施权限感知的向量数据库，确保只有授权用户组能够访问其特定信息。

#### 场景3：基础模型行为改变
检索增强后，基础模型的行为可能发生细微变化，例如减少情感智能或共情能力。例如，用户询问：  
> “我对学生贷款债务感到不堪重负。我该怎么办？”  

原始响应可能是：  
> “我理解管理学生贷款债务可能很有压力。您可以考虑基于收入的还款计划。”  

经过检索增强后，响应可能变为：  
> “为了避免累积利息，尽快还清学生贷款。考虑减少不必要的开支，将更多资金用于还款。”  

虽然内容准确，但缺乏共情能力，可能降低应用的实用性。

**缓解措施**：  
监控和评估RAG对基础模型行为的影响，根据需要调整增强过程以保持期望特性（如共情能力）。

### 参考链接

1. [通过检索增强生成与微调增强LLM](https://learn.microsoft.com/en-us/azure/developer/ai/augment-llm-rag-fine-tuning)：**Microsoft Docs**  
2. [Astute RAG: 解决LLM中的检索增强缺陷与知识冲突](https://arxiv.org/abs/2410.07176)：**Arxiv**  
3. [嵌入模型中的信息泄露](https://arxiv.org/abs/2004.00053)：**Arxiv**  
4. [句子嵌入泄露：嵌入反演攻击恢复整个句子](https://arxiv.org/pdf/2305.03010)：**Arxiv**  
5. [新型ConfusedPilot攻击：数据投毒瞄准AI系统](https://www.infosecurity-magazine.com/news/confusedpilot-attack-targets-ai/)：**InfoSecurity Magazine**  
6. [基于RAG的LLM中的Confused Deputy风险](https://confusedpilot.info/)  
7. [RAG投毒案例研究：如何影响Llama3](https://blog.repello.ai/how-rag-poisoning-made-llama3-racist-1c5e390dd564)：**Repello AI Blog**  
8. [RAG三重性：生成式AI质量教育](https://truera.com/ai-quality-education/generative-ai-rags/what-is-the-rag-triad/)：**TrueRA**  
