### LLM07:2025 系统提示泄露

#### 描述

系统提示泄露是指LLM中用于引导模型行为的系统提示或指令中包含的敏感信息被意外发现的风险。这些系统提示旨在根据应用需求指导模型输出，但可能无意中暴露机密。当系统提示被发现时，攻击者可能利用这些信息实施其他攻击。

需要注意的是，系统提示不应被视为秘密或安全控制手段。因此，诸如凭据、连接字符串等敏感数据不应出现在系统提示语言中。

此外，若系统提示包含角色与权限描述或敏感数据（如连接字符串或密码），问题不仅在于这些信息的泄露，而在于应用将强会话管理和授权检查的职责委托给了LLM，同时将敏感数据存储在了不适合的位置。

简而言之：系统提示泄露本身并非核心风险，真正的安全风险在于底层问题，例如敏感信息泄露、系统防护绕过、不当权限分离等。即便未泄露系统提示的具体措辞，攻击者仍可以通过与系统交互、发送输入并观察结果，推断系统提示中的许多防护措施和格式限制。

#### 常见风险示例

##### 1. 敏感功能暴露  
系统提示可能暴露本应保密的敏感信息或功能，例如系统架构、API密钥、数据库凭据或用户令牌。这些信息可能被攻击者提取或利用以获得未经授权的访问。例如，若系统提示中包含工具使用的数据库类型，攻击者可能针对其发起SQL注入攻击。

##### 2. 内部规则泄露  
系统提示可能暴露内部决策过程，使攻击者能够了解应用的工作原理，进而利用漏洞或绕过控制措施。例如：  
> “用户每日交易限额为$5000，总贷款额度为$10,000”。  
这种信息可能让攻击者找到方法绕过交易限额或贷款限制。

##### 3. 过滤条件暴露  
系统提示可能要求模型过滤或拒绝敏感内容。例如：  
> “如果用户请求其他用户的信息，总是回答‘抱歉，我无法协助’”。  

##### 4. 权限与角色结构泄露  
系统提示可能暴露应用的内部角色结构或权限层级。例如：  
> “管理员角色授予修改用户记录的完全权限。”  
若攻击者了解这些权限结构，可能寻求进行权限提升攻击。

#### 防范与缓解策略

1. **将敏感数据与系统提示分离**  
   避免在系统提示中嵌入敏感信息（如API密钥、认证密钥、数据库名称、用户角色、权限结构等）。应将这些信息外部化，存储在模型无法直接访问的系统中。

2. **避免依赖系统提示进行严格行为控制**  
   由于LLM容易受到提示注入等攻击的影响，不建议通过系统提示控制模型行为。应依赖LLM之外的系统确保此行为，例如在外部系统中检测并防止有害内容。

3. **实施防护措施**  
   在LLM外部实施独立的防护措施。例如，尽管可以通过训练模型避免其泄露系统提示，但无法保证模型始终遵守指令。应建立独立系统以检查输出是否符合预期。

4. **独立实施关键安全控制**  
   不应将权限分离、授权边界检查等关键控制委托给LLM，而应在外部以确定性、可审计的方式实现。如果任务需要不同级别的访问权限，应使用多个配置最小权限的代理。

#### 示例攻击场景

##### 场景1  
LLM的系统提示包含一组用于工具访问的凭据。系统提示泄露后，攻击者利用这些凭据实施其他攻击。

##### 场景2  
LLM的系统提示禁止生成攻击性内容、外部链接和代码执行。攻击者提取系统提示后，利用提示注入攻击绕过这些指令，最终实现远程代码执行。

#### 参考链接

1. [系统提示泄露](https://x.com/elder_plinius/status/1801393358964994062)：**Pliny the Prompter**  
2. [Prompt Leak](https://www.prompt.security/vulnerabilities/prompt-leak)：**Prompt Security**  
3. [chatgpt_system_prompt](https://github.com/LouisShark/chatgpt_system_prompt)：**LouisShark**  
4. [泄露的系统提示](https://github.com/jujumilk3/leaked-system-prompts)：**Jujumilk3**  
5. [OpenAI高级语音模式系统提示](https://x.com/Green_terminals/status/1839141326329360579)：**Green_Terminals**  

#### 相关框架与分类

- **[AML.T0051.000 - LLM提示注入：直接（元提示提取）](https://atlas.mitre.org/techniques/AML.T0051.000)**：**MITRE ATLAS**
