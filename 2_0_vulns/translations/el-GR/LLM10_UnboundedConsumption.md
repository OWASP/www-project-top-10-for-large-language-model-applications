## LLM10:2025 Απεριόριστη Κατανάλωση (Unbounded Consumption)

### Περιγραφή

Η απεριόριστη κατανάλωση αναφέρεται στη διαδικασία κατά την οποία ένα Μεγάλο Γλωσσικό Μοντέλο (LLM) παράγει εξόδους με βάση ερωτήματα ή προτροπές εισόδου. Η εξαγωγή συμπερασμάτων είναι μια κρίσιμη λειτουργία των LLM, που περιλαμβάνει την εφαρμογή των διδαχθέντων προτύπων και γνώσεων για την παραγωγή σχετικών απαντήσεων ή προβλέψεων.

Οι επιθέσεις που αποσκοπούν στη διακοπή της παροχής υπηρεσιών, στην εξάντληση των οικονομικών πόρων του στόχου ή ακόμη και στην κλοπή πνευματικής ιδιοκτησίας μέσω της κλωνοποίησης της συμπεριφοράς ενός μοντέλου εξαρτώνται από μια κοινή κατηγορία τρωτών σημείων ασφαλείας προκειμένου να επιτύχουν. Η απεριόριστη κατανάλωση συμβαίνει όταν μια εφαρμογή μεγάλου γλωσσικού μοντέλου (LLM) επιτρέπει στους χρήστες να διεξάγουν υπερβολικά και ανεξέλεγκτα συμπεράσματα, οδηγώντας σε κινδύνους όπως άρνηση παροχής υπηρεσιών (DoS), οικονομικές απώλειες, κλοπή μοντέλων και υποβάθμιση υπηρεσιών. Οι υψηλές υπολογιστικές απαιτήσεις των LLM, ιδίως σε περιβάλλοντα νέφους, τα καθιστούν ευάλωτα στην εκμετάλλευση πόρων και στη μη εξουσιοδοτημένη χρήση.

### Συνήθη Παραδείγματα Ευπάθειας

#### 1. Κορεσμός εισόδου μεταβλητού μήκους
  Οι επιτιθέμενοι μπορούν να υπερφορτώσουν το LLM με πολυάριθμες εισόδους διαφορετικού μήκους, εκμεταλλευόμενοι την αναποτελεσματικότητα της επεξεργασίας. Αυτό μπορεί να εξαντλήσει τους πόρους και ενδεχομένως να καταστήσει το σύστημα μη ανταποκρινόμενο, επηρεάζοντας σημαντικά τη διαθεσιμότητα των υπηρεσιών.
#### 2. Άρνηση πορτοφολιού (DoW)
  Με την έναρξη μεγάλου όγκου λειτουργιών, οι επιτιθέμενοι εκμεταλλεύονται το μοντέλο κόστους ανά χρήση των υπηρεσιών ΤΝ που βασίζονται στο νέφος, οδηγώντας σε μη βιώσιμες οικονομικές επιβαρύνσεις για τον πάροχο και διακινδυνεύοντας την οικονομική καταστροφή.
#### 3. Συνεχής υπερχείλιση εισόδου
  Η συνεχής αποστολή εισροών που υπερβαίνουν το παράθυρο περιεχομένου του LLM μπορεί να οδηγήσει σε υπερβολική χρήση υπολογιστικών πόρων, με αποτέλεσμα την υποβάθμιση των υπηρεσιών και τη διακοπή της λειτουργίας.
#### 4. Ερωτήματα απαιτητικά σε πόρους
  Η υποβολή ασυνήθιστα απαιτητικών ερωτημάτων που περιλαμβάνουν πολύπλοκες ακολουθίες ή περίπλοκα γλωσσικά μοτίβα μπορεί να εξαντλήσει τους πόρους του συστήματος, οδηγώντας σε παρατεταμένους χρόνους επεξεργασίας και πιθανές αποτυχίες του συστήματος.
#### 5. Εξαγωγή μοντέλου μέσω API
  Οι επιτιθέμενοι μπορεί να κάνουν ερωτήματα στο API του μοντέλου χρησιμοποιώντας ειδικά διαμορφωμένες εισόδους και τεχνικές prompt injection για να συλλέξουν επαρκείς εξόδους ώστε να αναπαράγουν ένα μερικό μοντέλο ή να δημιουργήσουν ένα σκιώδες μοντέλο. Αυτό δεν ενέχει μόνο κινδύνους κλοπής πνευματικής ιδιοκτησίας αλλά υπονομεύει επίσης την ακεραιότητα του αρχικού μοντέλου.
#### 6. Αντιγραφή λειτουργίας μοντέλου
  Η χρήση του μοντέλου-στόχου για τη δημιουργία συνθετικών δεδομένων εκπαίδευσης μπορεί να επιτρέψει στους επιτιθέμενους να τελειοποιήσουν ένα άλλο θεμελιώδες μοντέλο, δημιουργώντας ένα λειτουργικό ισοδύναμο. Αυτό παρακάμπτει τις παραδοσιακές μεθόδους εξαγωγής βάσει ερωτημάτων, θέτοντας σημαντικούς κινδύνους για τα μοντέλα και τις τεχνολογίες αποκλειστικής ιδιοκτησίας.
#### 7. Επιθέσεις πλευρικού καναλιού
  Οι κακόβουλοι επιτιθέμενοι μπορούν να εκμεταλλευτούν τις τεχνικές φιλτραρίσματος εισόδου του LLM για να εκτελέσουν επιθέσεις πλευρικού καναλιού, συλλέγοντας βάρη μοντέλων και πληροφορίες αρχιτεκτονικής. Αυτό θα μπορούσε να θέσει σε κίνδυνο την ασφάλεια του μοντέλου και να οδηγήσει σε περαιτέρω εκμετάλλευση.

### Στρατηγικές Πρόληψης και Αντιμετώπισης

#### 1. Επικύρωση εισόδου
  Εφαρμόστε αυστηρή επικύρωση εισόδου για να διασφαλίσετε ότι οι είσοδοι δεν υπερβαίνουν τα λογικά όρια μεγέθους.
#### 2. Περιορισμός της έκθεσης των Logits και Logprobs
  Περιορίστε ή αποκρύψτε την έκθεση των `logit_bias` και `logprobs` στις αποκρίσεις API. Παρέχετε μόνο τις απαραίτητες πληροφορίες χωρίς να αποκαλύπτετε λεπτομερείς πιθανότητες.
#### 3. Περιορισμός ρυθμού χρήσης
  Εφαρμόστε περιορισμό ρυθμού χρήσης και ποσοστώσεις χρηστών για να περιορίσετε τον αριθμό των αιτήσεων που μπορεί να κάνει μια μεμονωμένη πηγαία οντότητα σε μια δεδομένη χρονική περίοδο.
#### 4. Διαχείριση κατανομής πόρων
  Παρακολουθήστε και διαχειριστείτε δυναμικά την κατανομή των πόρων για να αποτρέψετε την υπερβολική κατανάλωση πόρων από κάθε μεμονωμένο χρήστη ή αίτηση.
#### 5. Χρονοδιακόπτες και περιορισμός χρόνου
  Ορίστε χρονικά όρια και περιορίστε την επεξεργασία για λειτουργίες με υψηλή χρήση πόρων για να αποτρέψετε την παρατεταμένη κατανάλωση πόρων.
#### 6. Τεχνικές Sandbox
  Περιορίστε την πρόσβαση του LLM σε πόρους δικτύου, εσωτερικές υπηρεσίες και API.
  - Αυτό είναι ιδιαίτερα σημαντικό για όλα τα κοινά σενάρια, καθώς περιλαμβάνει κινδύνους και απειλές εκ των έσω. Επιπλέον, ρυθμίζει την έκταση της πρόσβασης που έχει η εφαρμογή LLM σε δεδομένα και πόρους, αποτελώντας έτσι έναν κρίσιμο μηχανισμό ελέγχου για τον μετριασμό ή την αποτροπή επιθέσεων πλευρικού καναλιού.
#### 7. Ολοκληρωμένη καταγραφή, παρακολούθηση και ανίχνευση ανωμαλιών
  Συνεχής παρακολούθηση της χρήσης των πόρων και εφαρμογή της καταγραφής για τον εντοπισμό και την αντιμετώπιση ασυνήθιστων προτύπων κατανάλωσης πόρων.
#### 8. Υδατογράφημα
  Εφαρμογή πλαισίων υδατογραφήματος για την ενσωμάτωση και την ανίχνευση μη εξουσιοδοτημένης χρήσης των αποτελεσμάτων της LLM.
#### 9. Ομαλή υποβάθμιση
  Σχεδιάστε το σύστημα ώστε να υποβαθμίζεται με ασφάλεια κάτω από μεγάλο φορτίο, διατηρώντας τη μερική λειτουργικότητα αντί της πλήρους αποτυχίας.
#### 10. Περιορισμός των ενεργειών σε αναμονή και ομαλή κλιμάκωση
  Εφαρμόστε περιορισμούς σχετικά με τον αριθμό των ενεργειών σε ουρά αναμονής και το σύνολο των ενεργειών, ενσωματώνοντας παράλληλα δυναμική κλιμάκωση και εξισορρόπηση φορτίου για την αντιμετώπιση διαφορετικών απαιτήσεων και τη διασφάλιση σταθερής απόδοσης του συστήματος.
#### 11. Εκπαίδευση ανθεκτικότητας σε αντικείμενα ανταγωνισμού
  Εκπαίδευση μοντέλων για την ανίχνευση και τον μετριασμό ανταγωνιστικών ερωτημάτων και προσπαθειών εξαγωγής.
#### 12. Φιλτράρισμα Glitch Token
  Δημιουργήστε λίστες γνωστών σημείων δυσλειτουργίας και σαρώστε την έξοδο πριν την προσθήκη της στο παράθυρο περιβάλλοντος του μοντέλου.
#### 13. Έλεγχοι πρόσβασης
  Εφαρμογή ισχυρών ελέγχων πρόσβασης, συμπεριλαμβανομένου του ελέγχου πρόσβασης βάσει ρόλων (RBAC) και της αρχής των ελαχίστων προνομίων, για τον περιορισμό της μη εξουσιοδοτημένης πρόσβασης στα αποθετήρια μοντέλων LLM και στα περιβάλλοντα εκπαίδευσης.
#### 14. Κεντρικό αποθετήριο μοντέλων ML
  Χρησιμοποιήστε έναν κεντρικό κατάλογο ή μητρώο μοντέλων ML για τα μοντέλα που χρησιμοποιούνται στην παραγωγή, εξασφαλίζοντας τη σωστή διακυβέρνηση και τον έλεγχο πρόσβασης.
#### 15. Αυτοματοποιημένη ανάπτυξη MLOps
  Εφαρμογή αυτοματοποιημένης ανάπτυξης MLOps με ροές εργασίας διακυβέρνησης, παρακολούθησης και έγκρισης για την αυστηροποίηση των ελέγχων πρόσβασης και ανάπτυξης εντός της υποδομής.

### Παραδείγματα Σεναρίων Επίθεσης

#### Σενάριο #1: Μη ελεγχόμενο μέγεθος εισόδου
  Ένας επιτιθέμενος υποβάλλει μια ασυνήθιστα μεγάλη είσοδο σε μια εφαρμογή LLM που επεξεργάζεται δεδομένα κειμένου, με αποτέλεσμα την υπερβολική χρήση μνήμης και φορτίου CPU, με αποτέλεσμα να καταρρεύσει ενδεχομένως το σύστημα ή να επιβραδυνθεί σημαντικά η υπηρεσία.
#### Σενάριο #2: Επαναλαμβανόμενα αιτήματα
  Ένας επιτιθέμενος διαβιβάζει μεγάλο όγκο αιτημάτων στο LLM API, προκαλώντας υπερβολική κατανάλωση υπολογιστικών πόρων και καθιστώντας την υπηρεσία μη διαθέσιμη στους νόμιμους χρήστες.
#### Σενάριο #3: Ερωτήματα υψηλής χρήσης πόρων
  Ένας επιτιθέμενος κατασκευάζει συγκεκριμένες εισόδους σχεδιασμένες να ενεργοποιούν τις πιο δαπανηρές υπολογιστικά διεργασίες του LLM, οδηγώντας σε παρατεταμένη χρήση της CPU και πιθανή αποτυχία του συστήματος.
#### Σενάριο #4: Άρνηση πορτοφολιού (DoW)
  Ένας επιτιθέμενος δημιουργεί υπερβολικές λειτουργίες για να εκμεταλλευτεί το μοντέλο πληρωμής ανά χρήση των υπηρεσιών ΤΝ που βασίζονται στο νέφος, προκαλώντας μη βιώσιμο κόστος για τον πάροχο υπηρεσιών.
#### Σενάριο #5: Αντιγραφή λειτουργίας μοντέλου
  Ένας εισβολέας χρησιμοποιεί το API του LLM για να δημιουργήσει συνθετικά δεδομένα εκπαίδευσης και να βελτιώσει ένα άλλο μοντέλο, δημιουργώντας ένα λειτουργικό ισοδύναμο και παρακάμπτοντας τους παραδοσιακούς περιορισμούς εξαγωγής μοντέλων.
#### Σενάριο #6: Παράκαμψη του φιλτραρίσματος εισόδου του συστήματος
  Ένας κακόβουλος επιτιθέμενος παρακάμπτει τις τεχνικές φιλτραρίσματος εισόδου και τις προεπιλογές του LLM για να εκτελέσει επίθεση πλευρικού καναλιού και να ανακτήσει πληροφορίες μοντέλου σε έναν τηλεχειριζόμενο πόρο υπό τον έλεγχό του.

### Σύνδεσμοι Αναφοράς

1. [Proof Pudding (CVE-2019-20634)](https://avidml.org/database/avid-2023-v009/) **AVID** (`moohax` & `monoxgas`)
2. [arXiv:2403.06634 Stealing Part of a Production Language Model](https://arxiv.org/abs/2403.06634) **arXiv**
3. [Runaway LLaMA | How Meta's LLaMA NLP model leaked](https://www.deeplearning.ai/the-batch/how-metas-llama-nlp-model-leaked/): **Deep Learning Blog**
4. [You wouldn't download an AI, Extracting AI models from mobile apps](https://altayakkus.substack.com/p/you-wouldnt-download-an-ai): **Substack blog**
5. [A Comprehensive Defense Framework Against Model Extraction Attacks](https://ieeexplore.ieee.org/document/10080996): **IEEE**
6. [Alpaca: A Strong, Replicable Instruction-Following Model](https://crfm.stanford.edu/2023/03/13/alpaca.html): **Stanford Center on Research for Foundation Models (CRFM)**
7. [How Watermarking Can Help Mitigate The Potential Risks Of LLMs?](https://www.kdnuggets.com/2023/03/watermarking-help-mitigate-potential-risks-llms.html): **KD Nuggets**
8. [Securing AI Model Weights Preventing Theft and Misuse of Frontier Models](https://www.rand.org/content/dam/rand/pubs/research_reports/RRA2800/RRA2849-1/RAND_RRA2849-1.pdf)
9. [Sponge Examples: Energy-Latency Attacks on Neural Networks: Arxiv White Paper](https://arxiv.org/abs/2006.03463) **arXiv**
10. [Sourcegraph Security Incident on API Limits Manipulation and DoS Attack](https://about.sourcegraph.com/blog/security-update-august-2023) **Sourcegraph**

### Σχετικά Πλαίσια και Ταξινομήσεις

Ανατρέξτε σε αυτή την ενότητα για αναλυτικές πληροφορίες, στρατηγικές σεναρίων σχετικά με την ανάπτυξη υποδομών, εφαρμοσμένους ελέγχους περιβάλλοντος και άλλες βέλτιστες πρακτικές.

- [MITRE CWE-400: Uncontrolled Resource Consumption](https://cwe.mitre.org/data/definitions/400.html) **MITRE Common Weakness Enumeration**
- [AML.TA0000 ML Model Access: Mitre ATLAS](https://atlas.mitre.org/tactics/AML.TA0000) & [AML.T0024 Exfiltration via ML Inference API](https://atlas.mitre.org/techniques/AML.T0024) **MITRE ATLAS**
- [AML.T0029 - Denial of ML Service](https://atlas.mitre.org/techniques/AML.T0029) **MITRE ATLAS**
- [AML.T0034 - Cost Harvesting](https://atlas.mitre.org/techniques/AML.T0034) **MITRE ATLAS**
- [AML.T0025 - Exfiltration via Cyber Means](https://atlas.mitre.org/techniques/AML.T0025) **MITRE ATLAS**
- [OWASP Machine Learning Security Top Ten - ML05:2023 Model Theft](https://owasp.org/www-project-machine-learning-security-top-10/docs/ML05_2023-Model_Theft.html) **OWASP ML Top 10**
- [API4:2023 - Unrestricted Resource Consumption](https://owasp.org/API-Security/editions/2023/en/0xa4-unrestricted-resource-consumption/) **OWASP Web Application Top 10**
- [OWASP Resource Management](https://owasp.org/www-project-secure-coding-practices-quick-reference-guide/) **OWASP Secure Coding Practices**
