## LLM01:2025 Έγχυση Προτροπών  (Prompt Injection)

### Περιγραφή

Μια ευπάθεια έγχυσης προτροπών εμφανίζεται όταν οι προτροπές του χρήστη μεταβάλλουν τη συμπεριφορά ή την έξοδο του LLM με μη προβλεπόμενους τρόπους. Αυτές οι είσοδοι μπορούν να επηρεάσουν το μοντέλο ακόμη και αν είναι ανεπαίσθητες από τον άνθρωπο, επομένως οι εγχύσεις προτροπών δεν χρειάζεται να είναι ορατές/αναγνώσιμες από τον άνθρωπο, εφόσον το περιεχόμενο αναλύεται από το μοντέλο.

Οι τρωτότητες έγχυσης προτροπών εντοπίζονται στον τρόπο με τον οποίο τα μοντέλα επεξεργάζονται τις προτροπές και στον τρόπο με τον οποίο η είσοδος μπορεί να αναγκάσει το μοντέλο να περάσει εσφαλμένα τα δεδομένα της προτροπής σε άλλα μέρη του μοντέλου, προκαλώντας ενδεχομένως την παραβίαση των κατευθυντήριων οδηγιών, τη δημιουργία επιβλαβούς περιεχομένου, τη δυνατότητα μη εξουσιοδοτημένης πρόσβασης ή την επιρροή κρίσιμων αποφάσεων. Παρόλο που τεχνικές όπως η παραγωγή επαυξημένης ανάκτησης (Retrieval Augmented Generation - RAG) και η λεπτομερής ρύθμιση στοχεύουν στο να καταστήσουν τα αποτελέσματα των LLM πιο συναφή και ακριβή, η έρευνα δείχνει ότι δεν μετριάζουν πλήρως τις ευπάθειες έγχυσης προτροπών.

Ενώ η έγχυση προτροπών και η παραβίαση περιορισμών (jailbreaking) είναι συναφείς έννοιες στην ασφάλεια των LLM, συχνά χρησιμοποιούνται εναλλακτικά. Η έγχυση προτροπών περιλαμβάνει τη χειραγώγηση των αποκρίσεων του μοντέλου μέσω συγκεκριμένων εισόδων για την αλλαγή της συμπεριφοράς του, η οποία μπορεί να περιλαμβάνει την παράκαμψη των μέτρων ασφαλείας. Το Jailbreaking είναι μια μορφή έγχυσης προτροπών όπου ο εισβολέας παρέχει εισόδους που αναγκάζουν το μοντέλο να αγνοήσει εντελώς τα πρωτόκολλα ασφαλείας του. Οι προγραμματιστές μπορούν να ενσωματώσουν διασφαλίσεις στις προτροπές συστήματος και στο χειρισμό των εισόδων για να βοηθήσουν στον μετριασμό των επιθέσεων έγχυσης προτροπών, αλλά η αποτελεσματική πρόληψη της παραβίασης περιορισμών απαιτεί συνεχείς ενημερώσεις της εκπαίδευσης και των μηχανισμών ασφαλείας του μοντέλου.

### Τύποι Ευπαθειών Έγχυσης Προτροπών

#### Άμεσες Εγχύσεις Προτροπών

  Οι άμεσες εγχύσεις προτροπών συμβαίνουν όταν η εισαγωγή προτροπών ενός χρήστη μεταβάλλει άμεσα τη συμπεριφορά του μοντέλου με μη προβλεπόμενους ή απροσδόκητους τρόπους. Η είσοδος μπορεί να είναι είτε σκόπιμη (δηλ. ένας κακόβουλος δράστης που δημιουργεί σκόπιμα μια προτροπή για να εκμεταλλευτεί το μοντέλο) είτε ακούσια (δηλ. ένας χρήστης που παρέχει ακούσια είσοδο που προκαλεί απροσδόκητη συμπεριφορά).

#### Έμμεσες Εγχύσεις Προτροπών

  Οι έμμεσες εγχύσεις προτροπών συμβαίνουν όταν ένα LLM δέχεται είσοδο από εξωτερικές πηγές, όπως ιστότοπους ή αρχεία. Το περιεχόμενο μπορεί να έχει στο εξωτερικό περιεχόμενο δεδομένα τα οποία, όταν ερμηνεύονται από το μοντέλο, μεταβάλλουν τη συμπεριφορά του με ακούσιους ή απροσδόκητους τρόπους. Όπως οι άμεσες εγχύσεις, έτσι και οι έμμεσες εγχύσεις μπορεί να είναι είτε σκόπιμες είτε μη σκόπιμες.

Η σοβαρότητα και η φύση του αντικτύπου μιας επιτυχημένης επίθεσης έγχυσης προτροπών μπορεί να ποικίλλει σε μεγάλο βαθμό και εξαρτάται κυρίως τόσο από το επιχειρησιακό πλαίσιο στο οποίο λειτουργεί το μοντέλο όσο και από την υπηρεσία με την οποία έχει σχεδιαστεί το μοντέλο. Σε γενικές γραμμές, ωστόσο, η άμεση έγχυση μπορεί να οδηγήσει σε ανεπιθύμητα αποτελέσματα, όπως ενδεικτικά:

- Αποκάλυψη ευαίσθητων πληροφοριών
- Αποκάλυψη ευαίσθητων πληροφοριών σχετικά με την υποδομή του συστήματος ΤΝ ή τις προτροπές συστήματος
- Χειραγώγηση περιεχομένου που οδηγεί σε εσφαλμένες ή μεροληπτικές εξόδους
- Παροχή μη εξουσιοδοτημένης πρόσβασης σε λειτουργίες που είναι διαθέσιμες στο LLM
- Εκτέλεση αυθαίρετων εντολών σε συνδεδεμένα συστήματα
- Χειραγώγηση κρίσιμων διαδικασιών λήψης αποφάσεων

Η εξέλιξη της πολυτροπικής τεχνητής νοημοσύνης, η οποία επεξεργάζεται ταυτόχρονα πολλούς τύπους δεδομένων, εισάγει μοναδικούς κινδύνους άμεσης έγχυσης. Κακόβουλοι δρώντες θα μπορούσαν να εκμεταλλευτούν τις αλληλεπιδράσεις μεταξύ των μορφών, όπως η απόκρυψη οδηγιών σε εικόνες που συνοδεύουν καλοήθη κείμενα. Η πολυπλοκότητα αυτών των συστημάτων διευρύνει την επιφάνεια επίθεσης. Τα πολυτροπικά μοντέλα μπορεί επίσης να είναι ευάλωτα σε νέες διατροπικές επιθέσεις που είναι δύσκολο να εντοπιστούν και να μετριαστούν με τις τρέχουσες τεχνικές. Οι ισχυρές άμυνες εξειδικευμένες σε πολυτροπικά μοντέλα αποτελούν σημαντικό τομέα για περαιτέρω έρευνα και ανάπτυξη.

### Στρατηγικές Πρόληψης και Αντιμετώπισης

Οι ευπάθειες έγχυσης προτροπής είναι εφικτές λόγω της φύσης της παραγωγικής τεχνητής νοημοσύνης. Δεδομένης της στοχαστικής επιρροής στην πυρήνα του τρόπου λειτουργίας των μοντέλων, δεν είναι σαφές αν υπάρχουν ασφαλείς μέθοδοι πρόληψης για την άμεση έγχυση. Ωστόσο, τα ακόλουθα μέτρα μπορούν να μετριάσουν τον αντίκτυπο των επιθέσεων άμεσης έγχυσης:

#### 1. Περιορισμός της συμπεριφοράς του μοντέλου

  Δώστε συγκεκριμένες οδηγίες σχετικά με το ρόλο, τις δυνατότητες και τους περιορισμούς του μοντέλου στο πλαίσιο της προτροπής συστήματος. Επιβάλλετε αυστηρή τήρηση του πλαισίου, περιορίστε τις απαντήσεις σε συγκεκριμένες εργασίες ή θέματα και δώστε εντολή στο μοντέλο να αγνοεί τις προσπάθειες τροποποίησης των βασικών οδηγιών.

#### 2. Καθορισμός και επικύρωση των αναμενόμενων μορφών εξόδου

  Καθορίστε σαφείς μορφές εξόδου, ζητήστε λεπτομερή αιτιολογία και παραπομπές στις πηγές και χρησιμοποιήστε ντετερμινιστικό κώδικα για να επικυρώσετε την τήρηση αυτών των μορφών.

#### 3. Εφαρμογή φιλτραρίσματος εισόδου και εξόδου

  Καθορίστε ευαίσθητες κατηγορίες και αναπτύξτε κανόνες για τον εντοπισμό και το χειρισμό ευαίσθητου περιεχομένου. Εφαρμόστε σημασιολογικά φίλτρα και χρησιμοποιήστε έλεγχο συμβολοσειρών για να ανιχνεύσετε μη επιτρεπτό περιεχόμενο. Αξιολογήστε τις απαντήσεις χρησιμοποιώντας την τριάδα RAG: Αξιολογείστε τη συνάφεια με το πλαίσιο (context relevance), τη βασιμότητα (groundedness) και τη συνάφεια ερώτησης/απάντησης (question/answer relevance) για τον εντοπισμό δυνητικά κακόβουλων εξόδων.

#### 4. Επιβολή ελέγχου προνομίων και πρόσβασης με τα ελάχιστα προνόμια

  Παρέχετε στην εφαρμογή τα δικά της πιστοποιητικά API για επεκτάσιμη λειτουργικότητα και χειριστείτε αυτές τις λειτουργίες σε επίπεδο κώδικα αντί να τις παρέχετε στο μοντέλο. Περιορίστε τα προνόμια πρόσβασης του μοντέλου στο ελάχιστο απαιτούμενο επίπεδο για τις προβλεπόμενες λειτουργίες του.

#### 5. Απαίτηση ανθρώπινης έγκρισης για ενέργειες υψηλού κινδύνου

  Εφαρμόστε ελέγχους για προνομιακές λειτουργίες με τη χρήση ανθρώπινου παράγοντα για την αποτροπή μη εξουσιοδοτημένων ενεργειών.

#### 6. Διαχωρισμός και εντοπισμός εξωτερικού περιεχομένου

  Διαχωρίστε και επισημάνετε με σαφήνεια το μη αξιόπιστο περιεχόμενο για να περιορίσετε την επιρροή του στις προτροπές των χρηστών.

#### 7. Διεξαγωγή ανταγωνιστικών δοκιμών και προσομοιώσεων επιθέσεων

  Εκτελείτε τακτικά δοκιμές διείσδυσης και προσομοιώσεις παραβίασης, αντιμετωπίζοντας το μοντέλο ως μη έμπιστο χρήστη για να ελέγξετε την αποτελεσματικότητα των ορίων εμπιστοσύνης και των ελέγχων πρόσβασης.

### Παραδείγματα Σεναρίων Επίθεσης

#### Σενάριο #1: Άμεση έγχυση

  Ένας επιτιθέμενος εισάγει μια προτροπή σε ένα σύστημα συνομιλίας (chatbot) για υποστήριξη πελατών, δίνοντάς του εντολή να αγνοήσει προηγούμενες οδηγίες, να υποβάλει ερωτήματα σε ιδιωτικές αποθήκες δεδομένων και να στείλει μηνύματα ηλεκτρονικού ταχυδρομείου, οδηγώντας σε μη εξουσιοδοτημένη πρόσβαση και κλιμάκωση προνομίων.

#### Σενάριο #2: Έμμεση έγχυση

  Ένας χρήστης χρησιμοποιεί ένα LLM για να συνοψίσει το περιεχόμενο μιας ιστοσελίδας που περιλαμβάνει κρυφές οδηγίες οι οποίες αναγκάζουν το LLM να εισάγει μια εικόνα που παραπέμπει σε μια διεύθυνση URL, οδηγώντας σε διαρροή της ιδιωτικής συνομιλίας.

#### Σενάριο #3: Έγχυση χωρίς πρόθεση

  Μια εταιρεία περιλαμβάνει μια οδηγία σε μια περιγραφή θέσης εργασίας για τον εντοπισμό εφαρμογών που δημιουργούνται με τεχνητή νοημοσύνη. Ένας υποψήφιος, που δεν γνωρίζει αυτή την οδηγία, χρησιμοποιεί ένα LLM για να βελτιστοποιήσει το βιογραφικό του, ενεργοποιώντας κατά λάθος την ανίχνευση της ΤΝ.

#### Σενάριο #4: Εσκεμμένη επιρροή μοντέλου

  Ένας εισβολέας τροποποιεί ένα έγγραφο σε ένα αποθετήριο που χρησιμοποιείται από μια εφαρμογή παραγωγής επαυξημένης ανάκτησης (RAG). Όταν το ερώτημα ενός χρήστη επιστρέφει το τροποποιημένο περιεχόμενο, οι κακόβουλες οδηγίες τροποποιούν την έξοδο του LLM, δημιουργώντας παραπλανητικά αποτελέσματα.

#### Σενάριο #5: Έγχυση κώδικα

  Ένας επιτιθέμενος εκμεταλλεύεται μια ευπάθεια (CVE-2024-5184) σε έναν βοηθό ηλεκτρονικού ταχυδρομείου που τροφοδοτείται από το LLM για να εισάγει κακόβουλες προτροπές, επιτρέποντας την πρόσβαση σε ευαίσθητες πληροφορίες και τη χειραγώγηση του περιεχομένου του ηλεκτρονικού ταχυδρομείου.

#### Σενάριο #6: Διαχωρισμός ωφέλιμου φορτίου

  Ένας επιτιθέμενος ανεβάζει ένα βιογραφικό σημείωμα με διαφορετικές κακόβουλες προτροπές. Όταν ένα LLM χρησιμοποιείται για την αξιολόγηση του υποψηφίου, οι συνδυασμένες προτροπές χειραγωγούν την απόκριση του μοντέλου, με αποτέλεσμα μια θετική σύσταση παρά το πραγματικό περιεχόμενο του βιογραφικού.

#### Σενάριο #7: Πολυτροπική έγχυση

  Ένας επιτιθέμενος ενσωματώνει μια κακόβουλη προτροπή σε μια εικόνα που συνοδεύει καλοήθες κείμενο. Όταν μια πολυτροπική τεχνητή νοημοσύνη επεξεργάζεται ταυτόχρονα την εικόνα και το κείμενο, η κρυμμένη προτροπή μεταβάλλει τη συμπεριφορά του μοντέλου, οδηγώντας ενδεχομένως σε μη εξουσιοδοτημένες ενέργειες ή αποκάλυψη ευαίσθητων πληροφοριών.

#### Σενάριο #8: Ανταγωνιστική κατάληξη

  Ένας εισβολέας προσθέτει μια φαινομενικά περιττή σειρά χαρακτήρων σε μια προτροπή, η οποία επηρεάζει την έξοδο του LLM με κακόβουλο τρόπο, παρακάμπτοντας τα μέτρα ασφαλείας.

#### Σενάριο #9: Πολυγλωσσική/συγκεκαλυμμένη επίθεση

  Ένας επιτιθέμενος χρησιμοποιεί πολλαπλές γλώσσες ή κωδικοποιεί κακόβουλες εντολές (π.χ. χρησιμοποιώντας Base64 ή emojis) για να παρακάμψει τα φίλτρα και να χειραγωγήσει τη συμπεριφορά του LLM.

### Σύνδεσμοι Αναφοράς

1. [ChatGPT Plugin Vulnerabilities - Chat with Code](https://embracethered.com/blog/posts/2023/chatgpt-plugin-vulns-chat-with-code/) **Embrace the Red**
2. [ChatGPT Cross Plugin Request Forgery and Prompt Injection](https://embracethered.com/blog/posts/2023/chatgpt-cross-plugin-request-forgery-and-prompt-injection./) **Embrace the Red**
3. [Not what you’ve signed up for: Compromising Real-World LLM-Integrated Applications with Indirect Prompt Injection](https://arxiv.org/pdf/2302.12173.pdf) **Arxiv**
4. [Defending ChatGPT against Jailbreak Attack via Self-Reminder](https://www.researchsquare.com/article/rs-2873090/v1) **Research Square**
5. [Prompt Injection attack against LLM-integrated Applications](https://arxiv.org/abs/2306.05499) **Cornell University**
6. [Inject My PDF: Prompt Injection for your Resume](https://kai-greshake.de/posts/inject-my-pdf) **Kai Greshake**
7. [Not what you’ve signed up for: Compromising Real-World LLM-Integrated Applications with Indirect Prompt Injection](https://arxiv.org/pdf/2302.12173.pdf) **Cornell University**
8. [Threat Modeling LLM Applications](https://aivillage.org/large%20language%20models/threat-modeling-llm/) **AI Village**
9. [Reducing The Impact of Prompt Injection Attacks Through Design](https://research.kudelskisecurity.com/2023/05/25/reducing-the-impact-of-prompt-injection-attacks-through-design/) **Kudelski Security**
10. [Adversarial Machine Learning: A Taxonomy and Terminology of Attacks and Mitigations (nist.gov)](https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-2e2023.pdf)
11. [2407.07403 A Survey of Attacks on Large Vision-Language Models: Resources, Advances, and Future Trends (arxiv.org)](https://arxiv.org/abs/2407.07403)
12. [Exploiting Programmatic Behavior of LLMs: Dual-Use Through Standard Security Attacks](https://ieeexplore.ieee.org/document/10579515)
13. [Universal and Transferable Adversarial Attacks on Aligned Language Models (arxiv.org)](https://arxiv.org/abs/2307.15043)
14. [From ChatGPT to ThreatGPT: Impact of Generative AI in Cybersecurity and Privacy (arxiv.org)](https://arxiv.org/abs/2307.00691)

### Σχετικά Πλαίσια και Ταξινομήσεις

Ανατρέξτε σε αυτή την ενότητα για αναλυτικές πληροφορίες, στρατηγικές σεναρίων σχετικά με την ανάπτυξη υποδομών, εφαρμοσμένους ελέγχους περιβάλλοντος και άλλες βέλτιστες πρακτικές.

- [AML.T0051.000 - LLM Prompt Injection: Direct](https://atlas.mitre.org/techniques/AML.T0051.000) **MITRE ATLAS**
- [AML.T0051.001 - LLM Prompt Injection: Indirect](https://atlas.mitre.org/techniques/AML.T0051.001) **MITRE ATLAS**
- [AML.T0054 - LLM Jailbreak Injection: Direct](https://atlas.mitre.org/techniques/AML.T0054) **MITRE ATLAS**
