#$ LLM02:2025 Αποκάλυψη Ευαίσθητων  
##  Πληροφοριών (Sensitive Information Disclosure)

### Περιγραφή

Οι ευαίσθητες πληροφορίες μπορούν να επηρεάσουν τόσο τo LLM όσο και το πλαίσιο εφαρμογής του. Αυτό περιλαμβάνει προσωπικά ταυτοποιήσιμες πληροφορίες (PII), οικονομικά στοιχεία, αρχεία υγείας, εμπιστευτικά επιχειρηματικά δεδομένα, διαπιστευτήρια ασφαλείας και νομικά έγγραφα. Τα ιδιόκτητα μοντέλα μπορεί επίσης να έχουν μοναδικές μεθόδους εκπαίδευσης και πηγαίο κώδικα που θεωρούνται ευαίσθητα, ιδίως σε κλειστά ή ιδρυματικά μοντέλα.

Τα LLM, ειδικά όταν ενσωματώνονται σε εφαρμογές, κινδυνεύουν να εκθέσουν ευαίσθητα δεδομένα, ιδιόκτητους αλγορίθμους ή εμπιστευτικές λεπτομέρειες μέσω της εξόδου τους. Αυτό μπορεί να οδηγήσει σε μη εξουσιοδοτημένη πρόσβαση δεδομένων, παραβιάσεις της ιδιωτικότητας και παραβιάσεις της πνευματικής ιδιοκτησίας. Οι χρήστες θα πρέπει να γνωρίζουν πώς να αλληλεπιδρούν με ασφάλεια με τα LLM. Θα πρέπει να κατανοήσουν τους κινδύνους της ακούσιας παροχής ευαίσθητων δεδομένων, τα οποία μπορεί αργότερα να αποκαλυφθούν στην έξοδο του μοντέλου.

Για να μειωθεί αυτός ο κίνδυνος, οι εφαρμογές LLM θα πρέπει να εκτελούν επαρκή εξυγίανση δεδομένων για να αποτρέψουν την είσοδο δεδομένων χρηστών στο μοντέλο εκπαίδευσης. Οι ιδιοκτήτες των εφαρμογών θα πρέπει επίσης να παρέχουν σαφείς πολιτικές όρων χρήσης, επιτρέποντας στους χρήστες να μην παρέχουν συγκατάθεση να συμπεριληφθούν τα δεδομένα τους στο μοντέλο εκπαίδευσης. Η προσθήκη περιορισμών στο πλαίσιο της προτροπής του συστήματος σχετικά με τους τύπους δεδομένων που θα πρέπει να επιστρέφει το LLM μπορεί να προσφέρει μετριασμό κατά της αποκάλυψης ευαίσθητων πληροφοριών. Ωστόσο, αυτοί οι περιορισμοί ενδέχεται να μην τηρούνται πάντα και να μπορούν να παρακαμφθούν μέσω έγχυσης προτροπών ή άλλων μεθόδων.

### Συνήθη Παραδείγματα Ευπάθειας

#### 1. Διαρροή Προσωπικά Ταυτοποιήσιμων Πληροφοριών
  Προσωπικά ταυτοποιήσιμες πληροφορίες (PII) μπορεί να αποκαλυφθούν κατά τη διάρκεια αλληλεπιδράσεων με το LLM.
#### 2. Έκθεση Ιδιόκτητου Αλγορίθμου
  Οι κακώς διαμορφωμένες έξοδοι του μοντέλου μπορούν να αποκαλύψουν ιδιόκτητους αλγορίθμους ή δεδομένα. Η αποκάλυψη δεδομένων εκπαίδευσης μπορεί να εκθέσει τα μοντέλα σε επιθέσεις αντιστροφής, όπου οι επιτιθέμενοι εξάγουν ευαίσθητες πληροφορίες ή ανακατασκευάζουν τις εισόδους. Για παράδειγμα, όπως καταδείχθηκε στην επίθεση «Proof Pudding» (CVE-2019-20634), η αποκάλυψη δεδομένων εκπαίδευσης διευκόλυνε την εξαγωγή και αντιστροφή μοντέλων, επιτρέποντας στους επιτιθέμενους να παρακάμπτουν τους ελέγχους ασφαλείας σε αλγορίθμους μηχανικής μάθησης και να παρακάμπτουν τα φίλτρα ηλεκτρονικού ταχυδρομείου.
#### 3. Αποκάλυψη Ευαίσθητων Επιχειρηματικών Δεδομένων
  Οι παραγόμενες απαντήσεις ενδέχεται να περιλαμβάνουν εκ παραδρομής εμπιστευτικές επιχειρηματικές πληροφορίες.

### Στρατηγικές Πρόληψης και Μετριασμού

#### Εξυγίανση:

#### 1. Ενσωμάτωση Τεχνικών Εξυγίανσης Δεδομένων
  Εφαρμόστε την εξυγίανση δεδομένων για να αποτρέψετε την είσοδο δεδομένων χρηστών στο μοντέλο εκπαίδευσης. Αυτό περιλαμβάνει την εκκαθάριση ή την απόκρυψη ευαίσθητου περιεχομένου πριν από τη χρήση του στην εκπαίδευση.
#### 2. Ισχυρή Επικύρωση Εισόδου
  Εφαρμόστε αυστηρές μεθόδους επικύρωσης εισόδου για τον εντοπισμό και το φιλτράρισμα δυνητικά επιβλαβών ή ευαίσθητων εισόδων δεδομένων, διασφαλίζοντας ότι δεν θέτουν σε κίνδυνο το μοντέλο.

#### Έλεγχοι Πρόσβασης:

#### 1. Επιβολή Αυστηρών Ελέγχων Πρόσβασης
  Περιορίστε την πρόσβαση σε ευαίσθητα δεδομένα με βάση την αρχή των λιγότερων προνομίων. Χορηγήστε πρόσβαση μόνο σε δεδομένα που είναι απαραίτητα για τον συγκεκριμένο χρήστη ή διαδικασία.
#### 2. Περιορισμός των Πηγών Δεδομένων
  Περιορίστε την πρόσβαση του μοντέλου σε εξωτερικές πηγές δεδομένων και διασφαλίστε την ασφαλή διαχείριση της ενορχήστρωσης δεδομένων κατά τη διάρκεια εκτέλεσης για την αποφυγή ακούσιας διαρροής δεδομένων.

#### Ομοσπονδιακή Μάθηση και Τεχνικές Προστασίας της Ιδιωτικότητας:

#### 1. Αξιοποίηση της Ομοσπονδιακής Μάθησης (Federated Learning)
  Εκπαιδεύστε μοντέλα χρησιμοποιώντας αποκεντρωμένα δεδομένα που είναι αποθηκευμένα σε πολλούς διακομιστές ή συσκευές. Αυτή η προσέγγιση ελαχιστοποιεί την ανάγκη για κεντρική συλλογή δεδομένων και μειώνει τους κινδύνους έκθεσης.
#### 2. Ενσωμάτωση Διαφορικής Ιδιωτικότητας
  Εφαρμόστε τεχνικές που προσθέτουν θόρυβο στα δεδομένα ή στις εξόδους, καθιστώντας δύσκολο για τους επιτιθέμενους να αντιστρέψουν την επεξεργασία μεμονωμένων σημείων δεδομένων.

#### Εκπαίδευση Χρηστών και Διαφάνεια:

#### 1. Εκπαίδευση των Χρηστών για την Ασφαλή Χρήση των LLM
  Παροχή οδηγιών για την αποφυγή της εισαγωγής ευαίσθητων πληροφοριών. Προσφέρετε εκπαίδευση σχετικά με τις βέλτιστες πρακτικές για την ασφαλή αλληλεπίδραση με τα LLM.
#### 2. Διασφάλιση Διαφάνειας στη Χρήση Δεδομένων
  Διατηρήστε σαφείς πολιτικές σχετικά με τη διατήρηση, τη χρήση και τη διαγραφή δεδομένων. Να επιτρέπετε στους χρήστες να επιλέγουν να μην συμπεριλαμβάνονται τα δεδομένα τους σε διαδικασίες κατάρτισης.

#### Ασφαλής Διαμόρφωση Συστήματος:

#### 1. Απόκρυψη Προοιμίου Συστήματος
  Περιορίστε τη δυνατότητα των χρηστών να παρακάμπτουν ή να έχουν πρόσβαση στις αρχικές ρυθμίσεις του συστήματος, μειώνοντας τον κίνδυνο έκθεσης σε εσωτερικές ρυθμίσεις.
#### 2. Βέλτιστες Πρακτικές Αποφυγής Λανθασμένων Ρυθμίσεων Ασφαλείας
  Ακολουθήστε οδηγίες όπως το «OWASP API8:2023 Security Misconfiguration» για να αποφύγετε τη διαρροή ευαίσθητων πληροφοριών μέσω μηνυμάτων σφάλματος ή λεπτομερειών διαμόρφωσης.
  (Σύνδεσμος Αναφοράς: [OWASP API8:2023 Security Misconfiguration](https://owasp.org/API-Security/editions/2023/en/0xa8-security-misconfiguration/))

#### Προχωρημένες Τεχνικές:

#### 1. Ομομορφική Κρυπτογράφηση
  Χρησιμοποιήστε ομομορφική κρυπτογράφηση για να επιτρέψετε την ασφαλή ανάλυση δεδομένων και τη μηχανική μάθηση με διατήρηση της ιδιωτικότητας. Αυτό διασφαλίζει ότι τα δεδομένα παραμένουν εμπιστευτικά κατά την επεξεργασία τους από το μοντέλο.
#### 2. Τεχνικές Κωδικοποίησης (Tokenization) και Απόκρυψης (Redaction)
  Εφαρμόστε τη διαδικασία tokenization για την προεπεξεργασία και την εξυγίανση ευαίσθητων πληροφοριών. Τεχνικές όπως η αντιστοίχιση προτύπων μπορούν να ανιχνεύσουν και να διαγράψουν εμπιστευτικό περιεχόμενο πριν από την επεξεργασία.

### Παραδείγματα Σεναρίων Επίθεσης

#### Σενάριο #1: Ακούσια έκθεση δεδομένων
  Ένας χρήστης λαμβάνει μια απάντηση που περιέχει προσωπικά δεδομένα άλλου χρήστη λόγω ανεπαρκούς εξυγίανσης δεδομένων.
#### Σενάριο #2: Στοχευμένη έγχυση προτροπής
  Ένας εισβολέας παρακάμπτει τα φίλτρα εισόδου για να αποσπάσει ευαίσθητες πληροφορίες.
#### Σενάριο #3: Διαρροή δεδομένων μέσω δεδομένων εκπαίδευσης
  Η πλημμελής συμπερίληψη δεδομένων στην εκπαίδευση οδηγεί σε αποκάλυψη ευαίσθητων πληροφοριών.

### Σύνδεσμοι Αναφοράς

1. [Lessons learned from ChatGPT’s Samsung leak](https://cybernews.com/security/chatgpt-samsung-leak-explained-lessons/): **Cybernews**
2. [AI data leak crisis: New tool prevents company secrets from being fed to ChatGPT](https://www.foxbusiness.com/politics/ai-data-leak-crisis-prevent-company-secrets-chatgpt): **Fox Business**
3. [ChatGPT Spit Out Sensitive Data When Told to Repeat ‘Poem’ Forever](https://www.wired.com/story/chatgpt-poem-forever-security-roundup/): **Wired**
4. [Using Differential Privacy to Build Secure Models](https://neptune.ai/blog/using-differential-privacy-to-build-secure-models-tools-methods-best-practices): **Neptune Blog**
5. [Proof Pudding (CVE-2019-20634)](https://avidml.org/database/avid-2023-v009/) **AVID** (`moohax` & `monoxgas`)

### Σχετικά Πλαίσια και Ταξινομήσεις

Ανατρέξτε σε αυτή την ενότητα για αναλυτικές πληροφορίες, στρατηγικές σεναρίων σχετικά με την ανάπτυξη υποδομών, εφαρμοσμένους ελέγχους περιβάλλοντος και άλλες βέλτιστες πρακτικές.

- [AML.T0024.000 - Infer Training Data Membership](https://atlas.mitre.org/techniques/AML.T0024.000) **MITRE ATLAS**
- [AML.T0024.001 - Invert ML Model](https://atlas.mitre.org/techniques/AML.T0024.001) **MITRE ATLAS**
- [AML.T0024.002 - Extract ML Model](https://atlas.mitre.org/techniques/AML.T0024.002) **MITRE ATLAS**
