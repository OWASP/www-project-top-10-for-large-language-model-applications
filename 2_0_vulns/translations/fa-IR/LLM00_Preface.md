## پیامی از رهبران پروژه

پروژه «10 آسیب‌پذیری برتر امنیتی OWASP برای برنامه‌های کاربردی مدل‌های زبانی بزرگ (LLM)» در سال ۲۰۲۳ به عنوان یک ابتکار جمعی با هدف شناسایی و رسیدگی به چالش‌های امنیتی خاص برنامه‌های هوش مصنوعی آغاز شد. از آن زمان، شاهد گسترش روزافزون این فناوری در صنایع و کاربردهای متنوعی بوده‌ایم و به موازات آن، ریسک‌های مرتبط نیز افزایش یافته‌اند. با ادغام هر چه بیشتر LLMها در ابعاد مختلف، از تعاملات با مشتریان گرفته تا عملیات داخلی سازمان‌ها، توسعه‌دهندگان و متخصصان امنیت به طور مستمر در حال کشف آسیب‌پذیری‌های جدید و یافتن راه‌کارهایی برای مواجهه با آن‌ها هستند.

فهرست سال ۲۰۲۳ در افزایش آگاهی و ایجاد زیرساختی برای بهره‌برداری ایمن از LLM بسیار مؤثر واقع شد، اما از آن زمان تاکنون ما به تجربیات و دانش بیشتری دست یافته‌ایم. در نسخه به‌روزرسانی‌شده سال ۲۰۲۵، با گروهی بزرگ‌تر و متشکل از طیف متنوع‌تری از همکاران از سراسر جهان تعامل داشته‌ایم که همگی در تدوین این فهرست مشارکت داشته‌اند. این فرآیند شامل جلسات همفکری، رأی‌گیری و دریافت بازخوردهای عملی از متخصصانی بود که به‌طور مستقیم با مقوله امنیت برنامه‌های کاربردی LLM سروکار دارند؛ چه از طریق مشارکت مستقیم در نگارش موارد و چه از طریق ارائه پیشنهادها و انتقادات سازنده برای بهبود آن‌ها. هر یک از این مشارکت‌ها برای جامعیت و کاربردی‌تر شدن این نسخه جدید نقشی حیاتی ایفا کرده است.

### تازه‌های فهرست ده آسیب‌پذیری برتر سال ۲۰۲۵

فهرست سال ۲۰۲۵ نشان‌دهنده درک عمیق‌تری از مخاطرات موجود و ارائه‌دهنده به‌روزرسانی‌های حیاتی در خصوص نحوه به‌کارگیری مدل‌های زبانی بزرگ (LLM) در برنامه‌های کاربردی دنیای واقعی امروز است. به عنوان نمونه، آسیب‌پذیری **Unbounded Consumption** (مصرف بی‌حد و مرز) توسعه‌ای بر مفهوم حملات منع خدمت (Denial of Service) است که اکنون مخاطرات پیرامون مدیریت منابع و هزینه‌های پیش‌بینی‌نشده را نیز در بر می‌گیرد - مسئله‌ای که در استقرارهای LLM در مقیاس بزرگ به چالشی جدی تبدیل شده است.

در پاسخ به درخواست‌های مکرر جامعه کاربران برای ارائه راهنمایی‌های لازم در خصوص تأمین امنیت Retrieval-Augmented Generation (RAG) و دیگر روش‌های مبتنی بر Embedding، مورد **بردارها و بازنمودهای برداری (Vector and Embeddings)** به فهرست اضافه شده است. این روش‌ها اکنون به عنوان رویه‌های اصلی و محوری برای پایه‌گذاری و اعتبارسنجی خروجی‌های مدل‌های زبانی بزرگ محسوب می‌شوند.

همچنین، در راستای پاسخ به درخواست‌های مکرر جامعه‌ی کاربران و به‌منظور رسیدگی به یکی از چالش‌های امنیتی دارای مصادیق واقعی، مورد **نشت پرامپت سیستم (System Prompt Leakage)** را به فهرست افزوده‌ایم. بسیاری از توسعه‌دهندگان در طراحی برنامه‌های کاربردی مبتنی بر مدل‌های زبانی بزرگ، بر این فرض بودند که پرامپت‌های سیستمی به شکلی امن تفکیک شده و از دسترسی غیرمجاز مصون هستند. اما رخدادهای اخیر نشان داده است که نمی‌توان به‌طور قطعی و بدون اتخاذ تدابیر امنیتی لازم، محرمانه ماندن اطلاعات موجود در این پرامپت‌ها را تضمین کرد.

با توجه به روند فزاینده‌ی به‌کارگیری معماری‌های عامل‌محور (Agentic Architectures) که به مدل‌های زبانی بزرگ (LLM) استقلال عمل بیشتری اعطا می‌کنند، دامنه و اهمیت آسیب‌پذیری **اختیارات بیش از حد (Excessive Agency)** گسترش یافته است. در شرایطی که LLMها به عنوان عامل (Agent) یا در قالب افزونه‌ها (Plugins) ایفای نقش می‌کنند، عدم کنترل دقیق مجوزهای دسترسی می‌تواند به بروز اقدامات ناخواسته و پرمخاطره منجر شود. این امر موجب شده است تا توجه به این آسیب‌پذیری و اتخاذ تدابیر پیشگیرانه در قبال آن، بیش از هر زمان دیگری ضروری و حیاتی باشد.

### مسیر پیش رو

این فهرست، درست مانند خودِ فناوری هوش مصنوعی، حاصل دانش و تجربیات مشترکِ جامعه‌ی متن‌باز است. شکل‌گیری این فهرست مرهون مشارکت بی‌دریغ توسعه‌دهندگان، متخصصین علوم داده و کارشناسان امنیت از حوزه‌های گوناگون است که همگی در راستای ساخت برنامه‌های کاربردی هوش مصنوعیِ امن‌تر، تلاش می‌کنند. خرسندیم که این نسخه به‌روز شده (۲۰۲۵) را با شما به اشتراک می‌گذاریم و امیدواریم که این فهرست، ابزارها و دانش لازم برای حفاظت مؤثر از مدل‌های زبانی بزرگ (LLM) را در اختیارتان قرار دهد.

از تمامی عزیزانی که در تدوین این مجموعه یاری رساندند و همچنین از کلیه کسانی که از این فهرست استفاده نموده و در بهبود آن مشارکت می‌جویند، صمیمانه سپاسگزاریم. از اینکه در این مسیر با شما همگام و هم‌قدم هستیم، خرسند و مفتخریم.


#### Steve Wilson

رهبر پروژه «10 آسیب‌پذیری برتر امنیتی OWASP برای برنامه‌های کاربردی مدل‌های زبانی بزرگ»

لینکدین: https://www.linkedin.com/in/wilsonsd/

#### Ads Dawson

مسئول فنی و مسئول تدوین آسیب‌پذیری‌ها

رهبر پروژه «10 آسیب‌پذیری برتر امنیتی OWASP برای برنامه‌های کاربردی مدل‌های زبانی بزرگ»

LinkedIn: https://www.linkedin.com/in/adamdawson0/


### تیم ترجمه فارسی
#### Hamed Salimian

LinkedIn: https://www.linkedin.com/in/hamed-salimian

#### Arian Gharedaghi

LinkedIn: https://www.linkedin.com/in/arian-gharedaghi

### درباره ترجمه
با توجه به ماهیت فنی و حیاتی OWASP Top 10 برای برنامه‌های مدل زبان بزرگ (LLM)، ما به طور آگاهانه تصمیم گرفتیم که در تهیه این ترجمه تنها از مترجمان انسانی استفاده کنیم. مترجمان ذکرشده در بالا نه تنها دانش فنی عمیقی از محتوای اصلی دارند، بلکه تسلط لازم برای انجام موفقیت‌آمیز این ترجمه را نیز دارا هستند.

#### Talesh Seeparsan

رهبر ترجمه «10 آسیب‌پذیری برتر امنیتی OWASP برای برنامه‌های کاربردی مدل‌های زبانی بزرگ»

LinkedIn: https://www.linkedin.com/in/talesh/
