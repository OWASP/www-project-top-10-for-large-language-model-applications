## LLM07: 2025 सिस्टम Prompt रिसाव

### विवरण

LLMएस में सिस्टम Prompt रिसाव Vulnerability इस जोखिम को संदर्भित करती हैं कि सिस्टम के व्यवहार को आगे बढ़ाने के लिए उपयोग किए जाने वाले सिस्टम या निर्देशों में संवेदनशील जानकारी भी हो सकती हैं जिसे खोजा जाने का इरादा नहीं था। सिस्टम Prompt को एप्लिकेशन की आवश्यकताओं के आधार पर मॉडल के आउटपुट को निर्देशित करने के लिए डिज़ाइन किया गया हैं, लेकिन अनजाने में रहस्य हो सकते हैंं। जब खोज की जाती हैं, तो इस जानकारी का उपयोग अन्य हमलों को सुविधाजनक बनाने के लिए किया जा सकता हैं।

यह समझना महत्वपूर्ण हैं कि सिस्टम Prompt को गुप्त नहीं माना जाना चाहिए, न ही इसे सुरक्षा नियंत्रण के रूप में उपयोग किया जाना चाहिए। तदनुसार, संवेदनशील डेटा जैसे कि क्रेडेंशियल्स, कनेक्शन स्ट्रिंग्स आदि को सिस्टम Prompt भाषा के भीतर समाहित नहीं किया जाना चाहिए।

इसी तरह, यदि किसी सिस्टम Prompt में विभिन्न भूमिकाओं और अनुमतियों का वर्णन करने वाली जानकारी होती हैं, या कनेक्शन स्ट्रिंग्स या पासवर्ड जैसे संवेदनशील डेटा, जबकि इस तरह की जानकारी का प्रकटीकरण सहायक हो सकता हैं, तो मौलिक सुरक्षा जोखिम यह नहीं हैं कि इनका खुलासा किया गया हैं, यह हैं कि एप्लिकेशन यह हैं मजबूत सत्र प्रबंधन और प्राधिकरण चेक को LLM को सौंपने से बाईपास करने की अनुमति देता हैं, और यह संवेदनशील डेटा एक जगह पर संग्रहीत किया जा रहा हैं जो यह नहीं होना चाहिए।

संक्षेप में: सिस्टम का प्रकटीकरण खुद ही वास्तविक जोखिम पेश नहीं करता हैं - सुरक्षा जोखिम अंतर्निहित तत्वों के साथ निहित हैं, चाहे वह संवेदनशील जानकारी का खुलासा हो, सिस्टम रेलिंग बाईपास, विशेषाधिकारों का अनुचित पृथक्करण, आदि भले ही सटीक शब्द हैं। खुलासा नहीं किया गया, सिस्टम के साथ बातचीत करने वाले हमलावर लगभग निश्चित रूप से कई रेलिंग और फॉर्मेटिंग प्रतिबंधों को निर्धारित करने में सक्षम होंगे जो एप्लिकेशन का उपयोग करने के दौरान सिस्टम Prompt भाषा में मौजूद हैंं, मॉडल को उच्चारण भेजते हैंं, और परिणामों का अवलोकन करते हैंं।


### जोखिम के सामान्य उदाहरण

#### 1. संवेदनशील कार्यक्षमता का एक्सपोजर
  एप्लिकेशन का सिस्टम Prompt संवेदनशील जानकारी या कार्यक्षमता को प्रकट कर सकता हैं जिसे गोपनीय रखा जाना हैं, जैसे कि संवेदनशील सिस्टम आर्किटेक्चर, एपीआई कीज़, डेटाबेस क्रेडेंशियल्स, या user टोकन।  इन्हें आवेदन में अनधिकृत पहुंच प्राप्त करने के लिए हमलावरों द्वारा निकाला या उपयोग किया जा सकता हैं। उदाहरण के लिए, एक सिस्टम Prompt जिसमें एक टूल के लिए उपयोग किए जाने वाले डेटाबेस के प्रकार होते हैंं, हमलावर को SQL इंजेक्शन हमलों के लिए इसे लक्षित करने की अनुमति दे सकता हैं।
#### 2. आंतरिक नियमों का एक्सपोजर
  एप्लिकेशन के सिस्टम Prompt से आंतरिक निर्णय लेने की प्रक्रियाओं के बारे में जानकारी का पता चलता हैं जिसे गोपनीय रखा जाना चाहिए। यह जानकारी हमलावरों को अंतर्दृष्टि प्राप्त करने की अनुमति देती हैं कि आवेदन कैसे काम करता हैं जो हमलावरों को अनुप्रयोग में vulnerabilities या बायपास नियंत्रणों का फायदा उठाने की अनुमति दे सकता हैं। उदाहरण के लिए - एक बैंकिंग एप्लिकेशन हैं जिसमें एक चैटबॉट हैं और इसका सिस्टम Prompt जानकारी को प्रकट कर सकता हैं जैसे 
    > "एक user के लिए लेनदेन की सीमा $ 5000 प्रति दिन निर्धारित की जाती हैं। user के लिए कुल ऋण राशि $ 10,000 हैं"।
  यह जानकारी हमलावरों को आवेदन में सुरक्षा नियंत्रण को बायपास करने की अनुमति देती हैं जैसे कि सेट सीमा से अधिक लेनदेन करना या कुल ऋण राशि को बायपास करना।
#### 3. फ़िल्टरिंग मानदंड का खुलासा
  एक सिस्टम Prompt मॉडल को संवेदनशील सामग्री को फ़िल्टर या अस्वीकार करने के लिए कह सकता हैं। उदाहरण के लिए, एक मॉडल में एक सिस्टम Prompt हो सकता हैं, जैसे
    > "यदि कोई user किसी अन्य user के बारे में जानकारी का अनुरोध करता हैं, तो हमेशा, क्षमा करें, मैं उस अनुरोध के साथ सहायता नहीं कर सकता"। "
#### 4. अनुमतियों और user भूमिकाओं का प्रकटीकरण
  सिस्टम Prompt आंतरिक भूमिका संरचनाओं या एप्लिकेशन की अनुमति स्तरों को प्रकट कर सकता हैं। उदाहरण के लिए, एक सिस्टम Prompt प्रकट हो सकता हैं,
    > "व्यवस्थापक user भूमिका user रिकॉर्ड को संशोधित करने के लिए पूर्ण पहुंच अनुदान देता हैं।"
  यदि हमलावर इन भूमिका-आधारित अनुमतियों के बारे में सीखते हैंं, तो वे एक विशेषाधिकार वृद्धि के हमले की तलाश कर सकते हैंं।

### रोकथाम एवं बचाव के लिये रणनीतियाँ

#### 1.  सिस्टम Prompt से संवेदनशील डेटा को अलग करें
  किसी भी संवेदनशील जानकारी (जैसे एपीआई कुंजियाँ, प्रामाणिक कुंजियाँ, डेटाबेस नाम, user भूमिका, आवेदन की अनुमति संरचना) को सीधे सिस्टम में सीधे एम्बेड करने से बचें। इसके बजाय, ऐसी जानकारी को उन प्रणालियों के लिए बाहरी करें जो मॉडल सीधे एक्सेस नहीं करते हैंं।
#### 2.  सख्त व्यवहार नियंत्रण के लिए सिस्टम prompts पर निर्भरता से बचें
  चूंकि LLMS अन्य हमलों जैसे Prompt इंजेक्शन के लिए अतिसंवेदनशील होते हैंं जो सिस्टम Prompt को बदल सकते हैंं, जहां संभव हो तो मॉडल व्यवहार को नियंत्रित करने के लिए सिस्टम Prompt का उपयोग करने से बचने की सिफारिश की जाती हैं।  इसके बजाय, इस व्यवहार को सुनिश्चित करने के लिए LLM के बाहर प्रणालियों पर भरोसा करें।  उदाहरण के लिए, हानिकारक सामग्री का पता लगाना और रोकना बाहरी प्रणालियों में किया जाना चाहिए।
#### 3.  रेलिंग को लागू करें
  LLM के बाहर ही रेलिंग की एक प्रणाली को लागू करें।  जबकि एक मॉडल में विशेष व्यवहार को प्रशिक्षित करना प्रभावी हो सकता हैं, जैसे कि यह प्रशिक्षण देने के लिए कि वह अपने सिस्टम को Prompt को प्रकट नहीं करता हैं, यह गारंटी नहीं हैं कि मॉडल हमेशा इसका पालन करेगा।  एक स्वतंत्र प्रणाली जो यह निर्धारित करने के लिए आउटपुट का निरीक्षण कर सकती हैं कि क्या मॉडल अपेक्षाओं के अनुपालन में हैं, सिस्टम Prompt निर्देशों के लिए बेहतर हैं।
#### 4.  सुनिश्चित करें कि सुरक्षा नियंत्रण LLM से स्वतंत्र रूप से लागू किए गए हैंं
  महत्वपूर्ण नियंत्रण जैसे कि विशेषाधिकार पृथक्करण, प्राधिकरण सीमा जांच, और इसी तरह को LLM को नहीं दिया जाना चाहिए, या तो सिस्टम Prompt के माध्यम से या अन्यथा। इन नियंत्रणों को एक नियतात्मक, श्रव्य तरीके से होने की आवश्यकता हैं, और LLMs (वर्तमान में) इसके लिए अनुकूल नहीं हैंं। ऐसे मामलों में जहां कोई एजेंट कार्य कर रहा हैं, यदि उन कार्यों को विभिन्न स्तरों तक पहुंच की आवश्यकता होती हैं, तो कई एजैंट्स का उपयोग किया जाना चाहिए, प्रत्येक को वांछित कार्यों को करने के लिए आवश्यक कम से कम विशेषाधिकारों के साथ कॉन्फ़िगर किया जाता हैं।

### उदाहरण स्वरूप हमले के परिदृश्य

#### परिद्रश्य 1
   एक LLM में एक सिस्टम Prompt होता हैं जिसमें एक उपकरण के लिए उपयोग किए जाने वाले क्रेडेंशियल्स का एक सेट होता हैं जिसे उस तक पहुंच दी गई हैं।  सिस्टम Prompt एक हमलावर को लीक कर दिया जाता हैं, जो तब अन्य उद्देश्यों के लिए इन क्रेडेंशियल्स का उपयोग करने में सक्षम होता हैं।
#### परिदृश्य#2
  एक LLM में एक प्रणाली हैं जो आक्रामक सामग्री, बाहरी लिंक और कोड निष्पादन की पीढ़ी को प्रतिबंधित करती हैं। एक हमलावर इस प्रणाली को Prompt करता हैं और फिर एक दूरस्थ कोड निष्पादन हमले की सुविधा प्रदान करते हुए, इन निर्देशों को बायपास करने के लिए एक Prompt इंजेक्शन हमले का उपयोग करता हैं।

### संबंधित लिंक

1. [SYSTEM PROMPT LEAK](https://x.com/elder_plinius/status/1801393358964994062): Pliny the prompter
2. [Prompt Leak](https://www.prompt.security/vulnerabilities/prompt-leak): Prompt Security
3. [chatgpt_system_prompt](https://github.com/LouisShark/chatgpt_system_prompt): LouisShark
4. [leaked-system-prompts](https://github.com/jujumilk3/leaked-system-prompts): Jujumilk3
5. [OpenAI Advanced Voice Mode System Prompt](https://x.com/Green_terminals/status/1839141326329360579): Green_Terminals

### संबंधित फ्रेमवर्क और टैक्सोनॉमी

Infrastructure deployment, applied environment controls  तथा अन्य सर्वोत्तम उपायों से संबंधित व्यापक जानकारी, परिदृश्यों की रणनीतियों के लिए इस खंड का संदर्भ लें।

- [AML.T0051.000 - LLM Prompt Injection: Direct (Meta Prompt Extraction)](https://atlas.mitre.org/techniques/AML.T0051.000) **MITRE ATLAS**
