## LLM05: 2025 अनुचित आउटपुट हैंंडलिंग

### विवरण

अनुचित आउटपुट हैंंडलिंग विशेष रूप से अपर्याप्त सत्यापन, स्वच्छता, और LLM द्वारा उत्पन्न आउटपुट की हैंंडलिंग को संदर्भित करता हैं, इससे पहले कि वे अन्य componentों और प्रणालियों के लिए डाउनस्ट्रीम पारित करें। चूंकि LLM-जनित सामग्री को Prompt इनपुट द्वारा नियंत्रित किया जा सकता हैं, इसलिए यह व्यवहार userओं को अतिरिक्त कार्यक्षमता के लिए अप्रत्यक्ष पहुंच प्रदान करने के समान हैं।
अनुचित आउटपुट हैंंडलिंग इस बात से अलग हैं कि यह LLM-जनित आउटपुट से संबंधित हैं, इससे पहले कि वे नीचे की ओर पारित हो जाएं, जबकि ओवररेलेंस LLM आउटपुट की सटीकता और उपयुक्तता पर अति-निर्भरता के आसपास व्यापक चिंताओं पर ध्यान केंद्रित करता हैं।
एक अनुचित आउटपुट हैंंडलिंग Vulnerability का सफल exploit वेब ब्राउज़रों के साथ -साथ SSRF, विशेषाधिकार वृद्धि, या बैकएंड सिस्टम पर दूरस्थ कोड निष्पादन में XSS और CSRF में परिणाम हो सकता हैं।
निम्नलिखित स्थितियां इस Vulnerability के प्रभाव को बढ़ा सकती हैंं:
- एप्लिकेशन LLM विशेषाधिकारों से परे अनुदान देता हैं जो अंतिम userओं के लिए इरादा हैं, विशेषाधिकारों या दूरस्थ कोड निष्पादन में वृद्धि को सक्षम करता हैं।
- एप्लिकेशन अप्रत्यक्ष Prompt इंजेक्शन हमलों के लिए असुरक्षित हैं, जो एक हमलावर को लक्ष्य user के वातावरण तक विशेषाधिकार प्राप्त पहुंच प्राप्त करने की अनुमति दे सकता हैं।
- 3 पार्टी एक्सटेंशन इनपुट को पर्याप्त रूप से मान्य नहीं करते हैंं।
- विभिन्न संदर्भों के लिए उचित आउटपुट एन्कोडिंग की कमी (जैसे, HTML, जावास्क्रिप्ट, SQL)
- LLM आउटपुट की अपर्याप्त निगरानी और लॉगिंग
- LLM उपयोग के लिए दर सीमित या विसंगति का पता लगाने की अनुपस्थिति

### Vulnerability के सामान्य उदाहरण

1। LLM आउटपुट को सीधे सिस्टम शेल या इसी तरह के फ़ंक्शन जैसे EXEC या EVAL में दर्ज किया जाता हैं, जिसके परिणामस्वरूप रिमोट कोड निष्पादन होता हैं।
2। जावास्क्रिप्ट या मार्कडाउन LLM द्वारा उत्पन्न होता हैं और एक user को वापस कर दिया जाता हैं। कोड को तब ब्राउज़र द्वारा व्याख्या की जाती हैं, जिसके परिणामस्वरूप XSS होता हैं।
3। LLM- जनित SQL प्रश्नों को उचित मानकीकरण के बिना निष्पादित किया जाता हैं, जिससे SQL इंजेक्शन होता हैं।
4। LLM आउटपुट का उपयोग उचित स्वच्छता के बिना फ़ाइल पथ का निर्माण करने के लिए किया जाता हैं, जिसके परिणामस्वरूप संभवतः पथ ट्रैवर्सल vulnerabilities होती हैंं।
5। LLM-जनित सामग्री का उपयोग उचित भागने के बिना ईमेल टेम्प्लेट में किया जाता हैं, संभवतः फ़िशिंग हमलों के लिए अग्रणी हैं।

### रोकथाम एवं बचाव के लिये रणनीतियाँ

1। मॉडल को किसी अन्य user के रूप में मानें, एक शून्य-ट्रस्ट दृष्टिकोण को अपनाना, और मॉडल से बैकएंड फ़ंक्शंस के लिए आने वाली प्रतिक्रियाओं पर उचित इनपुट सत्यापन लागू करें।
2। प्रभावी इनपुट सत्यापन और स्वच्छता सुनिश्चित करने के लिए OWASP ASVS (एप्लिकेशन सुरक्षा सत्यापन मानक) दिशानिर्देशों का पालन करें।
3। जावास्क्रिप्ट या मार्कडाउन द्वारा अवांछित कोड निष्पादन को कम करने के लिए userओं को मॉडल आउटपुट वापस एनकोड करें। OWASP ASVS आउटपुट एन्कोडिंग पर विस्तृत मार्गदर्शन प्रदान करता हैं।
4। संदर्भ-जागरूक आउटपुट एन्कोडिंग को लागू करें जहां LLM आउटपुट का उपयोग किया जाएगा (जैसे, वेब सामग्री के लिए एचटीML एन्कोडिंग, डेटाबेस query के लिए एसक्यूएल एस्केपिंग)।
5। LLM आउटपुट से जुड़े सभी डेटाबेस संचालन के लिए पैरामीटर किए गए query या तैयार स्टेटमेंट का उपयोग करें।
6। LLM- जनित सामग्री से XSS हमलों के जोखिम को कम करने के लिए सख्त सामग्री सुरक्षा नीतियों (CSP) को नियोजित करें।
7। LLM आउटपुट में असामान्य पैटर्न का पता लगाने के लिए मजबूत लॉगिंग और मॉनिटरिंग सिस्टम को लागू करें जो exploit के प्रयासों को इंगित कर सकता हैं।

### उदाहरण स्वरूप हमले के परिदृश्य

#### परिद्रश्य 1
  एक एप्लिकेशन चैटबॉट सुविधा के लिए प्रतिक्रियाएं उत्पन्न करने के लिए एक LLM एक्सटेंशन का उपयोग करता हैं। एक्सटेंशन एक अन्य विशेषाधिकार प्राप्त LLM के लिए सुलभ कई प्रशासनिक कार्य भी प्रदान करता हैं। सामान्य प्रयोजन LLM सीधे अपनी प्रतिक्रिया को पारित करता हैं, बिना उचित आउटपुट सत्यापन के, एक्सटेंशन के लिए, एक्सटेंशन को रखरखाव के लिए बंद कर दिया जाता हैं।
#### परिदृश्य#2
  एक user एक लेख का संक्षिप्त सारांश उत्पन्न करने के लिए एक LLM द्वारा संचालित एक वेबसाइट सारांश उपकरण का उपयोग करता हैं। वेबसाइट में एक Prompt इंजेक्शन शामिल हैं जो LLM को वेबसाइट से या user की बातचीत से संवेदनशील सामग्री को पकड़ने के लिए निर्देश देता हैं। वहां से LLM संवेदनशील डेटा को एनकोड कर सकता हैं और इसे किसी भी आउटपुट सत्यापन या फ़िल्टरिंग के बिना, हमलावर-नियंत्रित सर्वर पर भेज सकता हैं।
#### परिदृश्य#3
  एक LLM userओं को चैट जैसी सुविधा के माध्यम से बैकएंड डेटाबेस के लिए SQL query को शिल्प करने की अनुमति देता हैं। एक user सभी डेटाबेस तालिकाओं को हटाने के लिए एक query का अनुरोध करता हैं। यदि LLM से तैयार की गई query की जांच नहीं की जाती हैं, तो सभी डेटाबेस टेबल हटा दिए जाएंगे।
#### परिदृश्य#4
  एक वेब ऐप आउटपुट सैनिटाइजेशन के बिना user texts prompts से सामग्री उत्पन्न करने के लिए एक LLM का उपयोग करता हैं। एक हमलावर एक तैयार किए गए Prompt को जमा कर सकता हैं, जिससे LLM एक असमान जावास्क्रिप्ट पेलोड को वापस कर सकता हैं, जिससे पीड़ित के ब्राउज़र पर रेंडर किए जाने पर एक्सएसएस हो जाता हैं। prompts की अपर्याप्त सत्यापन ने इस हमले को सक्षम किया।
#### परिदृश्य#5
  एक LLM का उपयोग विपणन अभियान के लिए गतिशील ईमेल टेम्प्लेट उत्पन्न करने के लिए किया जाता हैं। एक हमलावर ईमेल सामग्री के भीतर दुर्भावनापूर्ण जावास्क्रिप्ट को शामिल करने के लिए LLM में हेरफेर करता हैं। यदि एप्लिकेशन LLM आउटपुट को ठीक से स्वच्छ नहीं करता हैं, तो यह प्राप्तकर्ताओं पर XSS हमलों को जन्म दे सकता हैं जो Vulnerable ईमेल क्लाइंट में ईमेल देखते हैंं।
#### परिदृश्य#6
  एक LLM का उपयोग एक software कंपनी में प्राकृतिक भाषा इनपुट से कोड उत्पन्न करने के लिए किया जाता हैं, जिसका उद्देश्य विकास कार्यों को सुव्यवस्थित करना हैं। कुशल, यह दृष्टिकोण संवेदनशील जानकारी को उजागर करने, असुरक्षित डेटा हैंंडलिंग विधियों को बनाने, या SQL इंजेक्शन जैसी vulnerabilities को पेश करने का जोखिम उठाता हैं। AI गैर-मौजूद software Packageों को भी मतिभ्रम कर सकता हैं, संभावित रूप से मैलवेयर-संक्रमित संसाधनों को डाउनलोड करने के लिए अग्रणी developers। पूरी तरह से कोड की समीक्षा और सुझाए गए Packageों की सत्यापन सुरक्षा उल्लंघनों, अनधिकृत पहुंच और सिस्टम समझौते को रोकने के लिए महत्वपूर्ण हैं।

### संबंधित लिंक

1. [Proof Pudding (CVE-2019-20634)](https://avidml.org/database/avid-2023-v009/) **AVID** (`moohax` & `monoxgas`)
2. [Arbitrary Code Execution](https://security.snyk.io/vuln/SNYK-PYTHON-LANGCHAIN-5411357): **Snyk Security Blog**
3. [ChatGPT Plugin Exploit Explained: From Prompt Injection to Accessing Private Data](https://embracethered.com/blog/posts/2023/chatgpt-cross-plugin-request-forgery-and-prompt-injection./): **Embrace The Red**
4. [New prompt injection attack on ChatGPT web version. Markdown images can steal your chat data.](https://systemweakness.com/new-prompt-injection-attack-on-chatgpt-web-version-ef717492c5c2?gi=8daec85e2116): **System Weakness**
5. [Don’t blindly trust LLM responses. Threats to chatbots](https://embracethered.com/blog/posts/2023/ai-injections-threats-context-matters/): **Embrace The Red**
6. [Threat Modeling LLM Applications](https://aivillage.org/large%20language%20models/threat-modeling-llm/): **AI Village**
7. [OWASP ASVS - 5 Validation, Sanitization and Encoding](https://owasp-aasvs4.readthedocs.io/en/latest/V5.html#validation-sanitization-and-encoding): **OWASP AASVS**
8. [AI hallucinates software packages and devs download them – even if potentially poisoned with malware](https://www.theregister.com/2024/03/28/ai_bots_hallucinate_software_packages/) **Theregiste**
