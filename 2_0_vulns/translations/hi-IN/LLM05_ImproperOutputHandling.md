## LLM05:2025 Improper Output Handling
## LLM05: 2025 अनुचित आउटपुट हैंडलिंग

### Description
### विवरण

Improper Output Handling refers specifically to insufficient validation, sanitization, and handling of the outputs generated by large language models before they are passed downstream to other components and systems. Since LLM-generated content can be controlled by prompt input, this behavior is similar to providing users indirect access to additional functionality.
Improper Output Handling differs from Overreliance in that it deals with LLM-generated outputs before they are passed downstream whereas Overreliance focuses on broader concerns around overdependence on the accuracy and appropriateness of LLM outputs.
Successful exploitation of an Improper Output Handling vulnerability can result in XSS and CSRF in web browsers as well as SSRF, privilege escalation, or remote code execution on backend systems.
The following conditions can increase the impact of this vulnerability:
- The application grants the LLM privileges beyond what is intended for end users, enabling escalation of privileges or remote code execution.
- The application is vulnerable to indirect prompt injection attacks, which could allow an attacker to gain privileged access to a target user's environment.
- 3rd party extensions do not adequately validate inputs.
- Lack of proper output encoding for different contexts (e.g., HTML, JavaScript, SQL)
- Insufficient monitoring and logging of LLM outputs
- Absence of rate limiting or anomaly detection for LLM usage
अनुचित आउटपुट हैंडलिंग विशेष रूप से अपर्याप्त सत्यापन, स्वच्छता, और बड़े भाषा मॉडल द्वारा उत्पन्न आउटपुट की हैंडलिंग को संदर्भित करता है, इससे पहले कि वे अन्य घटकों और प्रणालियों के लिए डाउनस्ट्रीम पारित करें। चूंकि एलएलएम-जनित सामग्री को शीघ्र इनपुट द्वारा नियंत्रित किया जा सकता है, इसलिए यह व्यवहार उपयोगकर्ताओं को अतिरिक्त कार्यक्षमता के लिए अप्रत्यक्ष पहुंच प्रदान करने के समान है।
अनुचित आउटपुट हैंडलिंग इस बात से अलग है कि यह एलएलएम-जनित आउटपुट से संबंधित है, इससे पहले कि वे नीचे की ओर पारित हो जाएं, जबकि ओवररेलेंस एलएलएम आउटपुट की सटीकता और उपयुक्तता पर अति-निर्भरता के आसपास व्यापक चिंताओं पर ध्यान केंद्रित करता है।
एक अनुचित आउटपुट हैंडलिंग भेद्यता का सफल शोषण वेब ब्राउज़रों के साथ -साथ SSRF, विशेषाधिकार वृद्धि, या बैकएंड सिस्टम पर दूरस्थ कोड निष्पादन में XSS और CSRF में परिणाम हो सकता है।
निम्नलिखित स्थितियां इस भेद्यता के प्रभाव को बढ़ा सकती हैं:
- एप्लिकेशन एलएलएम विशेषाधिकारों से परे अनुदान देता है जो अंतिम उपयोगकर्ताओं के लिए इरादा है, विशेषाधिकारों या दूरस्थ कोड निष्पादन में वृद्धि को सक्षम करता है।
- एप्लिकेशन अप्रत्यक्ष शीघ्र इंजेक्शन हमलों के लिए असुरक्षित है, जो एक हमलावर को लक्ष्य उपयोगकर्ता के वातावरण तक विशेषाधिकार प्राप्त पहुंच प्राप्त करने की अनुमति दे सकता है।
- 3 पार्टी एक्सटेंशन इनपुट को पर्याप्त रूप से मान्य नहीं करते हैं।
- विभिन्न संदर्भों के लिए उचित आउटपुट एन्कोडिंग की कमी (जैसे, HTML, जावास्क्रिप्ट, SQL)
- एलएलएम आउटपुट की अपर्याप्त निगरानी और लॉगिंग
- एलएलएम उपयोग के लिए दर सीमित या विसंगति का पता लगाने की अनुपस्थिति

### Common Examples of Vulnerability
### भेद्यता के सामान्य उदाहरण

1. LLM output is entered directly into a system shell or similar function such as exec or eval, resulting in remote code execution.
2. JavaScript or Markdown is generated by the LLM and returned to a user. The code is then interpreted by the browser, resulting in XSS.
3. LLM-generated SQL queries are executed without proper parameterization, leading to SQL injection.
4. LLM output is used to construct file paths without proper sanitization, potentially resulting in path traversal vulnerabilities.
5. LLM-generated content is used in email templates without proper escaping, potentially leading to phishing attacks.
1। LLM आउटपुट को सीधे सिस्टम शेल या इसी तरह के फ़ंक्शन जैसे EXEC या EVAL में दर्ज किया जाता है, जिसके परिणामस्वरूप रिमोट कोड निष्पादन होता है।
2। जावास्क्रिप्ट या मार्कडाउन एलएलएम द्वारा उत्पन्न होता है और एक उपयोगकर्ता को वापस कर दिया जाता है। कोड को तब ब्राउज़र द्वारा व्याख्या की जाती है, जिसके परिणामस्वरूप XSS होता है।
3। LLM- जनित SQL प्रश्नों को उचित मानकीकरण के बिना निष्पादित किया जाता है, जिससे SQL इंजेक्शन होता है।
4। एलएलएम आउटपुट का उपयोग उचित स्वच्छता के बिना फ़ाइल पथ का निर्माण करने के लिए किया जाता है, जिसके परिणामस्वरूप संभवतः पथ ट्रैवर्सल कमजोरियां होती हैं।
5। एलएलएम-जनित सामग्री का उपयोग उचित भागने के बिना ईमेल टेम्प्लेट में किया जाता है, संभवतः फ़िशिंग हमलों के लिए अग्रणी है।

### Prevention and Mitigation Strategies
### रोकथाम और शमन रणनीतियाँ

1. Treat the model as any other user, adopting a zero-trust approach, and apply proper input validation on responses coming from the model to backend functions.
2. Follow the OWASP ASVS (Application Security Verification Standard) guidelines to ensure effective input validation and sanitization.
3. Encode model output back to users to mitigate undesired code execution by JavaScript or Markdown. OWASP ASVS provides detailed guidance on output encoding.
4. Implement context-aware output encoding based on where the LLM output will be used (e.g., HTML encoding for web content, SQL escaping for database queries).
5. Use parameterized queries or prepared statements for all database operations involving LLM output.
6. Employ strict Content Security Policies (CSP) to mitigate the risk of XSS attacks from LLM-generated content.
7. Implement robust logging and monitoring systems to detect unusual patterns in LLM outputs that might indicate exploitation attempts.
1। मॉडल को किसी अन्य उपयोगकर्ता के रूप में मानें, एक शून्य-ट्रस्ट दृष्टिकोण को अपनाना, और मॉडल से बैकएंड फ़ंक्शंस के लिए आने वाली प्रतिक्रियाओं पर उचित इनपुट सत्यापन लागू करें।
2। प्रभावी इनपुट सत्यापन और स्वच्छता सुनिश्चित करने के लिए OWASP ASVS (एप्लिकेशन सुरक्षा सत्यापन मानक) दिशानिर्देशों का पालन करें।
3। जावास्क्रिप्ट या मार्कडाउन द्वारा अवांछित कोड निष्पादन को कम करने के लिए उपयोगकर्ताओं को मॉडल आउटपुट वापस एनकोड करें। OWASP ASVS आउटपुट एन्कोडिंग पर विस्तृत मार्गदर्शन प्रदान करता है।
4। संदर्भ-जागरूक आउटपुट एन्कोडिंग को लागू करें जहां एलएलएम आउटपुट का उपयोग किया जाएगा (जैसे, वेब सामग्री के लिए एचटीएमएल एन्कोडिंग, डेटाबेस क्वेरी के लिए एसक्यूएल एस्केपिंग)।
5। एलएलएम आउटपुट से जुड़े सभी डेटाबेस संचालन के लिए पैरामीटर किए गए क्वेरी या तैयार स्टेटमेंट का उपयोग करें।
6। LLM- जनित सामग्री से XSS हमलों के जोखिम को कम करने के लिए सख्त सामग्री सुरक्षा नीतियों (CSP) को नियोजित करें।
7। एलएलएम आउटपुट में असामान्य पैटर्न का पता लगाने के लिए मजबूत लॉगिंग और मॉनिटरिंग सिस्टम को लागू करें जो शोषण के प्रयासों को इंगित कर सकता है।

### Example Attack Scenarios
### उदाहरण हमले परिदृश्य

#### Scenario #1
  An application utilizes an LLM extension to generate responses for a chatbot feature. The extension also offers a number of administrative functions accessible to another privileged LLM. The general purpose LLM directly passes its response, without proper output validation, to the extension causing the extension to shut down for maintenance.
#### Scenario #2
  A user utilizes a website summarizer tool powered by an LLM to generate a concise summary of an article. The website includes a prompt injection instructing the LLM to capture sensitive content from either the website or from the user's conversation. From there the LLM can encode the sensitive data and send it, without any output validation or filtering, to an attacker-controlled server.
#### Scenario #3
  An LLM allows users to craft SQL queries for a backend database through a chat-like feature. A user requests a query to delete all database tables. If the crafted query from the LLM is not scrutinized, then all database tables will be deleted.
#### Scenario #4
  A web app uses an LLM to generate content from user text prompts without output sanitization. An attacker could submit a crafted prompt causing the LLM to return an unsanitized JavaScript payload, leading to XSS when rendered on a victim's browser. Insufficient validation of prompts enabled this attack.
#### Scenario # 5
  An LLM is used to generate dynamic email templates for a marketing campaign. An attacker manipulates the LLM to include malicious JavaScript within the email content. If the application doesn't properly sanitize the LLM output, this could lead to XSS attacks on recipients who view the email in vulnerable email clients.
#### Scenario #6
  An LLM is used to generate code from natural language inputs in a software company, aiming to streamline development tasks. While efficient, this approach risks exposing sensitive information, creating insecure data handling methods, or introducing vulnerabilities like SQL injection. The AI may also hallucinate non-existent software packages, potentially leading developers to download malware-infected resources. Thorough code review and verification of suggested packages are crucial to prevent security breaches, unauthorized access, and system compromises.
#### परिद्रश्य 1
  एक एप्लिकेशन चैटबॉट सुविधा के लिए प्रतिक्रियाएं उत्पन्न करने के लिए एक एलएलएम एक्सटेंशन का उपयोग करता है। एक्सटेंशन एक अन्य विशेषाधिकार प्राप्त एलएलएम के लिए सुलभ कई प्रशासनिक कार्य भी प्रदान करता है। सामान्य प्रयोजन एलएलएम सीधे अपनी प्रतिक्रिया को पारित करता है, बिना उचित आउटपुट सत्यापन के, एक्सटेंशन के लिए, एक्सटेंशन को रखरखाव के लिए बंद कर दिया जाता है।
#### परिदृश्य#2
  एक उपयोगकर्ता एक लेख का संक्षिप्त सारांश उत्पन्न करने के लिए एक एलएलएम द्वारा संचालित एक वेबसाइट सारांश उपकरण का उपयोग करता है। वेबसाइट में एक त्वरित इंजेक्शन शामिल है जो एलएलएम को वेबसाइट से या उपयोगकर्ता की बातचीत से संवेदनशील सामग्री को पकड़ने के लिए निर्देश देता है। वहां से एलएलएम संवेदनशील डेटा को एनकोड कर सकता है और इसे किसी भी आउटपुट सत्यापन या फ़िल्टरिंग के बिना, हमलावर-नियंत्रित सर्वर पर भेज सकता है।
#### परिदृश्य#3
  एक एलएलएम उपयोगकर्ताओं को चैट जैसी सुविधा के माध्यम से बैकएंड डेटाबेस के लिए SQL क्वेरी को शिल्प करने की अनुमति देता है। एक उपयोगकर्ता सभी डेटाबेस तालिकाओं को हटाने के लिए एक क्वेरी का अनुरोध करता है। यदि एलएलएम से तैयार की गई क्वेरी की जांच नहीं की जाती है, तो सभी डेटाबेस टेबल हटा दिए जाएंगे।
#### परिदृश्य#4
  एक वेब ऐप आउटपुट सैनिटाइजेशन के बिना उपयोगकर्ता पाठ संकेत से सामग्री उत्पन्न करने के लिए एक एलएलएम का उपयोग करता है। एक हमलावर एक तैयार किए गए प्रॉम्प्ट को जमा कर सकता है, जिससे एलएलएम एक असमान जावास्क्रिप्ट पेलोड को वापस कर सकता है, जिससे पीड़ित के ब्राउज़र पर रेंडर किए जाने पर एक्सएसएस हो जाता है। संकेतों की अपर्याप्त सत्यापन ने इस हमले को सक्षम किया।
#### परिदृश्य#5
  एक एलएलएम का उपयोग विपणन अभियान के लिए गतिशील ईमेल टेम्प्लेट उत्पन्न करने के लिए किया जाता है। एक हमलावर ईमेल सामग्री के भीतर दुर्भावनापूर्ण जावास्क्रिप्ट को शामिल करने के लिए एलएलएम में हेरफेर करता है। यदि एप्लिकेशन एलएलएम आउटपुट को ठीक से स्वच्छ नहीं करता है, तो यह प्राप्तकर्ताओं पर XSS हमलों को जन्म दे सकता है जो कमजोर ईमेल क्लाइंट में ईमेल देखते हैं।
#### परिदृश्य#6
  एक एलएलएम का उपयोग एक सॉफ्टवेयर कंपनी में प्राकृतिक भाषा इनपुट से कोड उत्पन्न करने के लिए किया जाता है, जिसका उद्देश्य विकास कार्यों को सुव्यवस्थित करना है। कुशल, यह दृष्टिकोण संवेदनशील जानकारी को उजागर करने, असुरक्षित डेटा हैंडलिंग विधियों को बनाने, या SQL इंजेक्शन जैसी कमजोरियों को पेश करने का जोखिम उठाता है। AI गैर-मौजूद सॉफ़्टवेयर पैकेजों को भी मतिभ्रम कर सकता है, संभावित रूप से मैलवेयर-संक्रमित संसाधनों को डाउनलोड करने के लिए अग्रणी डेवलपर्स। पूरी तरह से कोड की समीक्षा और सुझाए गए पैकेजों की सत्यापन सुरक्षा उल्लंघनों, अनधिकृत पहुंच और सिस्टम समझौते को रोकने के लिए महत्वपूर्ण है।

### Reference Links
### संदर्भ लिंक

1. [Proof Pudding (CVE-2019-20634)](https://avidml.org/database/avid-2023-v009/) **AVID** (`moohax` & `monoxgas`)
2. [Arbitrary Code Execution](https://security.snyk.io/vuln/SNYK-PYTHON-LANGCHAIN-5411357): **Snyk Security Blog**
3. [ChatGPT Plugin Exploit Explained: From Prompt Injection to Accessing Private Data](https://embracethered.com/blog/posts/2023/chatgpt-cross-plugin-request-forgery-and-prompt-injection./): **Embrace The Red**
4. [New prompt injection attack on ChatGPT web version. Markdown images can steal your chat data.](https://systemweakness.com/new-prompt-injection-attack-on-chatgpt-web-version-ef717492c5c2?gi=8daec85e2116): **System Weakness**
5. [Don’t blindly trust LLM responses. Threats to chatbots](https://embracethered.com/blog/posts/2023/ai-injections-threats-context-matters/): **Embrace The Red**
6. [Threat Modeling LLM Applications](https://aivillage.org/large%20language%20models/threat-modeling-llm/): **AI Village**
7. [OWASP ASVS - 5 Validation, Sanitization and Encoding](https://owasp-aasvs4.readthedocs.io/en/latest/V5.html#validation-sanitization-and-encoding): **OWASP AASVS**
8. [AI hallucinates software packages and devs download them – even if potentially poisoned with malware](https://www.theregister.com/2024/03/28/ai_bots_hallucinate_software_packages/) **Theregiste**
1। [प्रूफ पुडिंग (CVE-2019-20634)]
2। [मनमानी कोड निष्पादन]
3। [CHATGPT प्लगइन एक्सप्लॉइट समझाया गया है: प्रॉम्प्ट इंजेक्शन से लेकर निजी डेटा तक पहुंचने तक] (https://embracethered.com/blog/posts/2023/chatgpt-cross-plugin-request-forgery-and-prompt- inspent./): ** लाल को गले लगाओ **
4। [CHATGPT वेब संस्करण पर नया शीघ्र इंजेक्शन हमला। मार्कडाउन इमेज आपके चैट डेटा को चुरा सकती है।] (https://systemweakness.com/new-prompt-injection- attack-on-chatgpt-web-fistor-ef717492c5c2?gi=8daec85e2116): ** सिस्टम कमजोरी **
5। [LLM प्रतिक्रियाओं पर आँख बंद करके भरोसा न करें। चैटबॉट्स को धमकी] (https://embracethered.com/blog/posts/2023/ai-injections-threats-context-matters/): ** लाल ** को गले लगाओ **
6। [खतरा मॉडलिंग एलएलएम एप्लिकेशन]
7।
8।

