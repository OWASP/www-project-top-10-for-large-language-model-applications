## LLM02: असुरक्षित आउटपुट हैंडलिंग

### विवरण

असुरक्षित तरिके से आउटपुट को संभालना एक ऐसी समस्या है, जो तब उत्पन्न होती है जब एक डाउनस्ट्रीम हिस्सा उचित जांच के बिना बड़े भाषा मॉडल (LLM) के आउटपुट को आँख बंद करके स्वीकार करता है, जैसे कि LLM आउटपुट को सीधे बैकएंड, विशेषाधिकार प्राप्त या क्लाइंट-साइड कार्य में पास करना।

चूंकि LLM के द्वारा बानी सामग्री को शीघ्र इनपुट द्वारा नियंत्रित किया जा सकता है, यह व्यवहार यूज़रओं को अतिरिक्त कार्यक्षमता तक अप्रत्यक्ष पहुंच प्रदान करने के समान है।

असुरक्षित आउटपुट हैंडलिंग के सफल शोषण के परिणामस्वरूप वेब ब्राउज़र में XSS और CSRF के साथ-साथ SSRF, विशेषाधिकार वृद्धि, या बैकएंड सिस्टम पर रिमोट कोड चलाना हो सकता है।

निम्नलिखित स्थितियाँ इस दिक्कत के प्रभाव को बढ़ा सकती हैं:
- एप्लिकेशन अंतिम यूज़रओं के लिए निर्धारित सीमा से परे LLM विशेषाधिकार प्रदान करता है, जिससे विशेषाधिकारों में वृद्धि या रिमोट कोड चलाना सक्षम होता है।
- एप्लिकेशन बाहरी प्रॉम्प्ट इंजेक्शन हमलों के प्रति संवेदनशील है, जो किसी हमलावर को लक्षित यूज़र के वातावरण तक विशेषाधिकार प्राप्त पहुंच प्राप्त करने की अनुमति दे सकता है।
- तृतीय पक्ष प्लगइन्स इनपुट को पर्याप्त रूप से मान्य नहीं करते हैं।

### कमज़ोरी के सामान्य उदाहरण

1. LLM आउटपुट को सीधे सिस्टम शेल या समान फ़ंक्शन जैसे exec या eval में दर्ज किया जाता है, जिसके परिणामस्वरूप रिमोट कोड चलाना होता है।
2. JavaScript  या Markdown  LLM द्वारा तैयार किया जाता है और यूज़र को लौटा दिया जाता है। फिर ब्राउज़र द्वारा कोड की व्याख्या की जाती है, जिसके परिणामस्वरूप XSS होता है।

### बचाव एवं न्यूनीकरण  तरीक़े

1. मॉडल को किसी अन्य यूज़र के समान मानें (शून्य-भरोसेमंद दृष्टिकोण) और मॉडल से बैकएंड फ़ंक्शंस में आने वाली प्रतिक्रियाओं पर उचित इनपुट सत्यापन लागू करें। 
2. प्रभावी इनपुट सत्यापन और स्वच्छता सुनिश्चित करने के लिए OWASP ASVS (एप्लिकेशन सुरक्षा सत्यापन मानक) दिशानिर्देशों का पालन करें।
3. JavaScript या मार्कडाउन द्वारा अनचाहे कोड निष्पादन को कम करने के लिए मॉडल आउटपुट को यूज़रओं के पास वापस एन्कोड करें। OWASP ASVS आउटपुट एन्कोडिंग पर विस्तृत मार्गदर्शन प्रदान करता है।

### उदाहरण हमले के परिदृश्य

1. एक एप्लिकेशन LLM plugin  का उपयोग करती है, चैटबॉट सुविधा के लिए प्रतिक्रियाएं उत्पन्न करने हेतु । हालाँकि, एप्लिकेशन सीधे LLM द्वारा जेनरेट किए गए रिस्पॉन्स को एक अंदरूनी फ़ंक्शन में भेजता है, जिसकी ज़िम्मेदारी सिस्टम कमांड को बिना उचित सत्यापन के निष्पादित करने के लिए होती है। इससे हमलावर अंतर्निहित सिस्टम पर मनमाने तरीके से कमांड चलाने के लिए LLM आउटपुट में हेरफेर कर सकता है, जिससे अनधिकृत ऐक्सेस हो सकता है या सिस्टम में अनपेक्षित बदलाव हो सकते हैं।
2. एक यूज़र किसी लेख का संक्षिप्त सारांश तैयार करने के लिए LLM द्वारा संचालित वेबसाइट समराइज़र टूल का इस्तेमाल करता है। वेबसाइट में एक प्रॉम्प्ट इंजेक्शन शामिल है, जिसमें LLM को निर्देश दिया गया है कि वह किसी भी वेबसाइट से या यूज़र की बातचीत से संवेदनशील सामग्री संजो सकता है । वहाँ से LLM संवेदनशील डेटा को एन्कोड कर सकता है और उसे किसी हमलावर द्वारा नियंत्रित सर्वर पर भेज सकता है।
3. LLM यूज़र को चैट जैसी सुविधा के ज़रिए बैकएंड डेटाबेस के लिए SQL queries  तैयार  करने की सुविधा देता है। एक यूज़र सभी डेटाबेस टेबल हटाने के लिए queries का अनुरोध करता है। अगर LLM से तैयार की गई queries की जांच नहीं की जाती है, तो सभी डेटाबेस टेबल हटा दिए जाएंगे।
4. एक दुर्भावनापूर्ण यूज़र LLM को बिना किसी सैनिटाइज़ेशन नियंत्रण के JavaScript पेलोड यूज़र को वापस लौटाने का निर्देश देता है। यह या तो प्रॉम्प्ट साझा करने, प्रॉम्प्ट इंजेक्शन से प्रभावित वेबसाइट या चैटबॉट के माध्यम से हो सकता है जो URL  पैरामीटर से प्रॉम्प्ट स्वीकार करता है। इसके बाद LLM यूज़र को बिना सैनिटाइज़ किया हुआ XSS पेलोड वापस लौटा देगा। बिना किसी अतिरिक्त फ़िल्टर के, LLM द्वारा अपेक्षित फ़िल्टर के अलावा, JavaScript यूज़र के ब्राउज़र में ही लागू हो जाएगी।

### संदर्भ लिंक

1. [Arbitrary Code Execution](https://security.snyk.io/vuln/SNYK-PYTHON-LANGCHAIN-5411357): Snyk Security Blog
2. [ChatGPT Plugin Exploit Explained](https://embracethered.com/blog/posts/2023/chatgpt-cross-plugin-request-forgery-and-prompt-injection./): From Prompt Injection to Accessing Private Data: Embrace The Red
3. [New prompt injection attack on ChatGPT web version. Markdown images can steal your chat data.](https://systemweakness.com/new-prompt-injection-attack-on-chatgpt-web-version-ef717492c5c2?gi=8daec85e2116): System Weakness
4. [Don’t blindly trust LLM responses. Threats to chatbots](https://embracethered.com/blog/posts/2023/ai-injections-threats-context-matters/): Embrace The Red
5. [Threat Modeling LLM Applications](https://aivillage.org/large%20language%20models/threat-modeling-llm/): AI Village
6. [OWASP ASVS - 5 Validation, Sanitization and Encoding](https://owasp-aasvs4.readthedocs.io/en/latest/V5.html#validation-sanitization-and-encoding): OWASP AASVS