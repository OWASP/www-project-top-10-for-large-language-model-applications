## LLM04: मॉडल का सेवा से इनकार

### विवरण

एक हमलावर LLM का प्रयोग इस प्रकार करता है, जिससे असाधारण रूप संसाधनों का उपभोग करता है । जिसके परिणामस्वरूप उनके और यूज़रओं के लिए सेवा की गुणवत्ता में गिरावट आती है, और संसाधन की लागत में वृद्धि होती है। 
हमलावर द्वारा LLM की संदर्भ विंडो में हस्तक्षेप करने व उसमें हेरफेर करना सुरक्षा की चिंता का विषय है ।विभिन्न ऍप्लिकेशन्स में LLM के बढ़ते उपयोग, उनके गहन संसाधन उपयोग, यूज़र इनपुट की अनिश्चितता और इस कमजोरी के बारे में डेवलपर्स में अनभिज्ञता के कारण यह मुद्दा अधिक गंभीर होता जा रहा है। LLM संदर्भ विंडो इनपुट और आउटपुट दोनों को कवर करते हुए, मॉडल द्वारा प्रबंधित किए जा सकने वाले टेक्स्ट की अधिकतम लंबाई को दर्शाता है। LLM भाषा पैटर्न की जटिलता को निर्धारित करता है जिसे मॉडल समझ सकता है और टेक्स्ट का आकार जिसे वह किसी भी समय प्रोसेस कर सकता है। संदर्भ विंडो का आकार मॉडल की बनावट और उसकी भिन्नता द्वारा परिभाषित किया जाता है । 

### कमज़ोरी के सामान्य उदाहरण

1. ऐसे प्रश्न प्रस्तुत करना, जिनके कारण कतार में बहुत अधिक मात्रा में कार्य उत्पन्न करने के माध्यम से संसाधनों का बार-बार उपयोग होता है, जैसे कि LangChain या AutoGPT के साथ।
2. ऐसे प्रश्न भेजना जो असामान्य रूप से संसाधन-खपत वाली हों, शायद इसलिए क्योंकि वे असामान्य शब्दावली या अनुक्रम का उपयोग करते हैं।
3. लगातार इनपुट ओवरफ़्लो: एक हमलावर LLM को इनपुट की एक शृंखला भेजता है, जो उसकी क्षमता (context window) को पार कर जाती है, जिससे मॉडल बहुत ज़्यादा मशीनी संसाधनों का उपभोग कर लेता है।
4. लंबे इनपुट की शृंखला : हमलावर बार-बार LLM को लंबे इनपुट भेजता है, जिनमें से प्रत्येक कॉन्टेक्स्ट विंडो (context window) को पार कर जाता है।
5. बार-बार संदर्भ (context) विस्तार : हमलावर इनपुट बनाता है जो बार-बार संदर्भ विस्तार को ट्रिगर करता है, जिससे LLM को बार-बार विस्तार करने और संदर्भ विंडो को प्रोसेस करने के लिए मजबूर होना पड़ता है।
6. परिवर्तनशील-लंबाई वाले इनपुट की बाढ़: हमलावर LLM में बड़ी मात्रा में परिवर्तनीय-लंबाई वाले इनपुट भेजता है, जहाँ हर इनपुट को सावधानी से तैयार किया जाता है ताकि संदर्भ विंडो की सीमा तक पहुँचा जा सके। इस तकनीक का उद्देश्य परिवर्तनशील इनपुट को प्रोसेस करने में किसी भी अक्षमता का फायदा उठाना, LLM पर दबाव डालना और संभावित रूप से इसे अनुत्तरदायी बनाना है।

### बचाव कैसे करें

1. यह पक्का करने के लिए कि यूज़र इनपुट निर्धारित सीमाओं का पालन करता है और किसी भी दुर्भावनापूर्ण इनपुट्स  को फ़िल्टर करता है, इनपुट सत्यापन और सैनिटाइज़ेशन लागू करें।
2. प्रत्येक अनुरोध या चरण के अनुसार संसाधन उपयोग को सीमित करें, ताकि जटिल भागों से जुड़े अनुरोध धीरे-धीरे निष्पादित हों।
3. किसी व्यक्तिगत यूज़र या IP पते द्वारा एक विशिष्ट समय सीमा के भीतर किए जाने वाले अनुरोधों की संख्या को सीमित करने के लिए API दर सीमा लागू करें।
4. LLM रिस्पॉन्स पर प्रतिक्रिया करने वाले सिस्टम में कतारबद्ध क्रियाओं और कुल क्रियाओं की संख्या सीमित करें।
5. असामान्य स्पाइक्स या पैटर्न की पहचान करने के लिए LLM के संसाधन उपयोग की लगातार निगरानी करें जो DoS हमले का संकेत दे सकते हैं।
6. LLM कॉन्टेक्स्ट विंडो के आधार पर सख्त इनपुट सीमाएँ निर्धारित करें, ताकि ओवरलोड और संसाधनों की कमी को रोका जा सके।
7. LLM में DoS की संभावित कमजोरियों के बारे में डेवलपर्स के बीच जागरूकता को बढ़ावा दें और LLM को सुरक्षित रूप से लागू करने के लिए दिशानिर्देश प्रदान करें।

### हमले के परिदृश्य में उदाहरण

1. एक हमलावर होस्ट किए गए मॉडल के लिए लगातार कई अनुरोध भेजता है, जिन्हें प्रोसेस करना मुश्किल और महंगा होता है, जिससे दूसरे यूज़र की सेवा खराब हो जाती है और होस्ट के लिए संसाधनों के बिल में वृद्धि होती है।
2. एक वेबपेज पर टेक्स्ट का एक टुकड़ा तब सामने आता है जब एक LLM-संचालित उपकरण एक सौम्य प्रश्न का उत्तर देने के लिए जानकारी एकत्र कर रहा होता है। इससे टूल कई और वेब पेज अनुरोध करने लगता है, जिसके परिणामस्वरूप बड़ी मात्रा में संसाधन की खपत होती है।
3. एक हमलावर लगातार LLM पर इनपुट की बमबारी करता है, जो कॉन्टेक्स्ट विंडो की क्षमता को पार जाती है। हमलावर बड़ी मात्रा में इनपुट भेजने के लिए स्वचालित स्क्रिप्ट या टूल का इस्तेमाल कर सकता है, जो LLM की प्रोसेसिंग क्षमताएं पर भारी पड़ जाती हैं। परिणामस्वरूप, LLM मशीनी संसाधनों की अत्यधिक खपत कर लेता है, जिससे सिस्टम काफी धीमा हो जाता है या पूरी तरह से अनुत्तरदायी हो जाता है।
4. एक हमलावर LLM को क्रमबद्ध इनपुट की एक शृंखला भेजता है, जिसमें हर इनपुट संदर्भ विंडो की सीमा से नीचे  होता है। इन इनपुट को बार-बार सबमिट करके, हमलावर का लक्ष्य संदर्भ विंडो की उपलब्ध क्षमता को खत्म करना है। चूंकि LLM हर इनपुट को उसकी संदर्भ विंडो में प्रोसेस करने के लिए संघर्ष करता है,जिससे सिस्टम के संसाधन कमजोर हो जाते हैं। इसके  परिणामस्वरूप प्रदर्शन खराब हो सकता है या सेवा से पूरी तरह इनकार कर दिया जाता है।
5. एक हमलावर संदर्भ विस्तार को बार-बार ट्रिगर करने के लिए LLM पुनरावर्ती तंत्र का लाभ उठाता है। इसका फायदा उठाने वाले इनपुट को तैयार करके, हमलावर मॉडल को महत्वपूर्ण मशीनी संसाधनों का उपभोग करते हुए संदर्भ विंडो को बार-बार विस्तारित और प्रोसेस करने के लिए मजबूर करता है। यह हमला सिस्टम पर दबाव डालता है और DoS स्थिति पैदा कर सकता है, जिससे LLM अनुत्तरदायी हो सकता है या क्रैश हो सकता है।
6. एक हमलावर LLM में बड़ी मात्रा में परिवर्तनशील इनपुट दे देता है, जिन्हें संदर्भ विंडो की सीमा तक पहुंचने के लिये तैयार किया जाता है। परिवर्तनशील लंबाई के इनपुट से LLM पर हावी होकर,वह अक्षमता का फायदा उठता है। इनपुट्स की यह बाढ़ LLM संसाधनों पर अत्यधिक भार डालती है, जिससे संभावित रूप से प्रदर्शन में गिरावट आ सकती है और वैध अनुरोधों का जवाब देने में सिस्टम की क्षमता में बाधा आ सकती है।
7. जबकि DoS हमलों का लक्ष्य आमतौर पर सिस्टम संसाधनों पर हावी होना होता है, वे सिस्टम व्यवहार के अन्य पहलुओं, जैसे API सीमाओं का भी फायदा उठा सकते हैं। उदाहरण के लिए, हाल ही में सोर्सग्राफ़ सुरक्षा घटना में, दुर्भावनापूर्ण अभिनेता ने एपीआई दर सीमा को बदलने के लिए एक लीक एडमिन एक्सेस टोकन का उपयोग किया, जिससे अनुरोध मात्रा के असामान्य स्तर को सक्षम करके सेवा में व्यवधान पैदा किया गया।

### संदर्भ लिंक

1. [LangChain max_iterations](https://twitter.com/hwchase17/status/1608467493877579777): hwchase17 on Twitter
2. [Sponge Examples: Energy-Latency Attacks on Neural Networks](https://arxiv.org/abs/2006.03463): Arxiv White Paper
3. [OWASP DOS Attack](https://owasp.org/www-community/attacks/Denial_of_Service): OWASP
4. [Learning From Machines](https://lukebechtel.com/blog/lfm-know-thy-context): Know Thy Context: Luke Bechtel
5. [Sourcegraph Security Incident on API Limits Manipulation and DoS Attack ](https://about.sourcegraph.com/blog/security-update-august-2023): Sourcegraph

