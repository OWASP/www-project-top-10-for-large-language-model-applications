## LLM08: अत्यधिक एजेंसी

### विवरण

LLM-आधारित सिस्टम को अक्सर उसके डेवलपर द्वारा दूसरे प्रणाली सिस्टम के साथ इंटरफेस करने और किसी प्रोम्प्ट के जवाब में कार्रवाई करने की क्षमता प्रदान की जाती है।इनपुट प्रॉम्प्ट या LLM आउटपुट के आधार पर डायनामिक रूप से निर्धारित करने के लिए किस फ़ंक्शन को लागू करना है इसका निर्णय LLM 'एजेंट' को भी सौंपा जा सकता है।

अत्यधिक क्षमता वह कमजोरी है जिसके कारण LLM से अनपेक्षित आउटपुट के जवाब में हानिकारक कार्रवाइयां की जा सकती हैं (भले ही LLM में खराबी क्यों न हो; चाहे वह मतिभ्रम हो, प्रत्यक्ष/अप्रत्यक्ष रूप से शीघ्र इंजेक्शन हो, दुर्भावनापूर्ण plugin हो, खराब तरीके से तैयार किए गए सौम्य प्रॉम्प्ट, या सिर्फ़ खराब प्रदर्शन करने वाला मॉडल)। अत्यधिक क्षमता का मूल कारण आम तौर पर एक या एक से अधिक होता है, जैसे की अत्यधिक कार्यक्षमता, अत्यधिक अनुमतियां या अत्यधिक स्वायत्तता।

अत्यधिक क्षमता गोपनीयता (confidentiality) , सत्यनिष्ठा (integrity) और उपलब्धता (availability) के सिद्धांतो पर कई तरह के प्रभाव डाल सकती है और यह इस बात पर निर्भर करती है कि LLM-आधारित ऐप किन सिस्टम के साथ इंटरैक्ट कर सकता है।

### कमज़ोरी के सामान्य उदाहरण

1. अत्यधिक कार्यक्षमता: एक LLM एजेंट एक plugin का उपयोग करता है, जिसमें ऐसे फ़ंक्शन शामिल हैं जिनकी सिस्टम के संचालन के लिए आवश्यकता नहीं है। उदाहरण के लिए, किसी डेवलपर को किसी LLM एजेंट को रिपॉज़िटरी से दस्तावेज़ पढ़ने की सुविधा देनी होती है,इसके लिये वह  तीसरे पक्ष के plugin  का इस्तेमाल करते  हैं,जिसके पास दस्तावेज़ों को संशोधित करने और हटाने की क्षमता भी है। 
2. वैकल्पिक रूप से, हो सकता है कि किसी plugin  को डेवलपमेंट के किसी चरण के दौरान ट्रायल किया गया हो और उसे किसी बेहतर विकल्प के पक्ष में छोड़ दिया गया हो, लेकिन मूल plugin LLM एजेंट के लिए उपलब्ध रहेगा।
3. अत्यधिक कार्यक्षमता: ओपन-एंडेड फ़ंक्शनैलिटी वाला LLM plugin , एप्लिकेशन के संचालन के लिए आवश्यक चीज़ों में  कमांड के इनपुट निर्देशों को ठीक से फ़िल्टर करने में विफल रहता है। उदाहरण के लिए, एक विशिष्ट शेल कमांड चलाने वाला plugin  दूसरे शेल कमांड को  निष्पादित होने से रोकने में विफल रहता है।
4. अत्यधिक अनुमतियां: LLM plugin के पास दूसरे सिस्टम पर अनुमतियां होती हैं जिनकी ऐप्लिकेशन संचालित करने के लिए ज़रूरत नहीं होती है। उदाहरण के लिए, डेटा पढ़ने के लिए बनाया गया plugin  किसी पहचान का इस्तेमाल करके डेटाबेस सर्वर से कनेक्ट होता है, जिसमें न केवल SELECT की अनुमतियां होती हैं, बल्कि UPDATE, INSERT और DELETE की अनुमतियां भी होती हैं।
5. अत्यधिक अनुमतियां: एक LLM plugin  जिसे यूज़र की ओर से ऑपरेशन करने के लिए बनाया गया है,वह  विशेषाधिकार प्राप्त कर डाउनस्ट्रीम सिस्टम को ऐक्सेस करता है। उदाहरण के लिए, मौजूदा यूज़र के दस्तावेज़ों  को पढ़ने के लिए एक plugin है, जो एक विशेषाधिकार प्राप्त खाते के साथ दस्तावेज़ रिपॉजिटरी से कनेक्ट होता है, जिसके पास सभी यूज़र की फ़ाइलों तक पहुंच होती है ।
6. अत्यधिक स्वायत्तता: कोई LLM-आधारित एप्लिकेशन या plugin  हाई-इम्पैक्ट कार्रवाइयों को स्वतंत्र रूप से सत्यापित करने और उन्हें मंज़ूरी देने में विफल रहता है। उदाहरण के लिए, एक plugin जो बिना किसी पुष्टि के यूज़र के दस्तावेज़ों को हटाने की अनुमति देता है।

### बचाव कैसे करें

निम्नलिखित कार्रवाइयों से अत्यधिक एजेंसी को रोका जा सकता है:

1. उन plugin/टूल को ज़रूरी फ़ंक्शन तक सीमित करें जिन्हें LLM एजेंट कॉल करने की अनुमति देते हैं। उदाहरण के लिए, अगर किसी LLM-आधारित सिस्टम के लिए किसी URL की सामग्री लाने की क्षमता की आवश्यकता नहीं है, तो LLM एजेंट को ऐसा plugin नहीं दिये जाने चाहिए।
2. LLM plugin/टूल में लागू किए गए फ़ंक्शन को न्यूनतम आवश्यक तक सीमित करें। उदाहरण के लिए, एक plugin जो ईमेल को सारांशितकरता है ,उसके लिए केवल ईमेल पढ़ने की क्षमता होनी चाहिये,अन्य कार्यक्षमताएँ जैसे कि संदेश हटाने या भेजना की नहीं ।
3. जहाँ संभव हो, ओपन-एंडेड फ़ंक्शन से बचें (उदाहरण के लिए, शेल कमांड चलने, URL प्राप्त करने वाले आदि) और ज़्यादा लक्षित कार्यक्षमता वाले plugin/टूल का इस्तेमाल करें। उदाहरण के लिए, किसी LLM- आधारित ऐप के लिए किसी फ़ाइल में कुछ आउटपुट लिखने की आवश्यकता हो सकती है। अगर इसे शेल फ़ंक्शन चलाने के लिए plugin  का उपयोग करके लागू किया जाता, तो अवांछनीय कार्रवाइयों का दायरा बहुत बड़ जाता  (कोई भी अन्य शेल कमांड निष्पादित किया जा सकता है)। एक ज़्यादा सुरक्षित विकल्प यह होगा कि एक ऐसा फ़ाइल-राइटिंग plugin बनाया जाए, जो सिर्फ़ उस खास सुविधा के साथ ही काम कर सके।
4. उन अनुमतियों को सीमित करें जो LLM plugins/टूल दूसरे सिस्टम को दी जाती हैं, ताकि अवांछनीय कार्रवाइयों का दायरा सीमित किया जा सके। उदाहरण के लिए, एक LLM एजेंट जो किसी ग्राहक को खरीदारी के सुझाव देने के लिए प्रॉडक्ट डेटाबेस का इस्तेमाल करता है, उसे सिर्फ़ 'प्रॉडक्ट' टेबल पढ़ने की ज़रूरत होगी; उसके पास दूसरी टेबल तक ऐक्सेस नहीं होनी चाहिए, न ही रिकॉर्ड डालने, अपडेट या हटाने की क्षमता होनी चाहिए। इसे उस पहचान के लिए उपयुक्त डेटाबेस अनुमतियां लागू करनी चाहिए, जिसका इस्तेमाल LLM plugin डेटाबेस से कनेक्ट करने के लिए करता है।
5. यह पक्का करने के लिए कि यूज़र की ओर से की गई कार्रवाइयां डाउनस्ट्रीम सिस्टम पर उस विशिष्ट यूज़र के संदर्भ में और न्यूनतम ज़रूरी विशेषाधिकारों के साथ निष्पादित हों, यूज़र की अनुमति और सुरक्षा क्षेत्र को ट्रैक करें। उदाहरण के लिए, एक LLM plugin  जो यूज़र के कोड रेपो को पढ़ता है,तो उसे  OAuth के ज़रिए और न्यूनतम स्कोप के साथ प्रमाणीकरण करना होगा।
6. सभी कार्रवाइयों को करने से पहले मानव द्वारा मंज़ूरी ले। इसे डाउनस्ट्रीम सिस्टम (LLM ऐप्लिकेशन के दायरे से बाहर) या LLM plugin /टूल में ही लागू किया जा सकता है। उदाहरण के लिए, किसी यूज़र की ओर से सोशल मीडिया कॉन्टेंट बनाने और पोस्ट करने वाले LLM-आधारित ऐप में 'पोस्ट' ऑपरेशन लागू करने वाले plugin /टूल/API में यूज़र की स्वीकृति शामिल होनी चाहिए।
7. किसी कार्रवाई की अनुमति है या नहीं, यह तय करने के लिए LLM पर निर्भर रहने के बजाय डाउनस्ट्रीम सिस्टम में प्राधिकरण (authorization) लागू करें। टूल/plugin लागू करते समय, मीडिएशन का पूरा सिद्धांत लागू करें, ताकि plugin/टूल के ज़रिये डाउनस्ट्रीम सिस्टम से किए गए सभी अनुरोधों की सुरक्षा नीतियों के तहत पुष्टि हो सके।

निम्नलिखित विकल्प अत्यधिक एजेंसी को नहीं रोकेंगे, लेकिन इससे होने वाले नुकसान के स्तर को सीमित कर सकते हैं:
1. LLM plugin/टूल और डाउनस्ट्रीम सिस्टम की गतिविधि की निगरानी कर सूचीबद्ध करें ताकि यह पता चल सके कि अवांछनीय कार्रवाइयां कहाँ हो रही हैं और उसी के अनुसार प्रतिक्रिया दें।
2. किसी निश्चित समयावधि में होने वाली अवांछनीय कार्रवाइयों की संख्या को कम करने के लिए दर-सीमा लागू करें, इससे पहले कि महत्वपूर्ण नुकसान हो, निगरानी के ज़रिए अवांछनीय कार्रवाइयों का पता लगाने के अवसर बढ़ाएँ।

###  हमले के परिदृश्य मे उदाहरण

LLM-आधारित व्यक्तिगत सहायक ऐप (personal assistant app) को plugin द्वारा किसी व्यक्ति के मेलबॉक्स से जोड़ा गया, जिससे की वह आने वाले emails को सारांशित करे । इसके लिये plugin को संदेशों को पढ़ने की क्षमता की आवश्यकता है, हालांकि सिस्टम डेवलपर द्वारा चुना plugin के पास संदेश भेजने की क्षमता भी हैं। अगर प्रयोग किया गया LLM अप्रत्यक्ष prompt इंजेक्शन हमले के प्रति कमजोर है, तब कोई दुर्भावनापूर्ण-ईमेल LLM को plugin द्वारा, 'send message' फनशन के प्रयोग से उपयोगकर्ता के मेलबॉक्स से स्पैम भेजने को कहता है। इससे बचने के लिये: <br> 
(क) अत्यधिक कार्यक्षमता को घटाने के लिये, केवल पढ़ने की क्षमता वाले plugin चुने, <br>
(ख) अत्यधिक अनुमतियों को घटाने के लिये उपयोगकर्ता की ईमेल को केवल-पढ़ने के दायरे वाली OAuth सत्र से जोड़े, <br>
(ग) अत्यधिक स्वायत्तता को घटाने के लिये उपयोगकर्ता, एलएलएम प्लगइन द्वारा बने प्रत्येक मेल की समीक्षा करके ही भेजे। मेल भेजने के इंटरफ़ेस की दर सीमित करने से भी क्षति को कम किया जा सकता है।

### संदर्भ लिंक

1. [Embrace the Red](https://embracethered.com/blog/posts/2023/chatgpt-cross-plugin-request-forgery-and-prompt-injection./): Confused Deputy Problem: Embrace The Red
2. [NeMo-Guardrails](https://github.com/NVIDIA/NeMo-Guardrails/blob/main/docs/security/guidelines.md): Interface guidelines: NVIDIA Github
3. [LangChain: Human-approval for tools](https://python.langchain.com/docs/modules/agents/tools/human_approval): Langchain Documentation
5. [Simon Willison: Dual LLM Pattern](https://simonwillison.net/2023/Apr/25/dual-llm-pattern/): Simon Willison
