| Publication | Author | Date | Title | Link |
|-------------|--------|------|-------|------|
| Wired | Matt Burgess | 13-Apr-23 | [The Hacking of ChatGPT Is Just Getting Started](https://www.wired.com/story/chatgpt-jailbreak-generative-ai-hacking/) |
| The Math Company | Arjun Menon | 23-Jan-23 | [Data Poisoning and Its Impact on the AI Ecosystem](https://themathcompany.com/blog/data-poisoning-and-its-impact-on-the-ai-ecosystem) |
| IEEE Spectrum | Payal Dhar | 24-Mar-23 | [Protecting AI Models from “Data Poisoning”](https://spectrum.ieee.org/ai-cybersecurity-data-poisoning) |
| AMB Crypto | Suzuki Shillsalot | 30-Apr-23 | [Here’s how anyone can Jailbreak ChatGPT with these top 4 methods](https://ambcrypto.com/heres-how-to-jailbreak-chatgpt-with-the-top-4-methods-5/) |
| Techopedia | Kaushik Pal | 22-Apr-23 | [What is Jailbreaking in AI models like ChatGPT?](https://www.techopedia.com/what-is-jailbreaking-in-ai-models-like-chatgpt) |
| The Register | Thomas Claburn | 26-Apr-23 | [How prompt injection attacks hijack today's top-end AI – and it's tough to fix](https://www.theregister.com/2023/04/26/simon_willison_prompt_injection/) |
| NCC Group | Jose Selvi | 5-Dec-22 | [Exploring Prompt Injection Attacks](https://research.nccgroup.com/2022/12/05/exploring-prompt-injection-attacks/) |
| Itemis | Rafael Tappe Maestro | 14-Feb-23 | [The Rise of Large Language Models ~ Part 2: Model Attacks, Exploits, and Vulnerabilities](https://blogs.itemis.com/en/model-attacks-exploits-and-vulnerabilities) |
| Hidden Layer | Eoin Wickens, Marta Janus | 23-Mar-23 | [The Dark Side of Large Language Models: Part 1](https://hiddenlayer.com/research/the-dark-side-of-large-language-models/) |
| Hidden Layer | Eoin Wickens, Marta Janus | 24-Mar-23 | [The Dark Side of Large Language Models: Part 2](https://hiddenlayer.com/research/the-dark-side-of-large-language-models-2/) |
| Embrace the Red | Wunderwuzzi | 29-Mar-23 | [AI Injections: Direct and Indirect Prompt Injections and Their Implications](https://embracethered.com/blog/posts/2023/ai-injections-direct-and-indirect-prompt-injection-basics/) |
| Embrace the Red | Wunderwuzzi | 15-Apr-23 | [Don't blindly trust LLM responses. Threats to chatbots](https://embracethered.com/blog/posts/2023/ai-injections-threats-context-matters/) |
| MufeedDVH | Mufeed | 9-Dec-22 | [Security in the age of LLMs](https://www.mufeedvh.com/llm-security/) |
