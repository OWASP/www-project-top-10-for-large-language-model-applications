### Educational Links

Some useful resource links to learn about LLM security issues.

| Publication | Author | Date | Title and Link |
|-------------|--------|---------|-------------|
| Wired | Matt Burgess | 13-Apr-23 | [The Hacking of ChatGPT Is Just Getting Started](https://www.wired.com/story/chatgpt-jailbreak-generative-ai-hacking/) |
| The Math Company | Arjun Menon | 23-Jan-23 | [Data Poisoning and Its Impact on the AI Ecosystem](https://themathcompany.com/blog/data-poisoning-and-its-impact-on-the-ai-ecosystem) |
| IEEE Spectrum | Payal Dhar | 24-Mar-23 | [Protecting AI Models from “Data Poisoning”](https://spectrum.ieee.org/ai-cybersecurity-data-poisoning) |
| AMB Crypto | Suzuki Shillsalot | 30-Apr-23 | [Here’s how anyone can Jailbreak ChatGPT with these top 4 methods](https://ambcrypto.com/heres-how-to-jailbreak-chatgpt-with-the-top-4-methods-5/) |
| Techopedia | Kaushik Pal | 22-Apr-23 | [What is Jailbreaking in AI models like ChatGPT?](https://www.techopedia.com/what-is-jailbreaking-in-ai-models-like-chatgpt) |
| The Register | Thomas Claburn | 26-Apr-23 | [How prompt injection attacks hijack today's top-end AI – and it's tough to fix](https://www.theregister.com/2023/04/26/simon_willison_prompt_injection/) |
| NCC Group | Jose Selvi | 5-Dec-22 | [Exploring Prompt Injection Attacks](https://research.nccgroup.com/2022/12/05/exploring-prompt-injection-attacks/) |
| Itemis | Rafael Tappe Maestro | 14-Feb-23 | [The Rise of Large Language Models ~ Part 2: Model Attacks, Exploits, and Vulnerabilities](https://blogs.itemis.com/en/model-attacks-exploits-and-vulnerabilities) |
| Hidden Layer | Eoin Wickens, Marta Janus | 23-Mar-23 | [The Dark Side of Large Language Models: Part 1](https://hiddenlayer.com/research/the-dark-side-of-large-language-models/) |
| Hidden Layer | Eoin Wickens, Marta Janus | 24-Mar-23 | [The Dark Side of Large Language Models: Part 2](https://hiddenlayer.com/research/the-dark-side-of-large-language-models-2/) |
| Embrace the Red | Wunderwuzzi | 29-Mar-23 | [AI Injections: Direct and Indirect Prompt Injections and Their Implications](https://embracethered.com/blog/posts/2023/ai-injections-direct-and-indirect-prompt-injection-basics/) |
| Embrace the Red | Wunderwuzzi | 15-Apr-23 | [Don't blindly trust LLM responses. Threats to chatbots](https://embracethered.com/blog/posts/2023/ai-injections-threats-context-matters/) |
| MufeedDVH | Mufeed | 9-Dec-22 | [Security in the age of LLMs](https://www.mufeedvh.com/llm-security/) |
| Team8 | Team8 CISO Village | 18-Apr-23 | [Generative AI and ChatGPT Enterprise Risks](https://team8.vc/wp-content/uploads/2023/04/Team8-Generative-AI-and-ChatGPT-Enterprise-Risks.pdf) |
| Deloitte | Deloitte AI Institute | 13-Mar-23 | [A new frontier in artificial intelligence - Implications of Generative AI for businesses](https://www2.deloitte.com/content/dam/Deloitte/us/Documents/deloitte-analytics/us-ai-institute-generative-artificial-intelligence.pdf) |
| Arxiv | Fabio Perez, Ian Ribeiro | 17-Nov-22 | [Ignore Previous Prompt: Attack Techniques For Language Models](https://arxiv.org/pdf/2211.09527.pdf) |
| Arxiv | Nicholas Carlini, et al | 14-Dec-20 | [Extracting Training Data from Large Language Models](https://arxiv.org/pdf/2012.07805.pdf) |
| danielmiessler.com | Daniel Miessler | 15-May-23 | [The AI Attack Surface Map v1.0](https://danielmiessler.com/blog/the-ai-attack-surface-map-v1-0/) |
| NCC Group | Chris Anley | 06-Jul-22 | [Practical Attacks on Machine Learning Systems](https://research.nccgroup.com/wp-content/uploads/2022/07/practical-attacks-on-ml.pdf) |
| CloudSecurityPodcast.tv | Ashish Rajan | 30-May-23 | [Can LLMs Be Attacked?](https://www.youtube.com/watch?v=Yl9qqt9C5lE)
| NVIDIA Developer | Will Pearce, Joseph Lucas | 14-Jun-23 | [NVIDIA AI Red Team: An Introduction] (https://developer.nvidia.com/blog/nvidia-ai-red-team-an-introduction) |
